/**
 * LLM配置API服务
 * 调用后端API管理LLM配置
 */

import { getBackendUrl } from '../utils/backendUrl';

const API_BASE_URL = `${getBackendUrl()}/api/llm`;

// ============================================================================
// Provider (供应商) 相关类型和API
// ============================================================================

export interface LLMProvider {
  provider_id: string;
  name: string;
  provider_type: 'openai' | 'deepseek' | 'anthropic' | 'local' | 'custom' | 'ollama' | 'gemini';
  is_system: boolean;
  override_url: boolean;
  default_api_url?: string;
  logo_light?: string;
  logo_dark?: string;
  logo_theme?: 'auto' | 'light' | 'dark';
  metadata?: Record<string, any>;
  created_at: string;
  updated_at: string;
}

export interface CreateProviderRequest {
  name: string;
  provider_type: 'openai' | 'deepseek' | 'anthropic' | 'local' | 'custom' | 'ollama' | 'gemini';
  override_url?: boolean;
  default_api_url?: string;
  logo_theme?: 'auto' | 'light' | 'dark';
  metadata?: Record<string, any>;
}

export interface UpdateProviderRequest {
  name?: string;
  provider_type?: 'openai' | 'deepseek' | 'anthropic' | 'local' | 'custom' | 'ollama' | 'gemini';
  override_url?: boolean;
  default_api_url?: string;
  logo_light?: string;
  logo_dark?: string;
  logo_theme?: 'auto' | 'light' | 'dark';
  metadata?: Record<string, any>;
}

export interface DownloadLogoResponse {
  logo_light: string;
  logo_dark: string;
  theme: string;
  format: string;
}

export interface LLMConfigFromDB {
  config_id: string;
  name: string;
  shortname?: string;
  provider: 'openai' | 'deepseek' | 'anthropic' | 'local' | 'custom' | 'ollama' | 'gemini';
  supplier?: string;  // Token/计费归属供应商（如 nvidia, openai）
  api_url?: string;
  model?: string;
  tags?: string[];
  enabled: boolean;
  is_default?: boolean;
  description?: string;
  metadata?: Record<string, any>;
  max_tokens?: number; // 模型的最大 token 限制（从后端获取）
  created_at: string;
  updated_at: string;
}

export interface CreateLLMConfigRequest {
  config_id?: string;
  name: string;
  shortname?: string;
  provider: 'openai' | 'deepseek' | 'anthropic' | 'local' | 'custom' | 'ollama' | 'gemini';
  supplier?: string;  // Token/计费归属供应商（如 nvidia, openai）
  api_key?: string;
  api_url?: string;
  model?: string;
  tags?: string[];
  enabled?: boolean;
  description?: string;
  metadata?: Record<string, any>;
}

/**
 * 获取所有LLM配置
 */
export async function getLLMConfigs(): Promise<LLMConfigFromDB[]> {
  const response = await fetch(`${API_BASE_URL}/configs`);
  if (!response.ok) {
    throw new Error(`Failed to fetch LLM configs: ${response.statusText}`);
  }
  const data = await response.json();
  return data.configs || [];
}

/**
 * 获取单个LLM配置
 */
export async function getLLMConfig(configId: string): Promise<LLMConfigFromDB> {
  const response = await fetch(`${API_BASE_URL}/configs/${configId}`);
  if (!response.ok) {
    throw new Error(`Failed to fetch LLM config: ${response.statusText}`);
  }
  return response.json();
}

/**
 * 创建LLM配置
 */
export async function createLLMConfig(config: CreateLLMConfigRequest): Promise<{ config_id: string; message: string }> {
  const response = await fetch(`${API_BASE_URL}/configs`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(config),
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } }));
    throw new Error(`Failed to create LLM config: ${error.error?.message || response.statusText}`);
  }
  return response.json();
}

/**
 * 更新LLM配置
 */
export async function updateLLMConfig(configId: string, updates: Partial<CreateLLMConfigRequest>): Promise<{ message: string }> {
  const response = await fetch(`${API_BASE_URL}/configs/${configId}`, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(updates),
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } }));
    throw new Error(`Failed to update LLM config: ${error.error?.message || response.statusText}`);
  }
  return response.json();
}

/**
 * 删除LLM配置
 */
export async function deleteLLMConfig(configId: string): Promise<{ message: string }> {
  const response = await fetch(`${API_BASE_URL}/configs/${configId}`, {
    method: 'DELETE',
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } }));
    throw new Error(`Failed to delete LLM config: ${error.error?.message || response.statusText}`);
  }
  return response.json();
}

/**
 * 获取LLM配置的API密钥（用于调用）
 */
export async function getLLMConfigApiKey(configId: string): Promise<string> {
  const response = await fetch(`${API_BASE_URL}/configs/${configId}/api-key`);
  if (!response.ok) {
    throw new Error(`Failed to get API key: ${response.statusText}`);
  }
  const data = await response.json();
  return data.api_key || '';
}

// ==================== LLM配置导入导出 ====================

export interface LLMConfigExportData {
  version: string;
  export_type: 'llm_config' | 'llm_configs';
  exported_at: string;
  llm_config?: {
    name: string;
    provider: string;
    api_key?: string;
    api_url?: string;
    model?: string;
    tags?: string[];
    enabled: boolean;
    description?: string;
    metadata?: Record<string, any>;
  };
  llm_configs?: Array<{
    name: string;
    provider: string;
    api_key?: string;
    api_url?: string;
    model?: string;
    tags?: string[];
    enabled: boolean;
    description?: string;
    metadata?: Record<string, any>;
  }>;
}

/**
 * 导出单个LLM配置
 */
export async function exportLLMConfig(configId: string): Promise<LLMConfigExportData> {
  const response = await fetch(`${API_BASE_URL}/configs/${configId}/export`);
  if (!response.ok) {
    const error = await response.json().catch(() => ({}));
    throw new Error(error.error || `Failed to export config: ${response.statusText}`);
  }
  return await response.json();
}

/**
 * 导出所有LLM配置
 */
export async function exportAllLLMConfigs(): Promise<LLMConfigExportData> {
  const response = await fetch(`${API_BASE_URL}/configs/export-all`);
  if (!response.ok) {
    const error = await response.json().catch(() => ({}));
    throw new Error(error.error || `Failed to export configs: ${response.statusText}`);
  }
  return await response.json();
}

/**
 * 导入LLM配置
 */
export async function importLLMConfigs(
  data: LLMConfigExportData,
  skipExisting: boolean = false
): Promise<{ imported: Array<{ config_id: string; name: string }>; skipped: string[] }> {
  const response = await fetch(`${API_BASE_URL}/configs/import?skip_existing=${skipExisting}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(data),
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({}));
    throw new Error(error.error || `Failed to import configs: ${response.statusText}`);
  }
  return await response.json();
}

/**
 * 下载LLM配置为JSON文件
 */
export async function downloadLLMConfigAsJson(configId: string, configName: string): Promise<void> {
  const data = await exportLLMConfig(configId);
  
  const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `${configName.replace(/[^a-zA-Z0-9\u4e00-\u9fa5]/g, '_')}_llm_config.json`;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}

/**
 * 下载所有LLM配置为JSON文件
 */
export async function downloadAllLLMConfigsAsJson(): Promise<void> {
  const data = await exportAllLLMConfigs();
  
  const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `llm_configs_${new Date().toISOString().slice(0, 10)}.json`;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}

/**
 * 从JSON文件导入LLM配置
 */
export function importLLMConfigsFromFile(): Promise<LLMConfigExportData> {
  return new Promise((resolve, reject) => {
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = '.json';
    
    input.onchange = async (e) => {
      const file = (e.target as HTMLInputElement).files?.[0];
      if (!file) {
        reject(new Error('No file selected'));
        return;
      }
      
      try {
        const text = await file.text();
        const data = JSON.parse(text) as LLMConfigExportData;
        
        // 验证数据格式
        if (!['llm_config', 'llm_configs'].includes(data.export_type)) {
          reject(new Error('无效的导入文件：不是LLM配置文件'));
          return;
        }
        
        if (!data.llm_config && !data.llm_configs) {
          reject(new Error('无效的导入文件：缺少配置数据'));
          return;
        }
        
        resolve(data);
      } catch (error) {
        reject(new Error('无法解析文件：请确保是有效的JSON格式'));
      }
    };
    
    input.click();
  });
}

// ============================================================================
// Provider API
// ============================================================================

/**
 * 系统支持的供应商信息
 */
export interface SupportedProvider {
  provider_type: 'openai' | 'deepseek' | 'anthropic' | 'gemini' | 'ollama';
  name: string;
  description: string;
  default_api_url: string;
  requires_api_key: boolean;
  icon: string;
  color: string;
}

/**
 * 获取系统支持的供应商列表
 */
export async function getSupportedProviders(): Promise<SupportedProvider[]> {
  const response = await fetch(`${API_BASE_URL}/providers/supported`);
  if (!response.ok) {
    throw new Error(`Failed to fetch supported providers: ${response.statusText}`);
  }
  const data = await response.json();
  return data.providers || [];
}

/**
 * 获取所有供应商
 */
export async function getProviders(): Promise<LLMProvider[]> {
  const response = await fetch(`${API_BASE_URL}/providers`);
  if (!response.ok) {
    throw new Error(`Failed to fetch providers: ${response.statusText}`);
  }
  const data = await response.json();
  return data.providers || [];
}

/**
 * 获取单个供应商
 */
export async function getProvider(providerId: string): Promise<LLMProvider> {
  const response = await fetch(`${API_BASE_URL}/providers/${providerId}`);
  if (!response.ok) {
    throw new Error(`Failed to fetch provider: ${response.statusText}`);
  }
  return response.json();
}

/**
 * 创建供应商
 */
export async function createProvider(provider: CreateProviderRequest): Promise<{ provider_id: string; message: string }> {
  const response = await fetch(`${API_BASE_URL}/providers`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(provider),
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: 'Unknown error' }));
    throw new Error(`Failed to create provider: ${error.error || response.statusText}`);
  }
  return response.json();
}

/**
 * 更新供应商
 */
export async function updateProvider(providerId: string, updates: UpdateProviderRequest): Promise<{ message: string }> {
  const response = await fetch(`${API_BASE_URL}/providers/${providerId}`, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(updates),
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: 'Unknown error' }));
    throw new Error(`Failed to update provider: ${error.error || response.statusText}`);
  }
  return response.json();
}

/**
 * 删除供应商
 */
export async function deleteProvider(providerId: string): Promise<{ message: string }> {
  const response = await fetch(`${API_BASE_URL}/providers/${providerId}`, {
    method: 'DELETE',
  });
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: 'Unknown error' }));
    throw new Error(`Failed to delete provider: ${error.error || response.statusText}`);
  }
  return response.json();
}

/**
 * 从 LobeHub CDN 下载供应商 Logo
 */
export async function downloadProviderLogo(
  provider: string,
  theme: 'auto' | 'light' | 'dark' = 'auto'
): Promise<DownloadLogoResponse> {
  const response = await fetch(`${API_BASE_URL}/providers/download-logo?provider=${encodeURIComponent(provider)}&theme=${theme}`);
  if (!response.ok) {
    const error = await response.json().catch(() => ({ error: 'Unknown error' }));
    throw new Error(`Failed to download logo: ${error.error || response.statusText}`);
  }
  return response.json();
}

/**
 * Logo 选项
 */
export interface LogoOption {
  type: string;
  url: string;
  preview: string;
}

/**
 * Logo 选项响应
 */
export interface LogoOptionsResponse {
  light_options: LogoOption[];
  dark_options: LogoOption[];
  slug: string;
}

/**
 * 获取供应商的 Logo 选项（浅色和深色两组）
 */
export async function getProviderLogoOptions(provider: string): Promise<LogoOptionsResponse> {
  const response = await fetch(`${API_BASE_URL}/providers/logo-options?provider=${encodeURIComponent(provider)}`);
  if (!response.ok) {
    let errorData: any = { error: 'Unknown error' };
    try {
      errorData = await response.json();
    } catch {
      // 如果JSON解析失败，使用默认错误
    }
    // 创建一个包含更多信息的错误对象
    const errorObj: any = new Error(errorData.error || response.statusText);
    errorObj.response = response;
    errorObj.errorData = errorData;
    throw errorObj;
  }
  const data = await response.json();
  return {
    light_options: data.light_options || [],
    dark_options: data.dark_options || [],
    slug: data.slug || ''
  };
}

