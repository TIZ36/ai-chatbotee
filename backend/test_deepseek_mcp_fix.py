#!/usr/bin/env python3
"""
æµ‹è¯• DeepSeek MCP ä¿®å¤
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from services.mcp_execution_service import call_llm_api


def test_deepseek_api_routing():
    """æµ‹è¯• DeepSeek API è·¯ç”±"""
    print("ğŸ”„ æµ‹è¯• DeepSeek API è·¯ç”±...")

    # æ¨¡æ‹Ÿ DeepSeek é…ç½®ï¼ˆprovider=openai, model=deepseek-reasonerï¼‰
    deepseek_config = {
        'provider': 'openai',
        'model': 'deepseek-reasoner',
        'api_key': 'test_key',
        'api_url': None
    }

    # æ¨¡æ‹Ÿæ™®é€š OpenAI é…ç½®
    openai_config = {
        'provider': 'openai',
        'model': 'gpt-4',
        'api_key': 'test_key',
        'api_url': None
    }

    # æµ‹è¯•è·¯ç”±é€»è¾‘ï¼ˆæ£€æŸ¥ä»£ç åˆ†æ”¯ï¼Œä¸å®é™…è°ƒç”¨ APIï¼‰
    def check_routing_logic(llm_config):
        """æ£€æŸ¥è·¯ç”±é€»è¾‘"""
        provider = llm_config.get('provider', '')
        model = llm_config.get('model', '')
        is_deepseek_model = 'deepseek' in model.lower()

        if provider == 'openai' and is_deepseek_model:
            return 'deepseek'
        elif provider == 'openai' and not is_deepseek_model:
            return 'openai'
        else:
            return 'unknown'

    # æµ‹è¯• DeepSeek è·¯ç”±
    print("\nğŸ§ª æµ‹è¯• DeepSeek æ¨¡å‹è·¯ç”±...")
    route1 = check_routing_logic(deepseek_config)
    assert route1 == 'deepseek', f"DeepSeek è·¯ç”±å¤±è´¥: {route1}"
    print("  âœ… deepseek-reasoner -> deepseek API")

    # æµ‹è¯• OpenAI è·¯ç”±
    print("\nğŸ§ª æµ‹è¯• OpenAI æ¨¡å‹è·¯ç”±...")
    route2 = check_routing_logic(openai_config)
    assert route2 == 'openai', f"OpenAI è·¯ç”±å¤±è´¥: {route2}"
    print("  âœ… gpt-4 -> openai API")

    # æµ‹è¯•å®é™…çš„ call_llm_api å‡½æ•°æ˜¯å¦åŒ…å«æ­£ç¡®çš„åˆ†æ”¯
    import inspect
    source = inspect.getsource(call_llm_api)
    assert 'elif provider == \'openai\' and is_deepseek_model:' in source, "DeepSeek åˆ†æ”¯ä¸å­˜åœ¨"
    assert 'https://api.deepseek.com/v1/chat/completions' in source, "DeepSeek URL ä¸å­˜åœ¨"

    print("âœ… API è·¯ç”±é€»è¾‘æµ‹è¯•é€šè¿‡")

    return True


def test_deepseek_config_parsing():
    """æµ‹è¯• DeepSeek é…ç½®è§£æ"""
    print("ğŸ”„ æµ‹è¯• DeepSeek é…ç½®è§£æ...")

    # æµ‹è¯•æ¨¡å‹è¯†åˆ«
    test_configs = [
        ('deepseek-reasoner', True),
        ('deepseek-chat', True),
        ('DeepSeek-V2', True),
        ('gpt-4', False),
        ('claude-3', False),
        ('gemini-pro', False),
    ]

    for model, expected_is_deepseek in test_configs:
        is_deepseek = 'deepseek' in model.lower()
        status = "âœ…" if is_deepseek == expected_is_deepseek else "âŒ"
        print(f"  {status} {model}: {is_deepseek} (æœŸæœ›: {expected_is_deepseek})")
        assert is_deepseek == expected_is_deepseek, f"æ¨¡å‹è¯†åˆ«å¤±è´¥: {model}"

    print("âœ… é…ç½®è§£ææµ‹è¯•é€šè¿‡")

    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ DeepSeek MCP ä¿®å¤æµ‹è¯•")
    print("=" * 60)

    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_deepseek_config_parsing()
        test_deepseek_api_routing()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ DeepSeek MCP ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ ä¿®å¤å†…å®¹:")
        print("  - âœ… æ·»åŠ  DeepSeek æ¨¡å‹è¯†åˆ«é€»è¾‘")
        print("  - âœ… å®ç° DeepSeek API è·¯ç”±")
        print("  - âœ… æ”¯æŒ provider=openai çš„ DeepSeek æ¨¡å‹")
        print("  - âœ… ä¿æŒå‘åå…¼å®¹æ€§")
        return 0

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())