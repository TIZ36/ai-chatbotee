"""
Google Gemini Provider

ÊîØÊåÅ Gemini Ê®°ÂûãÔºåÂåÖÊã¨ÂõæÁâáÁîüÊàê
‰ºòÂÖà‰ΩøÁî® google-genai SDKÔºåÂõûÈÄÄÂà∞ REST API
"""

from typing import List, Optional, Dict, Any, Generator
import json
import base64
import requests

from .base import BaseLLMProvider, LLMMessage, LLMResponse


class GoogleProvider(BaseLLMProvider):
    """Google Gemini Provider"""
    
    provider_type = "gemini"
    sdk_available = False
    
    def __init__(self, api_key: str, api_url: Optional[str] = None,
                 model: Optional[str] = None, **kwargs):
        self._client = None
        self._types = None
        self.use_thoughtsig = kwargs.get('use_thoughtsig', True)  # Á≠æÂêçÂºÄÂÖ≥ÔºåÈªòËÆ§ÂºÄÂêØ
        super().__init__(api_key, api_url, model, **kwargs)
    
    def _init_sdk(self):
        """ÂàùÂßãÂåñ Google GenAI SDK"""
        try:
            from google import genai
            from google.genai import types
            import os
            
            # ÊûÑÂª∫ http_options
            http_options = {'api_version': 'v1beta'}
            
            # 1. Ê£ÄÊü•ÊòØÂê¶ÈÖçÁΩÆ‰∫ÜËá™ÂÆö‰πâ API URLÔºàÂèçÂêë‰ª£ÁêÜÔºâ
            if self.api_url:
                base_url = self.api_url.rstrip('/')
                # Â¶ÇÊûú URL ÂåÖÂê´ /v1beta Êàñ /v1ÔºåÂéªÊéâÂÆÉÔºàSDK ‰ºöËá™Â∑±Âä†Ôºâ
                if '/v1beta' in base_url:
                    base_url = base_url.split('/v1beta')[0]
                elif '/v1' in base_url:
                    base_url = base_url.split('/v1')[0]
                
                http_options['base_url'] = base_url
                self._log(f"‚úÖ Using custom API URL (reverse proxy): {base_url}")
                print(f"[GEMINIProvider] ‚úÖ SDK ‰ΩøÁî®ÂèçÂêë‰ª£ÁêÜ: {base_url}")
            
            # 2. Ê£ÄÊü•Á≥ªÁªü‰ª£ÁêÜÁéØÂ¢ÉÂèòÈáèÔºàHTTP_PROXY / HTTPS_PROXYÔºâ
            http_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('HTTP_PROXY') or \
                         os.environ.get('https_proxy') or os.environ.get('http_proxy')
            
            if http_proxy:
                # ÈÖçÁΩÆ httpx ÂÆ¢Êà∑Á´Ø‰ΩøÁî®‰ª£ÁêÜ
                http_options['client_args'] = {
                    'proxy': http_proxy,
                    'timeout': 120.0,
                }
                self._log(f"‚úÖ Using system proxy: {http_proxy}")
                print(f"[GEMINIProvider] ‚úÖ SDK ‰ΩøÁî®Á≥ªÁªü‰ª£ÁêÜ: {http_proxy}")
            
            # 3. ÂàõÂª∫ Client
            if http_options.get('base_url') or http_options.get('client_args'):
                self._client = genai.Client(
                    api_key=self.api_key,
                    http_options=http_options
                )
                self._log("SDK initialized with custom http_options")
            else:
                # Êó†‰ª£ÁêÜÈÖçÁΩÆÔºåÁõ¥Êé•‰ΩøÁî®ÂÆòÊñπ API
                self._log("‚ö†Ô∏è No proxy configured, using official API directly")
                print("[GEMINIProvider] ‚ö†Ô∏è Êú™Ê£ÄÊµãÂà∞‰ª£ÁêÜÈÖçÁΩÆÔºåÁõ¥Êé•‰ΩøÁî®ÂÆòÊñπ API")
                print("[GEMINIProvider] üí° ÊèêÁ§∫ÔºöÂ¶ÇÈÅáÂú∞Âå∫ÈôêÂà∂ÔºåËØ∑ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè HTTPS_PROXY ÊàñÂú® LLM ÈÖçÁΩÆ‰∏≠ËÆæÁΩÆ api_url")
                self._client = genai.Client(api_key=self.api_key)
            
            self._types = types
            self.sdk_available = True
            self._log(f"SDK initialized successfully")
        except ImportError:
            self._log("google-genai SDK not installed, using REST API")
            self.sdk_available = False
        except Exception as e:
            self._log_error(f"Failed to initialize SDK: {e}")
            self.sdk_available = False
    
    def chat(self, messages: List[LLMMessage], **kwargs) -> LLMResponse:
        """ÈùûÊµÅÂºèËÅäÂ§©"""
        if self.sdk_available and self._client:
            return self._chat_sdk(messages, **kwargs)
        return self._chat_rest(messages, **kwargs)
    
    def chat_stream(self, messages: List[LLMMessage], **kwargs) -> Generator[str, None, LLMResponse]:
        """ÊµÅÂºèËÅäÂ§©"""
        # ÂõæÁâáÁîüÊàêÊ®°Âûã‰∏çÊîØÊåÅÊµÅÂºèÔºå‰ΩøÁî®ÈùûÊµÅÂºè
        if self._is_image_generation_model():
            self._log("Image generation model detected, using non-streaming")
            response = self.chat(messages, **kwargs)
            if response.content:
                yield response.content
            return response
        
        if self.sdk_available and self._client:
            yield from self._chat_stream_sdk(messages, **kwargs)
        else:
            yield from self._chat_stream_rest(messages, **kwargs)
    
    def _is_image_generation_model(self) -> bool:
        """Ê£ÄÊü•ÊòØÂê¶ÊòØÂõæÁâáÁîüÊàêÊ®°Âûã"""
        return self.model and 'image' in self.model.lower()

    def _requires_thought_signature_workaround(self) -> bool:
        """
        ÈÉ®ÂàÜ Gemini ÂõæÂÉè/Â§öÊ®°ÊÄÅÊ®°ÂûãÂú®‚ÄúÂõûÁÅåÂéÜÂè≤ model ËæìÂá∫‚ÄùÊó∂Ôºå‰ºöË¶ÅÊ±ÇÊØè‰∏™ part ÈÉΩÊê∫Â∏¶ thoughtSignatureÔºå
        ‰ΩÜÂéÜÂè≤Êï∞ÊçÆÈÄöÂ∏∏Ê≤°Êúâ‰øùÂ≠ò text part ÁöÑ thoughtSignatureÔºåÂØºËá¥ 400 INVALID_ARGUMENT„ÄÇ

        ËøôÈáåÂÅö‰∏Ä‰∏™‰øùÂÆàÁöÑÂÖºÂÆπÁ≠ñÁï•ÔºöÂΩì‰ΩøÁî®ÂõæÂÉèÁõ∏ÂÖ≥Ê®°ÂûãÊó∂ÔºåÊääÂéÜÂè≤ assistant/tool ÁöÑÊñáÊú¨ÈôçÁ∫ß‰∏∫ user role ÂèëÈÄÅÔºå
        ‰ª•ÈÅøÂÖçËß¶Âèë thoughtSignature Âº∫Ê†°È™åÔºåÂêåÊó∂‰∏çÂΩ±ÂìçÁî®Êà∑‰∏ä‰º†ÂõæÁâáÔºàÂõæÁîüÂõæÔºâ„ÄÇ
        """
        m = (self.model or '').lower()
        return ('image' in m) or ('image-preview' in m)
    
    def _chat_sdk(self, messages: List[LLMMessage], **kwargs) -> LLMResponse:
        """‰ΩøÁî® SDK ÁöÑÈùûÊµÅÂºèËÅäÂ§©"""
        try:
            contents, system_instruction = self._convert_messages_for_gemini_sdk(messages)
            
            # ÊûÑÂª∫ÈÖçÁΩÆ
            config = {}
            if system_instruction:
                config['system_instruction'] = system_instruction
            
            # ÂõæÁâáÁîüÊàêÊ®°ÂûãÈÖçÁΩÆ
            if self._is_image_generation_model():
                config['response_modalities'] = ['TEXT', 'IMAGE']
                self._log("Enabled response_modalities: ['TEXT', 'IMAGE']")
            
            self._log(f"Calling SDK: model={self.model}, contents={len(contents)}")
            
            # Ë∞ÉÁî® API
            response = self._client.models.generate_content(
                model=self.model or 'gemini-2.5-flash',
                contents=contents,
                config=self._types.GenerateContentConfig(**config) if config else None
            )
            
            # Ëß£ÊûêÂìçÂ∫î
            content = ""
            media = []
            
            if response.candidates:
                for candidate in response.candidates:
                    if candidate.content and candidate.content.parts:
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                content += part.text
                            elif hasattr(part, 'inline_data') and part.inline_data:
                                mime_type = part.inline_data.mime_type or 'image/png'
                                image_data = part.inline_data.data
                                if isinstance(image_data, bytes):
                                    data = base64.b64encode(image_data).decode('utf-8')
                                else:
                                    data = image_data

                                # ÊèêÂèñ thoughtSignatureÔºàGemini 2.5+Ôºâ
                                thought_sig = None
                                if hasattr(part, 'thought_signature') and part.thought_signature:
                                    thought_sig = part.thought_signature
                                    self._log(f"Found thoughtSignature in image: {len(thought_sig)} chars")

                                # ‰øùÂ≠òÂà∞ media ÂàóË°®ÔºàÂâçÁ´ØÁî®Áº©Áï•Âõæ/È¢ÑËßàÂ±ïÁ§∫Ôºå‰∏çÂÜçÂæÄ Markdown content ÈáåÂ°ûÂõæÔºâ
                                media_item = {
                                    'type': 'image',
                                    'mimeType': mime_type,
                                    'data': data
                                }
                                # ‰øùÂ≠ò thoughtSignatureÔºàÂ¶ÇÊûúÂ≠òÂú®ÔºâÔºå‰æõÂêéÁª≠ËØ∑Ê±Ç‰ΩøÁî®
                                if thought_sig:
                                    media_item['thoughtSignature'] = thought_sig
                                    self._log(f"‚úÖ ÂõæÁâáÂåÖÂê´ thoughtSignature ({len(thought_sig)} Â≠óÁ¨¶)")
                                else:
                                    self._log(f"‚ö†Ô∏è ÂõæÁâá‰∏çÂåÖÂê´ thoughtSignature")
                                media.append(media_item)
                                self._log(f"Received image: {mime_type} ({len(data)} chars)")
            
            return LLMResponse(
                content=content,
                media=media if media else None,
                finish_reason=response.candidates[0].finish_reason if response.candidates else None
            )
        except Exception as e:
            self._log_error(f"SDK chat error: {e}", e)
            detail = str(e) or repr(e)
            raise RuntimeError(f"Google API error: {detail}")
    
    def _chat_stream_sdk(self, messages: List[LLMMessage], **kwargs) -> Generator[str, None, LLMResponse]:
        """‰ΩøÁî® SDK ÁöÑÊµÅÂºèËÅäÂ§©"""
        try:
            contents, system_instruction = self._convert_messages_for_gemini_sdk(messages)
            
            # ÊûÑÂª∫ÈÖçÁΩÆ
            config = {}
            if system_instruction:
                config['system_instruction'] = system_instruction
            
            # ÂõæÁâáÁîüÊàêÊ®°ÂûãÈÖçÁΩÆ
            if self._is_image_generation_model():
                config['response_modalities'] = ['TEXT', 'IMAGE']
            
            self._log(f"Calling SDK stream: model={self.model}")
            
            # ÊµÅÂºèË∞ÉÁî®
            stream = self._client.models.generate_content_stream(
                model=self.model or 'gemini-2.5-flash',
                contents=contents,
                config=self._types.GenerateContentConfig(**config) if config else None
            )
            
            full_content = ""
            finish_reason = None
            media = []
            
            for chunk in stream:
                if chunk.candidates:
                    for candidate in chunk.candidates:
                        if candidate.content and candidate.content.parts:
                            for part in candidate.content.parts:
                                if hasattr(part, 'text') and part.text:
                                    full_content += part.text
                                    yield part.text
                                elif hasattr(part, 'inline_data') and part.inline_data:
                                    # ÊèêÂèñÂõæÁâáÊï∞ÊçÆ
                                    mime_type = part.inline_data.mime_type or 'image/png'
                                    image_data = part.inline_data.data
                                    if isinstance(image_data, bytes):
                                        data = base64.b64encode(image_data).decode('utf-8')
                                    else:
                                        data = image_data
                                    
                                    # ÊèêÂèñ thoughtSignatureÔºàGemini 2.5+Ôºâ
                                    thought_sig = None
                                    if hasattr(part, 'thought_signature') and part.thought_signature:
                                        thought_sig = part.thought_signature
                                        self._log(f"[Stream] Found thoughtSignature in image: {len(thought_sig)} chars")
                                    
                                    media_item = {
                                        'type': 'image',
                                        'mimeType': mime_type,
                                        'data': data
                                    }
                                    if thought_sig:
                                        media_item['thoughtSignature'] = thought_sig
                                        self._log(f"‚úÖ ÂõæÁâáÂåÖÂê´ thoughtSignature ({len(thought_sig)} Â≠óÁ¨¶)")
                                    else:
                                        self._log(f"‚ö†Ô∏è ÂõæÁâá‰∏çÂåÖÂê´ thoughtSignature")
                                    media.append(media_item)
                                    self._log(f"[Stream] Received image: {mime_type} ({len(data)} chars)")
                        if candidate.finish_reason:
                            finish_reason = candidate.finish_reason
            
            return LLMResponse(
                content=full_content,
                media=media if media else None,
                finish_reason=finish_reason
            )
        except Exception as e:
            self._log_error(f"SDK stream error: {e}", e)
            detail = str(e) or repr(e)
            raise RuntimeError(f"Google API error: {detail}")
    
    def _chat_rest(self, messages: List[LLMMessage], **kwargs) -> LLMResponse:
        """‰ΩøÁî® REST API ÁöÑÈùûÊµÅÂºèËÅäÂ§©"""
        url = self._get_api_url(stream=False)
        contents, system_instruction = self._convert_messages_for_gemini_rest(messages)
        
        payload = {'contents': contents}
        if system_instruction:
            # Gemini REST API ‰ΩøÁî® systemInstructionÔºàcamelCaseÔºâ
            payload['systemInstruction'] = system_instruction
        
        # ÂõæÁâáÁîüÊàêÊ®°ÂûãÈÖçÁΩÆ
        if self._is_image_generation_model():
            payload['generationConfig'] = {
                'responseModalities': ['TEXT', 'IMAGE']
            }
        
        self._log(f"Calling REST API: {url.split('?')[0]}...")
        
        response = requests.post(url, json=payload, timeout=120)
        
        if response.status_code != 200:
            error_text = self._parse_error_response(response)
            raise RuntimeError(f"Google API error: {error_text}")
        
        data = response.json()
        content = ""
        media = []
        
        candidates = data.get('candidates', [])
        for candidate in candidates:
            parts = candidate.get('content', {}).get('parts', [])
            for part in parts:
                if 'text' in part:
                    content += part['text']
                elif 'inlineData' in part:
                    media_item = {
                        'type': 'image',
                        'mimeType': part['inlineData'].get('mimeType', 'image/png'),
                        'data': part['inlineData'].get('data', '')
                    }
                    # ÊèêÂèñ thoughtSignatureÔºàGemini 2.5+Ôºâ- REST API Ê†ºÂºè
                    thought_sig = part.get('thoughtSignature')
                    if thought_sig:
                        media_item['thoughtSignature'] = thought_sig
                        self._log(f"[REST] Found thoughtSignature in image: {len(thought_sig)} chars")
                        self._log(f"‚úÖ ÂõæÁâáÂåÖÂê´ thoughtSignature ({len(thought_sig)} Â≠óÁ¨¶)")
                    else:
                        self._log(f"‚ö†Ô∏è ÂõæÁâá‰∏çÂåÖÂê´ thoughtSignature")
                    media.append(media_item)
        
        return LLMResponse(
            content=content,
            media=media if media else None,
            raw=data
        )
    
    def _chat_stream_rest(self, messages: List[LLMMessage], **kwargs) -> Generator[str, None, LLMResponse]:
        """‰ΩøÁî® REST API ÁöÑÊµÅÂºèËÅäÂ§©"""
        url = self._get_api_url(stream=True)
        contents, system_instruction = self._convert_messages_for_gemini_rest(messages)
        
        payload = {'contents': contents}
        if system_instruction:
            # Gemini REST API ‰ΩøÁî® systemInstructionÔºàcamelCaseÔºâ
            payload['systemInstruction'] = system_instruction
        
        response = requests.post(url, json=payload, stream=True, timeout=120)
        
        if response.status_code != 200:
            error_text = self._parse_error_response(response)
            raise RuntimeError(f"Google API error: {error_text}")
        
        full_content = ""
        finish_reason = None
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    try:
                        chunk = json.loads(line[6:])
                        candidates = chunk.get('candidates', [])
                        if candidates:
                            parts = candidates[0].get('content', {}).get('parts', [])
                            for part in parts:
                                if 'text' in part:
                                    text = part['text']
                                    full_content += text
                                    yield text
                            if candidates[0].get('finishReason'):
                                finish_reason = candidates[0]['finishReason']
                    except json.JSONDecodeError:
                        continue
        
        return LLMResponse(
            content=full_content,
            finish_reason=finish_reason
        )
    
    def _get_api_url(self, stream: bool = False) -> str:
        """Ëé∑Âèñ API URL"""
        model = self.model or 'gemini-2.5-flash'
        endpoint = 'streamGenerateContent?alt=sse' if stream else 'generateContent'
        
        if self.api_url:
            base = self.api_url.rstrip('/')
            url = f"{base}/models/{model}:{endpoint}"
        else:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:{endpoint}"
        
        # Ê∑ªÂä† API key
        separator = '&' if '?' in url else '?'
        url += f"{separator}key={self.api_key}"
        
        return url
    
    def _find_recent_thought_signature(self, messages: List[LLMMessage]) -> Optional[str]:
        """
        Êü•ÊâæÊúÄËøëÁöÑ LLM ËæìÂá∫ÁöÑÂ∏¶Êúâ thought signature ÁöÑÂõæÁâáÁöÑÁ≠æÂêç
        
        Args:
            messages: Ê∂àÊÅØÂàóË°®
            
        Returns:
            ÊúÄËøëÁöÑ thought signatureÔºåÂ¶ÇÊûúÊ≤°ÊâæÂà∞ËøîÂõû None
        """
        # ‰ªéÂêéÂæÄÂâçÊü•ÊâæÔºàÊúÄËøëÁöÑ‰ºòÂÖàÔºâ
        for msg in reversed(messages):
            if msg.role in ('assistant', 'model') and msg.media:
                for media_item in msg.media:
                    if isinstance(media_item, dict):
                        thought_sig = media_item.get('thoughtSignature') or media_item.get('thought_signature')
                        if thought_sig:
                            return thought_sig
        return None
    
    def _convert_messages_for_gemini_sdk(self, messages: List[LLMMessage]) -> tuple:
        """ËΩ¨Êç¢Ê∂àÊÅØÊ†ºÂºè‰∏∫ Gemini SDK Ê†ºÂºè"""
        contents = []
        system_instruction = None
        
        # Êü•ÊâæÊúÄËøëÁöÑ thought signatureÔºàÁî®‰∫éÁ≠æÂêçÂºÄÂÖ≥ÊâìÂºÄÊó∂ÁöÑÂèÇËÄÉÔºâ
        recent_thought_sig = self._find_recent_thought_signature(messages)
        if recent_thought_sig:
            self._log(f"ÊâæÂà∞ÊúÄËøëÁöÑ thoughtSignature ÂèÇËÄÉ: {len(recent_thought_sig)} Â≠óÁ¨¶")
        
        # È¢ÑÊ£ÄÊü•ÔºöÊâìÂç∞Âì™‰∫õÊ∂àÊÅØÂåÖÂê´ thoughtSignature
        self._log("=== ThoughtSignature Ê£ÄÊü• ===")
        content_idx = 0
        for i, msg in enumerate(messages):
            if msg.role == 'system':
                continue
            has_sig = False
            sig_count = 0
            if msg.media:
                for media_item in msg.media:
                    if isinstance(media_item, dict):
                        if media_item.get('thoughtSignature') or media_item.get('thought_signature'):
                            has_sig = True
                            sig_count += 1
            media_count = len(msg.media) if msg.media else 0
            status = f"‚úÖ {sig_count} sig" if has_sig else (f"‚ö†Ô∏è Êó†sig ({media_count}Âõæ)" if media_count > 0 else "")
            if media_count > 0:
                self._log(f"  Content[{content_idx}] {msg.role}: {media_count}Âº†Âõæ {status}")
            content_idx += 1
        self._log("=============================")
        
        for msg in messages:
            if msg.role == 'system':
                system_instruction = msg.content
            else:
                # ÂÖºÂÆπÔºöÂõæÂÉèÊ®°Âûã‰∏ãÂéÜÂè≤ assistant/tool ÊñáÊú¨ÂèØËÉΩË¶ÅÊ±Ç thoughtSignatureÔºàÊàë‰ª¨Ê≤°ÊúâÔºâÔºåÈôçÁ∫ß‰∏∫ user
                if msg.role == 'user':
                    role = 'user'
                else:
                    role = 'user' if self._requires_thought_signature_workaround() else 'model'
                parts = []
                
                # Ê∑ªÂä†ÊñáÊú¨
                if msg.content:
                    if role == 'user' and msg.role != 'user' and self._requires_thought_signature_workaround():
                        parts.append(self._types.Part.from_text(text=f"[ÂéÜÂè≤Âä©ÊâãÊ∂àÊÅØ] {msg.content}"))
                    else:
                        parts.append(self._types.Part.from_text(text=msg.content))
                
                # Ê∑ªÂä†Â™í‰Ωì
                if msg.media:
                    for media_item in msg.media:
                        if not isinstance(media_item, dict):
                            continue
                        
                        media_data = media_item.get('data') or media_item.get('url', '')
                        mime_type = media_item.get('mimeType') or media_item.get('mime_type', 'image/jpeg')
                        
                        # ËøêË°åÊó∂ÂÖúÂ∫ïÔºömedia_data ÂèØËÉΩÊòØ bytes/bytearrayÔºà‰ºöÂØºËá¥ÂêéÁª≠ JSON/Â§ÑÁêÜÂ§±Ë¥•Ôºâ
                        # - SDK Ë∑ØÂæÑÔºöÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®ÂéüÂßã bytes
                        if isinstance(media_data, (bytes, bytearray)):
                            image_bytes = bytes(media_data)
                            thought_sig = media_item.get('thoughtSignature') or media_item.get('thought_signature')
                            
                            # Â¶ÇÊûúÁ≠æÂêçÂºÄÂÖ≥ÊâìÂºÄ‰∏îÊ≤°ÊúâÁ≠æÂêçÔºåÂ∞ùËØï‰ΩøÁî®ÊúÄËøëÁöÑÁ≠æÂêç‰Ωú‰∏∫ÂèÇËÄÉ
                            if not thought_sig and self.use_thoughtsig and role != 'user' and recent_thought_sig:
                                thought_sig = recent_thought_sig
                                self._log(f"üîÑ ‰ΩøÁî®ÊúÄËøëÁöÑ thoughtSignature ‰Ωú‰∏∫ÂèÇËÄÉ ({len(thought_sig)} chars)")
                            
                            if thought_sig:
                                self._log(f"Including thoughtSignature for image ({len(thought_sig)} chars)")
                                parts.append(self._types.Part(
                                    inline_data=self._types.Blob(mime_type=mime_type, data=image_bytes),
                                    thought_signature=thought_sig
                                ))
                            else:
                                if role == 'user':
                                    parts.append(self._types.Part.from_bytes(data=image_bytes, mime_type=mime_type))
                                else:
                                    self._log("‚ö†Ô∏è Model image missing thoughtSignature, omitting image and adding placeholder text")
                                    parts.append(self._types.Part.from_text(
                                        text='[ÂõæÁâáÂ∑≤ÁúÅÁï•ÔºöÁº∫Â∞ë thoughtSignatureÔºàÊóßÂéÜÂè≤Êï∞ÊçÆÔºâÔºåÊó†Ê≥ïÂèëÈÄÅÁªô Gemini 2.5+]'
                                    ))
                            continue

                        # Â§ÑÁêÜ base64 Êï∞ÊçÆ
                        if isinstance(media_data, str):
                            if media_data.startswith('data:'):
                                if ';base64,' in media_data:
                                    media_data = media_data.split(';base64,', 1)[1]
                                elif ',' in media_data:
                                    media_data = media_data.split(',', 1)[1]
                            media_data = media_data.strip().replace('\n', '').replace('\r', '').replace(' ', '')
                        
                        if media_data and mime_type:
                            try:
                                image_bytes = base64.b64decode(media_data)
                                # Gemini 2.5+ÔºöÂ¶ÇÊûú‚ÄúÊääÊ®°ÂûãÁîüÊàêÁöÑÂõæÁâá‚ÄùÂÜçÂñÇÂõûÊ®°ÂûãÔºåÂøÖÈ°ªÂ∏¶ thought_signatureÔºõ
                                # ‰ΩÜ‚ÄúÁî®Êà∑‰∏ä‰º†ÁöÑÂõæÁâá‚ÄùÈÄöÂ∏∏Ê≤°Êúâ thought_signatureÔºå‰ªçÂ∫îÂÖÅËÆ∏Áî®‰∫éÂõæÁîüÂõæ„ÄÇ
                                thought_sig = media_item.get('thoughtSignature') or media_item.get('thought_signature')
                                
                                # Â¶ÇÊûúÁ≠æÂêçÂºÄÂÖ≥ÊâìÂºÄ‰∏îÊ≤°ÊúâÁ≠æÂêçÔºåÂ∞ùËØï‰ΩøÁî®ÊúÄËøëÁöÑÁ≠æÂêç‰Ωú‰∏∫ÂèÇËÄÉ
                                if not thought_sig and self.use_thoughtsig and role != 'user' and recent_thought_sig:
                                    thought_sig = recent_thought_sig
                                    self._log(f"üîÑ ‰ΩøÁî®ÊúÄËøëÁöÑ thoughtSignature ‰Ωú‰∏∫ÂèÇËÄÉ ({len(thought_sig)} chars)")
                                
                                if thought_sig:
                                    # ‰ΩøÁî® SDK ÂéüÁîü thought_signature ÊîØÊåÅ
                                    self._log(f"Including thoughtSignature for image ({len(thought_sig)} chars)")
                                    parts.append(self._types.Part(
                                        inline_data=self._types.Blob(mime_type=mime_type, data=image_bytes),
                                        thought_signature=thought_sig
                                    ))
                                else:
                                    if role == 'user':
                                        # Áî®Êà∑ÂõæÁâáÔºöÂÖÅËÆ∏Êó† thoughtSignatureÔºàÁî®‰∫éÂõæÁîüÂõæÔºâ
                                        parts.append(self._types.Part.from_bytes(data=image_bytes, mime_type=mime_type))
                                    else:
                                        # assistant/model ÂõæÁâáÔºöÊó† thoughtSignature ‰ºöËß¶Âèë 400ÔºåÈôçÁ∫ß‰∏∫ÊñáÊú¨Âç†‰Ωç
                                        self._log("‚ö†Ô∏è Model image missing thoughtSignature, omitting image and adding placeholder text")
                                        parts.append(self._types.Part.from_text(
                                            text='[ÂõæÁâáÂ∑≤ÁúÅÁï•ÔºöÁº∫Â∞ë thoughtSignatureÔºàÊóßÂéÜÂè≤Êï∞ÊçÆÔºâÔºåÊó†Ê≥ïÂèëÈÄÅÁªô Gemini 2.5+]'
                                        ))
                            except Exception as e:
                                self._log_error(f"Failed to decode image: {e}")
                
                if parts:
                    contents.append(self._types.Content(role=role, parts=parts))
        
        return contents, system_instruction
    
    def _convert_messages_for_gemini_rest(self, messages: List[LLMMessage]) -> tuple:
        """ËΩ¨Êç¢Ê∂àÊÅØÊ†ºÂºè‰∏∫ Gemini REST API Ê†ºÂºè"""
        contents = []
        system_instruction = None
        
        # Êü•ÊâæÊúÄËøëÁöÑ thought signatureÔºàÁî®‰∫éÁ≠æÂêçÂºÄÂÖ≥ÊâìÂºÄÊó∂ÁöÑÂèÇËÄÉÔºâ
        recent_thought_sig = self._find_recent_thought_signature(messages)
        if recent_thought_sig:
            self._log(f"ÊâæÂà∞ÊúÄËøëÁöÑ thoughtSignature ÂèÇËÄÉ: {len(recent_thought_sig)} Â≠óÁ¨¶")
        
        # È¢ÑÊ£ÄÊü•ÔºöÊâìÂç∞Âì™‰∫õÊ∂àÊÅØÂåÖÂê´ thoughtSignature
        self._log("=== ThoughtSignature Ê£ÄÊü• (REST) ===")
        content_idx = 0
        for i, msg in enumerate(messages):
            if msg.role == 'system':
                continue
            has_sig = False
            sig_count = 0
            if msg.media:
                for media_item in msg.media:
                    if isinstance(media_item, dict):
                        if media_item.get('thoughtSignature') or media_item.get('thought_signature'):
                            has_sig = True
                            sig_count += 1
            media_count = len(msg.media) if msg.media else 0
            status = f"‚úÖ {sig_count} sig" if has_sig else (f"‚ö†Ô∏è Êó†sig ({media_count}Âõæ)" if media_count > 0 else "")
            if media_count > 0:
                self._log(f"  Content[{content_idx}] {msg.role}: {media_count}Âº†Âõæ {status}")
            content_idx += 1
        self._log("=====================================")
        
        for msg in messages:
            if msg.role == 'system':
                system_instruction = {'parts': [{'text': msg.content}]}
            else:
                # ÂÖºÂÆπÔºöÂõæÂÉèÊ®°Âûã‰∏ãÂéÜÂè≤ assistant/tool ÊñáÊú¨ÂèØËÉΩË¶ÅÊ±Ç thoughtSignatureÔºàÊàë‰ª¨Ê≤°ÊúâÔºâÔºåÈôçÁ∫ß‰∏∫ user
                if msg.role == 'user':
                    role = 'user'
                else:
                    role = 'user' if self._requires_thought_signature_workaround() else 'model'
                parts = []
                
                if msg.content:
                    if role == 'user' and msg.role != 'user' and self._requires_thought_signature_workaround():
                        parts.append({'text': f"[ÂéÜÂè≤Âä©ÊâãÊ∂àÊÅØ] {msg.content}"})
                    else:
                        parts.append({'text': msg.content})
                
                if msg.media:
                    for media_item in msg.media:
                        if not isinstance(media_item, dict):
                            continue
                        
                        media_data = media_item.get('data') or media_item.get('url', '')
                        mime_type = media_item.get('mimeType') or media_item.get('mime_type', 'image/jpeg')
                        
                        # ËøêË°åÊó∂ÂÖúÂ∫ïÔºöREST payload ÂøÖÈ°ªÊòØ JSONÔºåÂèØÂ∫èÂàóÂåñÔºõbytes/bytearray ÂøÖÈ°ªËΩ¨ base64 Â≠óÁ¨¶‰∏≤
                        if isinstance(media_data, (bytes, bytearray)):
                            media_data = base64.b64encode(bytes(media_data)).decode('utf-8')

                        if isinstance(media_data, str):
                            if media_data.startswith('data:'):
                                if ';base64,' in media_data:
                                    media_data = media_data.split(';base64,', 1)[1]
                                elif ',' in media_data:
                                    media_data = media_data.split(',', 1)[1]
                            media_data = media_data.strip().replace('\n', '').replace('\r', '').replace(' ', '')
                        
                        if media_data and mime_type:
                            # Gemini 2.5+ÔºöÊ®°ÂûãÁîüÊàêÁöÑÂõæÁâáÂõûÁÅåÂøÖÈ°ªÂ∏¶ thoughtSignatureÔºõÁî®Êà∑‰∏ä‰º†ÂõæÁâáÂèØÊó†Á≠æÂêçÁî®‰∫éÂõæÁîüÂõæ„ÄÇ
                            thought_sig = media_item.get('thoughtSignature') or media_item.get('thought_signature')
                            
                            # Â¶ÇÊûúÁ≠æÂêçÂºÄÂÖ≥ÊâìÂºÄ‰∏îÊ≤°ÊúâÁ≠æÂêçÔºåÂ∞ùËØï‰ΩøÁî®ÊúÄËøëÁöÑÁ≠æÂêç‰Ωú‰∏∫ÂèÇËÄÉ
                            if not thought_sig and self.use_thoughtsig and role != 'user' and recent_thought_sig:
                                thought_sig = recent_thought_sig
                                self._log(f"üîÑ ‰ΩøÁî®ÊúÄËøëÁöÑ thoughtSignature ‰Ωú‰∏∫ÂèÇËÄÉ ({len(thought_sig)} chars)")
                            
                            if thought_sig:
                                part_data = {
                                    'inlineData': {
                                        'mimeType': mime_type,
                                        'data': media_data
                                    },
                                    'thoughtSignature': thought_sig
                                }
                                self._log(f"Including thoughtSignature for image ({len(thought_sig)} chars)")
                                parts.append(part_data)
                            else:
                                if role == 'user':
                                    # Áî®Êà∑ÂõæÁâáÔºöÂÖÅËÆ∏Êó† thoughtSignatureÔºàÁî®‰∫éÂõæÁîüÂõæÔºâ
                                    parts.append({
                                        'inlineData': {
                                            'mimeType': mime_type,
                                            'data': media_data
                                        }
                                    })
                                else:
                                    # assistant/model ÂõæÁâáÔºöÊó† thoughtSignature ‰ºöËß¶Âèë 400ÔºåÈôçÁ∫ß‰∏∫ÊñáÊú¨Âç†‰Ωç
                                    self._log("‚ö†Ô∏è Model image missing thoughtSignature, omitting image and adding placeholder text")
                                    parts.append({'text': '[ÂõæÁâáÂ∑≤ÁúÅÁï•ÔºöÁº∫Â∞ë thoughtSignatureÔºàÊóßÂéÜÂè≤Êï∞ÊçÆÔºâÔºåÊó†Ê≥ïÂèëÈÄÅÁªô Gemini 2.5+]'})
                
                if parts:
                    contents.append({'role': role, 'parts': parts})
        
        return contents, system_instruction
    
    def _parse_error_response(self, response) -> str:
        """Ëß£ÊûêÈîôËØØÂìçÂ∫î"""
        try:
            error_data = response.json()
            msg = (error_data.get('error', {}) or {}).get('message', '')
            if msg:
                return msg
            if response.text:
                return response.text
            return f"HTTP {response.status_code}"
        except:
            return response.text or f"HTTP {response.status_code}"
    
    def models(self) -> List[str]:
        """
        Ëé∑ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®
        ‰ºòÂÖà‰ΩøÁî® SDKÔºåÂõûÈÄÄÂà∞ REST API
        """
        try:
            # ‰ºòÂÖà‰ΩøÁî® SDK
            if self.sdk_available and self._client:
                try:
                    # Google GenAI SDK ÂèØËÉΩÊ≤°ÊúâÁõ¥Êé•ÁöÑ models.list() ÊñπÊ≥ï
                    # Â∞ùËØï‰ΩøÁî® REST API
                    pass
                except Exception as e:
                    self._log(f"SDK models() not available: {e}, using REST API")
            
            # ‰ΩøÁî® REST API
            # Gemini API: https://generativelanguage.googleapis.com/v1beta/models?key=API_KEY
            base_url = self.api_url or 'https://generativelanguage.googleapis.com'
            if '/v1beta' not in base_url and '/v1' not in base_url:
                base_url = f"{base_url.rstrip('/')}/v1beta"
            elif base_url.endswith('/v1'):
                base_url = base_url.replace('/v1', '/v1beta')
            
            models_url = f"{base_url}/models"
            params = {'key': self.api_key}
            
            self._log(f"Fetching models via REST API: {models_url}")
            response = requests.get(models_url, params=params, timeout=10)
            
            if response.status_code != 200:
                raise RuntimeError(f"Failed to fetch models: {response.status_code} {response.text}")
            
            data = response.json()
            # Gemini ËøîÂõûÊ†ºÂºèÔºö{ models: [{ name: "...", ... }] }
            if isinstance(data, dict) and isinstance(data.get('models'), list):
                model_names = [model.get('name') for model in data['models'] if model.get('name')]
                # ÊèêÂèñÊ®°Âûã IDÔºà‰ªéÂÆåÊï¥ÂêçÁß∞‰∏≠ÔºåÂ¶Ç "models/gemini-2.0-flash-exp" -> "gemini-2.0-flash-exp"Ôºâ
                model_ids = []
                for name in model_names:
                    if '/' in name:
                        model_ids.append(name.split('/')[-1])
                    else:
                        model_ids.append(name)
                self._log(f"Fetched {len(model_ids)} models via REST API")
                return model_ids
            
            # ÂÖºÂÆπÂÖ∂‰ªñÊ†ºÂºè
            if isinstance(data, list):
                model_ids = [item.get('name') if isinstance(item, dict) else item for item in data if item]
                # ÊèêÂèñÊ®°Âûã ID
                extracted_ids = []
                for name in model_ids:
                    if isinstance(name, str) and '/' in name:
                        extracted_ids.append(name.split('/')[-1])
                    elif name:
                        extracted_ids.append(name)
                self._log(f"Fetched {len(extracted_ids)} models via REST API (array format)")
                return extracted_ids
            
            raise RuntimeError("Invalid response format from models API")
            
        except Exception as e:
            self._log_error(f"Failed to fetch models: {e}", e)
            raise
