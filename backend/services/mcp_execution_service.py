"""
MCP æ‰§è¡ŒæœåŠ¡ï¼ˆä¾› AgentActor/æ¥å£å¤ç”¨ï¼‰

ç›®æ ‡ï¼š
- ç»™å®š mcp_server_id + ç”¨æˆ·è¾“å…¥ + llm_config_id
- å…ˆè·å– MCP tools åˆ—è¡¨
- ç”¨ LLM äº§å‡º tool_calls JSON
- æ‰§è¡Œ tool_calls å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ + logs

æ³¨æ„ï¼šè¿™é‡Œä¸ä¾èµ– Flask app.pyï¼Œé¿å…å¾ªç¯å¯¼å…¥ã€‚
ä½¿ç”¨ mcp_common_logic æ¨¡å—ç›´æ¥è°ƒç”¨ MCPï¼ˆç±»ä¼¼ ok-publish åˆ†æ”¯ï¼‰ã€‚
"""

from __future__ import annotations

import json
import re
from datetime import datetime
from typing import Any, Dict, List, Optional

import requests

from database import get_mysql_connection
from mcp_server.mcp_common_logic import get_mcp_tools_list, call_mcp_tool, prepare_mcp_headers, initialize_mcp_session
import pymysql


def _mk_logger(external_log: Optional[callable] = None) -> tuple[list[str], callable]:
    logs: list[str] = []

    def add_log(message: str):
        line = f"[{datetime.now().strftime('%H:%M:%S')}] {message}"
        logs.append(line)
        if external_log:
            try:
                external_log(line)
            except Exception:
                pass

    return logs, add_log


def _truncate_deep(obj: Any, *, max_str: int = 2000) -> Any:
    """é¿å…æŠŠè¶…å¤§ç»“æœï¼ˆå°¤å…¶ base64ï¼‰å¡è¿› processSteps/system prompt"""
    if obj is None:
        return None
    if isinstance(obj, str):
        s = obj
        if len(s) > max_str:
            return s[:max_str] + f"...[truncated:{len(s)}]"
        return s
    if isinstance(obj, (int, float, bool)):
        return obj
    if isinstance(obj, list):
        return [_truncate_deep(x, max_str=max_str) for x in obj[:200]]
    if isinstance(obj, dict):
        out: Dict[str, Any] = {}
        for k, v in list(obj.items())[:200]:
            # å¸¸è§å­—æ®µï¼šdata/base64ï¼Œå•ç‹¬æ›´ä¸¥æ ¼ä¸€ç‚¹
            if k in ("data", "image", "base64", "payload") and isinstance(v, str) and len(v) > 512:
                out[k] = v[:256] + f"...[truncated:{len(v)}]"
            else:
                out[k] = _truncate_deep(v, max_str=max_str)
        return out
    return str(obj)


def call_llm_api(llm_config: dict, system_prompt: str, user_input: str, add_log=None):
    """
    è°ƒç”¨LLM APIï¼ˆç±»ä¼¼ ok-publish åˆ†æ”¯çš„å®ç°ï¼‰
    ç›´æ¥è°ƒç”¨ APIï¼Œä¸é€šè¿‡ llm_service
    """
    if add_log:
        add_log(f"ğŸ”„ è°ƒç”¨LLM API: {llm_config.get('provider', 'unknown')} - {llm_config.get('model', 'unknown')}")
        add_log(f"ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}, ç”¨æˆ·è¾“å…¥é•¿åº¦: {len(user_input)}")
        add_log(f"LLMé…ç½®è¯¦æƒ…: provider={llm_config.get('provider')}, model={llm_config.get('model')}, api_url={llm_config.get('api_url', 'é»˜è®¤')}, has_api_key={bool(llm_config.get('api_key'))}")

    provider = llm_config.get('provider', '')
    api_key = llm_config.get('api_key', '')
    api_url = llm_config.get('api_url', '')
    model = llm_config.get('model', '')

    # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥å¿…è¦å‚æ•°
    if not provider:
        if add_log:
            add_log("âŒ LLMé…ç½®ä¸­ç¼ºå°‘providerå­—æ®µ")
        return None

    if not api_key:
        if add_log:
            add_log(f"âŒ APIå¯†é’¥ä¸ºç©º (provider: {provider})")
        return None

    if not model:
        if add_log:
            add_log(f"âŒ æ¨¡å‹åç§°ä¸ºç©º (provider: {provider})")
        return None
    
    if provider == 'openai':
        default_url = 'https://api.openai.com/v1/chat/completions'
        url = api_url or default_url
        
        payload = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_input}
            ],
            # å·¥å…·é€‰æ‹©/ç»“æ„åŒ–è¾“å‡ºï¼šå°½é‡ç¨³å®š
            'temperature': 0.1,
        }
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        if response.ok:
            data = response.json()
            content = data['choices'][0]['message']['content']
            if add_log:
                add_log(f"âœ… OpenAI APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
            return content
        else:
            if add_log:
                add_log(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text[:200]}...")
            return None
            
    elif provider == 'anthropic':
        default_url = 'https://api.anthropic.com/v1/messages'
        url = api_url or default_url
        
        payload = {
            'model': model,
            'max_tokens': 4096,
            'messages': [
                {'role': 'user', 'content': f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥: {user_input}"}
            ],
        }
        
        headers = {
            'x-api-key': api_key,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json',
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        if response.ok:
            data = response.json()
            content = data['content'][0]['text']
            if add_log:
                add_log(f"âœ… Anthropic APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
            return content
        else:
            if add_log:
                add_log(f"âŒ Anthropic APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text[:200]}...")
            return None
            
    elif provider == 'gemini':
        default_url = 'https://generativelanguage.googleapis.com/v1beta'
        base_url = api_url or default_url
        model_name = model or 'gemini-2.5-flash'
        
        # æ„å»ºå®Œæ•´çš„ API URL
        if base_url.endswith('/'):
            url = f"{base_url}models/{model_name}:generateContent"
        else:
            url = f"{base_url}/models/{model_name}:generateContent"
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Gemini æ ¼å¼
        contents = [
            {
                'role': 'user',
                'parts': [{'text': f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥: {user_input}"}]
            }
        ]
        
        payload = {
            'contents': contents,
            'generationConfig': {
                # å·¥å…·é€‰æ‹©/ç»“æ„åŒ–è¾“å‡ºï¼šå°½é‡ç¨³å®š
                'temperature': 0.1,
            },
        }
        
        # åªåœ¨metadataä¸­æ˜ç¡®æŒ‡å®šthinking_levelæ—¶æ‰æ·»åŠ ï¼ˆæŸäº›æ¨¡å‹ä¸æ”¯æŒæ­¤å­—æ®µï¼‰
        if llm_config.get('metadata') and llm_config['metadata'].get('thinking_level'):
            payload['generationConfig']['thinkingLevel'] = llm_config['metadata']['thinking_level']
        
        headers = {
            'x-goog-api-key': api_key,
            'Content-Type': 'application/json',
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        if response.ok:
            data = response.json()
            if data.get('candidates') and len(data['candidates']) > 0:
                candidate = data['candidates'][0]
                if candidate.get('content') and candidate['content'].get('parts'):
                    # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                    text_parts = [part.get('text', '') for part in candidate['content']['parts'] if part.get('text')]
                    content = ''.join(text_parts)
                    if add_log:
                        add_log(f"âœ… Gemini APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                    return content
            if add_log:
                add_log("âŒ Gemini APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
            return None
        else:
            if add_log:
                try:
                    error_data = response.json() if response.content else {}
                    error_msg = error_data.get('error', {}).get('message', response.text)
                except:
                    error_msg = response.text[:200]
                add_log(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {response.status_code} - {error_msg}")
            return None
    else:
        if add_log:
            add_log(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        return None


def execute_mcp_with_llm(
    *,
    mcp_server_id: str,
    input_text: str,
    llm_config_id: str,
    add_log: Optional[callable] = None,
    max_iterations: int = 3,
    topic_id: Optional[str] = None,
    existing_session_id: Optional[str] = None,
    agent_system_prompt: Optional[str] = None,  # Agent çš„äººè®¾/ç³»ç»Ÿæç¤ºè¯
) -> Dict[str, Any]:
    """
    æ‰§è¡Œ MCPï¼šç”± LLM å†³å®š tool_callsï¼Œç„¶åé€ä¸ªè°ƒç”¨ MCP toolã€‚
    
    Args:
        agent_system_prompt: Agent çš„äººè®¾ï¼Œä¼šä½œä¸ºç³»ç»Ÿæç¤ºè¯çš„ä¸€éƒ¨åˆ†

    Returns:
      {
        "summary": str | None,
        "raw_result": dict | None,
        "logs": list[str],
        "error": str | None,
        "llm_response": str | None,
      }
    """
    # ANSI é¢œè‰²ç 
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    MAGENTA = '\033[95m'
    RESET = '\033[0m'
    BOLD = '\033[1m'
    
    print(f"{MAGENTA}{BOLD}[MCP EXEC] ========== execute_mcp_with_llm å¼€å§‹ =========={RESET}")
    print(f"{MAGENTA}[MCP EXEC] Server: {mcp_server_id}, LLM: {llm_config_id}{RESET}")
    print(f"{MAGENTA}[MCP EXEC] Input é•¿åº¦: {len(input_text) if input_text else 0} å­—ç¬¦{RESET}")
    
    logs, log = _mk_logger(add_log)

    try:
        # å»æ‰ AgentActor æ³¨å…¥çš„â€œå·¥å…·ä½¿ç”¨æƒæç¤ºâ€ï¼Œé¿å…æ±¡æŸ“ LLM å†³ç­–è¾“å…¥
        effective_input = re.sub(r"^\[ä½ å·²è·å¾—å·¥å…·ä½¿ç”¨æƒï¼š.*?\]\s*", "", input_text or "").strip()
        if not effective_input:
            effective_input = input_text or ""

        conn = get_mysql_connection()
        if not conn:
            return {"error": "MySQL not available", "logs": logs}

        cursor = None
        try:
            import pymysql

            cursor = conn.cursor(pymysql.cursors.DictCursor)

            # è·å–LLMé…ç½®ï¼ˆåŒ…æ‹¬åŠ å¯†çš„API keyï¼‰
            log(f"è·å–LLMé…ç½®: {llm_config_id}")
            cursor.execute(
                """
                SELECT config_id, provider, api_key, api_url, model, enabled, metadata
                FROM llm_configs
                WHERE config_id = %s AND enabled = 1
                """,
                (llm_config_id,),
            )
            llm_config = cursor.fetchone()

            if not llm_config:
                log(f"âŒ LLMé…ç½®ä¸å­˜åœ¨æˆ–å·²ç¦ç”¨: {llm_config_id}")
                # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰å…¶ä»–å¯ç”¨çš„é…ç½®
                cursor.execute("SELECT config_id, provider, model, enabled FROM llm_configs")
                all_configs = cursor.fetchall()
                log(f"æ•°æ®åº“ä¸­çš„æ‰€æœ‰LLMé…ç½®: {[(c['config_id'], c['provider'], c['model'], c['enabled']) for c in all_configs]}")
                return {"error": "LLM config not found or disabled", "logs": logs}

            # è§£æ metadataï¼ˆå¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
            if llm_config.get('metadata') and isinstance(llm_config['metadata'], str):
                try:
                    llm_config['metadata'] = json.loads(llm_config['metadata'])
                except Exception as e:
                    log(f"âš ï¸ LLMé…ç½®metadataè§£æå¤±è´¥: {e}")
                    llm_config['metadata'] = {}

            log(f"âœ… LLMé…ç½®è·å–æˆåŠŸ: {llm_config['provider']} - {llm_config['model']}")
            log(f"   é…ç½®ID: {llm_config['config_id']}")
            log(f"   API URL: {llm_config.get('api_url', 'é»˜è®¤')}")
            log(f"   API Key: {'å·²è®¾ç½®' if llm_config.get('api_key') else 'âŒ æœªè®¾ç½®'}")
            log(f"   Metadata: {llm_config.get('metadata', {})}")

            # éªŒè¯LLMé…ç½®çš„å®Œæ•´æ€§
            missing_fields = []
            if not llm_config.get('provider'):
                missing_fields.append('provider')
            if not llm_config.get('model'):
                missing_fields.append('model')
            if not llm_config.get('api_key'):
                missing_fields.append('api_key')

            if missing_fields:
                error_msg = f"LLMé…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}"
                log(f"âŒ {error_msg}")
                return {"error": error_msg, "logs": logs}

            # MCP server
            log(f"è·å–MCPæœåŠ¡å™¨é…ç½®: {mcp_server_id}")
            cursor.execute(
                """
                SELECT server_id, name, url, enabled
                FROM mcp_servers
                WHERE server_id = %s AND enabled = 1
                """,
                (mcp_server_id,),
            )
            mcp_server = cursor.fetchone()
            if not mcp_server:
                return {"error": "MCP server not found or disabled", "logs": logs}

            server_name = mcp_server.get("name") or mcp_server_id
            server_url = mcp_server.get("url")
            log(f"MCPæœåŠ¡å™¨é…ç½®è·å–æˆåŠŸ: {server_name} ({server_url})")

            # ==================== ä½¿ç”¨ mcp_common_logic ç›´æ¥è°ƒç”¨ MCPï¼ˆç±»ä¼¼ ok-publishï¼‰ ====================
            # 1. å‡†å¤‡è¯·æ±‚å¤´ï¼ˆåŒ…æ‹¬ OAuth token ç­‰ï¼‰
            base_headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json, text/event-stream',
                'mcp-protocol-version': '2025-06-18',
            }
            headers = prepare_mcp_headers(server_url, base_headers, base_headers)
            
            # 1.5 å¦‚æœæœ‰ existing_session_idï¼Œå¤ç”¨å·²æœ‰ä¼šè¯ï¼ˆé‡è¦ï¼šæŸäº› MCP æœåŠ¡å™¨è¦æ±‚ä¿æŒä¼šè¯è¿ç»­æ€§ï¼‰
            if existing_session_id:
                headers['mcp-session-id'] = existing_session_id
                log(f"å¤ç”¨å·²æœ‰ MCP session: {existing_session_id[:16]}...")
            
            # 2. åˆå§‹åŒ– MCP ä¼šè¯ï¼ˆä»…å½“æ²¡æœ‰ session_id æ—¶ï¼‰
            if 'mcp-session-id' not in headers:
                init_response = initialize_mcp_session(server_url, headers)
                if not init_response:
                    log("âš ï¸ MCP initialize å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•è·å–å·¥å…·åˆ—è¡¨")
                else:
                    log(f"MCP ä¼šè¯åˆå§‹åŒ–æˆåŠŸï¼Œsession_id: {headers.get('mcp-session-id', 'N/A')[:16]}...")
            else:
                log(f"è·³è¿‡ MCP ä¼šè¯åˆå§‹åŒ–ï¼Œä½¿ç”¨å·²æœ‰ session_id")
            
            # 3. è·å–å·¥å…·åˆ—è¡¨
            log("Step 2/3: tools/list")
            # Actor åœºæ™¯ä¼˜å…ˆä¸èµ°ç¼“å­˜ï¼šé¿å… tools/list çš„çŸ­æœŸç¼“å­˜æ©ç›– session-id/æƒé™å˜æ›´
            tools_response = get_mcp_tools_list(server_url, headers, use_cache=False)
            if not tools_response or 'result' not in tools_response:
                return {
                    "error": "Failed to get MCP tools list",
                    "logs": logs,
                    "debug": {
                        "server_url": server_url,
                        "mcp_session_id": headers.get("mcp-session-id"),
                        "tools_response_preview": _truncate_deep(tools_response, max_str=1200),
                    },
                }

            tools = tools_response['result'].get('tools', [])
            if not tools:
                return {
                    "error": "No tools available from MCP server",
                    "logs": logs,
                }

            log(f"è·å–åˆ° {len(tools)} ä¸ªå¯ç”¨å·¥å…·")
            print(f"{GREEN}[MCP EXEC] âœ… è·å–åˆ° {len(tools)} ä¸ªå·¥å…·{RESET}")
            # è¯¦ç»†æ—¥å¿—ï¼šæ˜¾ç¤ºæ‰€æœ‰å·¥å…·åˆ—è¡¨
            all_tool_names = [t.get('name', 'unnamed') for t in tools]
            log(f"  å¯ç”¨å·¥å…·: {', '.join(all_tool_names)}")
            print(f"{CYAN}[MCP EXEC] æ‰€æœ‰å·¥å…·: {', '.join(all_tool_names)}{RESET}")
            
            # æ‰“å°å½“å‰ session_id çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
            current_session_id = headers.get('mcp-session-id')
            if current_session_id:
                log(f"  å½“å‰ MCP Session ID: {current_session_id[:16]}...")
            else:
                log(f"  âš ï¸ è­¦å‘Šï¼šæ—  MCP Session IDï¼ˆæŸäº›æœåŠ¡å™¨å¯èƒ½è¦æ±‚ï¼‰")

            # æ„å»ºå·¥å…·æè¿°ï¼ˆåŒ…å«å®Œæ•´çš„å‚æ•° schemaï¼‰
            def _format_tool_params(schema: Dict[str, Any]) -> str:
                """æ ¼å¼åŒ–å·¥å…·å‚æ•°ä¸ºæ˜“è¯»çš„æè¿°"""
                if not schema or not isinstance(schema, dict):
                    return "  å‚æ•°: æ— "
                
                props = schema.get("properties", {})
                required = schema.get("required", [])
                
                if not props:
                    return "  å‚æ•°: æ— "
                
                lines = []
                for param_name, param_info in props.items():
                    param_type = param_info.get("type", "string")
                    param_desc = param_info.get("description", "")
                    is_required = param_name in required
                    req_mark = "*å¿…éœ€*" if is_required else "å¯é€‰"
                    lines.append(f"    - {param_name} ({param_type}, {req_mark}): {param_desc}")
                
                return "  å‚æ•°:\n" + "\n".join(lines)
            
            tools_description_parts = []
            for t in tools:
                name = t.get('name', '')
                desc = t.get('description', '')
                schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                params_desc = _format_tool_params(schema)
                tools_description_parts.append(f"ã€{name}ã€‘\n  æè¿°: {desc}\n{params_desc}")
            
            tools_description = '\n\n'.join(tools_description_parts)
            
            # æ„å»ºå·¥å…·åç§°æ˜ å°„ï¼ˆç”¨äºéªŒè¯ï¼‰
            tool_name_map: Dict[str, Dict[str, Any]] = {}
            for t in tools:
                tool_name = t.get('name', '').strip()
                if tool_name:
                    schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                    props = {}
                    required = []
                    if isinstance(schema, dict):
                        props = schema.get("properties") or {}
                        required = schema.get("required") or []
                    tool_name_map[tool_name.lower()] = {
                        'name': tool_name,
                        'description': t.get('description', '').strip(),
                        'schema': schema,
                        'props': props if isinstance(props, dict) else {},
                        'required': required if isinstance(required, list) else [],
                    }

            # ç³»ç»Ÿæç¤ºè¯ï¼šAgent äººè®¾ + å·¥å…·è°ƒåº¦åŸåˆ™
            system_prompt_parts = []
            
            # 1. Agent çš„äººè®¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if agent_system_prompt:
                system_prompt_parts.append(agent_system_prompt)
                system_prompt_parts.append("")  # ç©ºè¡Œåˆ†éš”
            
            # 2. å·¥å…·è°ƒåº¦åŸåˆ™
            system_prompt_parts.append("""## å·¥å…·è°ƒåº¦èƒ½åŠ›

ä½ å¯ä»¥ä½¿ç”¨å·¥å…·æ¥å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œä»å¯ç”¨å·¥å…·ä¸­é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·å¹¶è°ƒç”¨ã€‚

### âš ï¸ é‡è¦ï¼šè¿”å›æ ¼å¼è¦æ±‚

**ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€è§£é‡Šæˆ–markdownä»£ç å—ã€‚**

å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œåªè¿”å›è¿™ä¸ªJSONæ ¼å¼ï¼š
```json
{
  "tool_calls": [
    {
      "name": "å·¥å…·åç§°ï¼ˆå¿…é¡»å®Œå…¨åŒ¹é…å¯ç”¨å·¥å…·ä¸­çš„åç§°ï¼‰",
      "arguments": {"å‚æ•°å": "å‚æ•°å€¼", "å¿…éœ€å‚æ•°2": "å€¼2"}
    }
  ],
  "done": true
}
```

å¦‚æœä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œåªè¿”å›ï¼š
```json
{
  "tool_calls": [],
  "done": true
}
```

**ç¤ºä¾‹ï¼š**
- è°ƒç”¨ search_feeds å·¥å…·ï¼š`{"tool_calls": [{"name": "search_feeds", "arguments": {"query": "å…³é”®è¯"}}], "done": true}`
- è°ƒç”¨ get_feed_detail å·¥å…·ï¼š`{"tool_calls": [{"name": "get_feed_detail", "arguments": {"feed_id": "123"}}], "done": true}`

**æ³¨æ„ï¼š**
1. åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€ã€åç¼€ã€è§£é‡Šæ–‡å­—
2. å·¥å…·åç§°å¿…é¡»å®Œå…¨åŒ¹é…åˆ—è¡¨ä¸­çš„åç§°
3. argumentså¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡
4. doneå­—æ®µè¡¨ç¤ºæ˜¯å¦å®Œæˆä»»åŠ¡""")
            
            system_prompt = "\n".join(system_prompt_parts)
            
            print(f"{CYAN}[MCP EXEC] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦{RESET}")
            
            # ç”¨æˆ·æ¶ˆæ¯ï¼šå†å² + å½“å‰è¯·æ±‚ + å·¥å…·åˆ—è¡¨
            user_message_parts = []
            
            # ä» effective_input ä¸­æå–å†å²å’Œå½“å‰è¯·æ±‚
            # effective_input æ ¼å¼å¯èƒ½æ˜¯ï¼šã€å¯¹è¯å†å²ã€‘...ã€å½“å‰è¯·æ±‚ã€‘...
            user_message_parts.append(effective_input)
            
            # æ·»åŠ å®Œæ•´çš„å·¥å…·åˆ—è¡¨
            user_message_parts.append(f"\n\n## å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆå…± {len(tools)} ä¸ªï¼‰\n")
            user_message_parts.append(tools_description)
            user_message_parts.append("\n\nè¯·æ ¹æ®ä¸Šè¿°è¯·æ±‚é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·å¹¶è¿”å› JSONã€‚")
            
            user_input_for_llm = "".join(user_message_parts)
            
            print(f"{CYAN}[MCP EXEC] ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(user_input_for_llm)} å­—ç¬¦{RESET}")

            # è®©åŒä¸€ä¸ª llm_config å†³å®š tool_callsï¼ˆæ”¯æŒå¤šè½®â€œè¿ç»­è°ƒç”¨â€ï¼‰
            # æ³¨æ„ï¼šä¸åŒæ¨¡å‹å¯¹â€œä¸¥æ ¼è¾“å‡º JSONâ€èƒ½åŠ›å·®å¼‚å¾ˆå¤§ï¼ˆå°¤å…¶ Gemini/è½»é‡æ¨¡å‹ï¼‰ã€‚
            # è¿™é‡Œä¸åšâ€œè‡ªåŠ¨çŒœå·¥å…·â€çš„ fallbackï¼šå¿…é¡»ç”± LLM å†³å®š tool_callsï¼›è‹¥å¤±è´¥åˆ™è¿”å› errorã€‚
            def _schema_props(t: Dict[str, Any]) -> Dict[str, Any]:
                schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                if isinstance(schema, dict):
                    props = schema.get("properties") or {}
                    return props if isinstance(props, dict) else {}
                return {}

            def _default_args_for_tool(t: Dict[str, Any], text: str) -> Dict[str, Any]:
                props = _schema_props(t)
                if "input" in props:
                    return {"input": text}
                if "query" in props:
                    return {"query": text}
                if "text" in props:
                    return {"text": text}
                if len(props) == 1:
                    k = next(iter(props.keys()))
                    return {k: text}
                # æ—  schema / schema ä¸æ˜ç¡®ï¼šå…œåº•ç”¨ input
                return {"input": text}

            def _infer_next_tool_from_context(
                user_input: str,
                prior_results: str,
                tool_list: List[Dict[str, Any]],
                executed_results: List[Dict[str, Any]],
                tool_map: Dict[str, Dict[str, Any]]
            ) -> Optional[Dict[str, Any]]:
                """
                æ ¹æ®å·²æ‰§è¡Œç»“æœå’Œç”¨æˆ·è¾“å…¥æ¨æ–­ä¸‹ä¸€æ­¥åº”è¯¥è°ƒç”¨çš„å·¥å…·
                
                ç­–ç•¥ï¼š
                1. å¦‚æœä¹‹å‰çš„å·¥å…·æ‰§è¡Œæœ‰é”™è¯¯ï¼Œä¸å†ç»§ç»­
                2. å¦‚æœä¹‹å‰çš„ç»“æœä¸­æœ‰æ˜ç¡®çš„"ä¸‹ä¸€æ­¥"æç¤ºï¼Œå°è¯•è§£æ
                3. å¦‚æœç”¨æˆ·è¾“å…¥åŒ…å«å¤šä¸ªæ„å›¾ï¼Œå°è¯•æ‰¾åˆ°å°šæœªæ‰§è¡Œçš„å·¥å…·
                """
                # æ£€æŸ¥æ˜¯å¦æœ‰æ‰§è¡Œå¤±è´¥çš„ç»“æœ
                for r in executed_results:
                    if r.get('error'):
                        return None  # æœ‰é”™è¯¯ï¼Œä¸å†ç»§ç»­
                
                # æå–å·²æ‰§è¡Œçš„å·¥å…·åç§°
                executed_tool_names = set()
                for r in executed_results:
                    tool_name = r.get('tool')
                    if tool_name:
                        executed_tool_names.add(tool_name.lower())
                
                # æ‰¾åˆ°å°šæœªæ‰§è¡Œçš„ç›¸å…³å·¥å…·
                user_lower = user_input.lower()
                tokens = [w for w in re.split(r"[^a-z0-9\u4e00-\u9fff]+", user_lower) if w]
                
                best_candidate = None
                best_score = 0
                
                for t in tool_list:
                    tool_name = t.get('name', '').lower()
                    if tool_name in executed_tool_names:
                        continue  # å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡
                    
                    # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
                    hay = f"{t.get('name','')} {t.get('description','')}".lower()
                    score = 0
                    for w in tokens[:12]:
                        if w and w in hay:
                            score += 1
                    
                    # å¦‚æœå¾—åˆ†è¶³å¤Ÿé«˜ï¼ˆè‡³å°‘æœ‰2ä¸ªå…³é”®è¯åŒ¹é…ï¼‰ï¼Œè€ƒè™‘ä½œä¸ºå€™é€‰
                    if score >= 2 and score > best_score:
                        best_score = score
                        best_candidate = t
                
                if best_candidate:
                    tool_name = best_candidate.get('name', '')
                    # æ„å»ºå‚æ•°
                    args = _default_args_for_tool(best_candidate, user_input)
                    return {"name": tool_name, "arguments": args}
                
                return None

            all_tool_calls: List[Dict[str, Any]] = []
            results: List[Dict[str, Any]] = []
            seen_signatures: set[str] = set()
            executed_tool_names: set[str] = set()  # è®°å½•å·²æ‰§è¡Œçš„å·¥å…·å

            log("Step 3/3: tools/call (iterative)")
            for it in range(max(1, int(max_iterations or 1))):
                # æ„é€ è¿­ä»£æç¤ºï¼šé™„å¸¦å·²æ‰§è¡Œå·¥å…·çš„"å¯è¯»è¾“å‡º"ï¼Œè®©æ¨¡å‹å†³å®šæ˜¯å¦ç»§ç»­è°ƒç”¨
                prior_texts = []
                for r in results[-6:]:
                    if r.get("tool") and r.get("tool_text"):
                        prior_texts.append(f"ã€{r['tool']}ã€‘æ‰§è¡Œç»“æœ:\n{r['tool_text']}")
                prior_block = ("\n\n".join(prior_texts)).strip()

                # æ„å»ºå·²æ‰§è¡Œå·¥å…·åˆ—è¡¨
                executed_tools_str = ", ".join(executed_tool_names) if executed_tool_names else "æ— "

                if it == 0:
                    # é¦–è½®ï¼šç®€å•æç¤º
                    iter_system = system_prompt + "\n\nè¯·åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚åªè¿”å›JSONæ ¼å¼ã€‚"
                else:
                    # åç»­è½®æ¬¡ï¼šå¼ºè°ƒä¸è¦é‡å¤è°ƒç”¨
                    iter_system = system_prompt + f"""

## å½“å‰çŠ¶æ€

- å·²æ‰§è¡Œå·¥å…·: {executed_tools_str}
- è¿™æ˜¯ç¬¬ {it+1} è½®å†³ç­–

## å†³ç­–è§„åˆ™

1. **ä¸è¦é‡å¤è°ƒç”¨å·²æ‰§è¡Œè¿‡çš„å·¥å…·**ï¼ˆé™¤éæœ‰æ˜ç¡®çš„æ–°å‚æ•°ï¼‰
2. å¦‚æœç”¨æˆ·çš„éœ€æ±‚å·²è¢«æ»¡è¶³ï¼Œè¿”å› {{"tool_calls": [], "done": true}}
3. åªæœ‰åœ¨ç¡®å®éœ€è¦æ–°ä¿¡æ¯æ—¶æ‰è°ƒç”¨æ–°å·¥å…·"""

                # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼šå†å² + è¯·æ±‚ + å·¥å…·åˆ—è¡¨ + å·²æ‰§è¡Œç»“æœ
                iter_user = user_input_for_llm
                if prior_block:
                    iter_user += f"\n\n=== å·²æ‰§è¡Œå·¥å…·çš„ç»“æœ ===\n{prior_block}\n\nè¯·æ ¹æ®ä»¥ä¸Šç»“æœå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨æ›´å¤šå·¥å…·ï¼Œæˆ–è€…ä»»åŠ¡å·²å®Œæˆã€‚"

                tool_calls: List[Dict[str, Any]] = []
                llm_text: str = ""
                done_flag = False
                def _parse_llm_tool_calls(raw_text: str) -> Tuple[List[Dict[str, Any]], bool, Optional[str]]:
                    """
                    å°½é‡é²æ£’åœ°ä» LLM è¾“å‡ºä¸­è§£æå‡º JSONï¼ˆæ”¯æŒ ```json ä»£ç å—ã€å‰åç¼€æ–‡æœ¬ï¼‰ã€‚
                    åªè¦èƒ½è§£æåˆ°åŒ…å« tool_calls çš„ JSON å¯¹è±¡å³å¯ã€‚
                    """
                    if not raw_text:
                        return [], False, "empty llm output"

                    txt = (raw_text or "").strip()

                    # å»æ‰ markdown code fenceï¼ˆå¸¸è§ï¼š```json ... ```ï¼‰
                    fence_match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", txt, re.IGNORECASE)
                    if fence_match:
                        txt = fence_match.group(1).strip()

                    # å…¼å®¹æ™ºèƒ½å¼•å·
                    txt = (
                        txt.replace("\u201c", "\"")
                        .replace("\u201d", "\"")
                        .replace("\u2018", "'")
                        .replace("\u2019", "'")
                    )

                    def _extract_json_objects(s: str) -> List[str]:
                        objs: List[str] = []
                        depth = 0
                        start = None
                        for i, ch in enumerate(s):
                            if ch == "{":
                                if depth == 0:
                                    start = i
                                depth += 1
                            elif ch == "}":
                                if depth > 0:
                                    depth -= 1
                                    if depth == 0 and start is not None:
                                        objs.append(s[start : i + 1])
                                        start = None
                        return objs

                    candidates = _extract_json_objects(txt)
                    if not candidates:
                        return [], False, "no json object found in llm output"

                    last_err: Optional[str] = None
                    for cand in candidates:
                        try:
                            data = json.loads(cand)
                            if not isinstance(data, dict):
                                continue
                            tc = data.get("tool_calls", [])
                            parsed_calls: List[Dict[str, Any]] = tc if isinstance(tc, list) else []
                            parsed_done = bool(data.get("done")) if "done" in data else False
                            # å¿…é¡»è‡³å°‘åŒ…å« tool_calls å­—æ®µï¼ˆå…è®¸ç©ºæ•°ç»„è¡¨ç¤º doneï¼‰
                            if "tool_calls" in data:
                                return parsed_calls, parsed_done, None
                        except Exception as e:
                            last_err = f"{type(e).__name__}: {str(e)}"
                            continue

                    # Fallback: å°è¯•æ›´æ¿€è¿›çš„JSONæå–
                    # æŸ¥æ‰¾åŒ…å« "tool_calls" çš„JSONç‰‡æ®µ
                    fallback_candidates = []
                    tool_calls_pattern = re.compile(r'["\']tool_calls["\']\s*:\s*\[', re.IGNORECASE)
                    for match in tool_calls_pattern.finditer(txt):
                        start_pos = match.start()
                        # ä»åŒ¹é…ä½ç½®å‘å‰æŸ¥æ‰¾JSONå¼€å§‹
                        brace_count = 0
                        json_start = -1
                        for i in range(start_pos, -1, -1):
                            if txt[i] == '{':
                                brace_count += 1
                                if brace_count == 1:
                                    json_start = i
                                    break
                            elif txt[i] == '}':
                                brace_count -= 1

                        if json_start >= 0:
                            # ä»json_startå¼€å§‹æå–å®Œæ•´çš„JSONå¯¹è±¡
                            depth = 0
                            for i in range(json_start, len(txt)):
                                if txt[i] == '{':
                                    depth += 1
                                elif txt[i] == '}':
                                    depth -= 1
                                    if depth == 0:
                                        candidate = txt[json_start:i+1]
                                        fallback_candidates.append(candidate)
                                        break

                    # å°è¯•è§£æfallbackå€™é€‰
                    for cand in fallback_candidates:
                        try:
                            data = json.loads(cand)
                            if isinstance(data, dict) and "tool_calls" in data:
                                tc = data.get("tool_calls", [])
                                parsed_calls: List[Dict[str, Any]] = tc if isinstance(tc, list) else []
                                parsed_done = bool(data.get("done")) if "done" in data else False
                                return parsed_calls, parsed_done, None
                        except Exception as e:
                            continue

                    return [], False, last_err or "json parse failed"

                def _decide_with_llm(system_text: str, user_text: str, round_label: str) -> Tuple[List[Dict[str, Any]], bool, str, Optional[str]]:
                    out_text = ""
                    calls: List[Dict[str, Any]] = []
                    done: bool = False
                    parse_err: Optional[str] = None
                    try:
                        log(f"{round_label}ï¼šä½¿ç”¨LLMå†³å®šä¸‹ä¸€æ­¥å·¥å…·è°ƒç”¨")
                        log(f"   LLMé…ç½®ID: {llm_config_id}")
                        log(f"   LLMé…ç½®å†…å®¹: provider={llm_config.get('provider')}, model={llm_config.get('model')}, has_api_key={bool(llm_config.get('api_key'))}")
                        api_result = call_llm_api(llm_config, system_text, user_text, log)

                        if api_result is None:
                            # LLM APIè°ƒç”¨å¤±è´¥
                            parse_err = "llm_api_call_failed: APIè°ƒç”¨è¿”å›Noneï¼Œè¯·æ£€æŸ¥LLMé…ç½®ã€ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥"
                            out_text = ""
                        elif api_result == "":
                            # LLMè¿”å›äº†ç©ºå­—ç¬¦ä¸²
                            parse_err = "llm_returned_empty: LLMè¿”å›äº†ç©ºå­—ç¬¦ä¸²"
                            out_text = ""
                        else:
                            # APIè°ƒç”¨æˆåŠŸï¼Œæœ‰è¿”å›å†…å®¹
                            out_text = api_result
                            calls, done, parse_err = _parse_llm_tool_calls(out_text)

                    except Exception as e:
                        log(f"âš ï¸ {round_label} LLM å†³ç­–å¤±è´¥: {str(e)}")
                        parse_err = f"llm_call_failed: {type(e).__name__}: {str(e)}"
                        out_text = ""

                    # å…³é”®è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºé¢„è§ˆ + è§£æé”™è¯¯
                    preview = (out_text or "").replace("\n", "\\n")[:600]
                    print(f"{MAGENTA}[MCP EXEC] {round_label} LLMè¾“å‡ºé¢„è§ˆ: {preview}{RESET}")
                    if parse_err:
                        print(f"{YELLOW}[MCP EXEC] {round_label} é”™è¯¯: {parse_err}{RESET}")

                    return calls, done, out_text, parse_err

                # ç¬¬ä¸€æ¬¡å†³ç­–ï¼šå¿…é¡»ç”± LLM ç»™å‡º tool_calls
                tool_calls, done_flag, llm_text, parse_error = _decide_with_llm(
                    iter_system,
                    iter_user,
                    f"ç¬¬ {it+1}/{max_iterations} è½®",
                )

                # å…è®¸ä¸€æ¬¡é‡è¯•ï¼šå¦‚æœ LLM æ²¡ç»™å‡º tool_calls ä¸”ä¹Ÿæ²¡æ˜ç¡® done=true
                if (not tool_calls) and (not done_flag):
                    retry_system = (
                        system_prompt
                        + "\n\nâš ï¸ é”™è¯¯ï¼šä½ ä¸Šä¸€æ¬¡æ²¡æœ‰è¿”å›åˆæ³•çš„JSONæ ¼å¼ã€‚"
                        + "\n\nè¯·é‡æ–°æ€è€ƒå¹¶åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
                        + "\n- éœ€è¦å·¥å…·ï¼š{\"tool_calls\": [{\"name\": \"å·¥å…·å\", \"arguments\": {...}}], \"done\": true}"
                        + "\n- ä¸éœ€è¦å·¥å…·ï¼š{\"tool_calls\": [], \"done\": true}"
                        + "\n\nç°åœ¨è¯·é‡æ–°å›ç­”ï¼Œåªè¾“å‡ºJSONï¼š"
                    )
                    tool_calls, done_flag, retry_text, retry_parse_error = _decide_with_llm(
                        retry_system,
                        iter_user,
                        f"ç¬¬ {it+1}/{max_iterations} è½®ï¼ˆé‡è¯•1æ¬¡ï¼‰",
                    )
                    if retry_text:
                        llm_text = retry_text
                        parse_error = retry_parse_error

                if not tool_calls:
                    if done_flag:
                        break

                    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„é”™è¯¯ä¿¡æ¯
                    if parse_error and ("llm_api_call_failed" in parse_error or "llm_call_failed" in parse_error):
                        # APIè°ƒç”¨å¤±è´¥
                        error_msg = "LLM APIè°ƒç”¨å¤±è´¥"
                        suggestion = "è¯·æ£€æŸ¥ï¼š1) LLMé…ç½®æ˜¯å¦æ­£ç¡® 2) APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ 3) ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ 4) APIé¢åº¦æ˜¯å¦å……è¶³"
                    elif parse_error and "llm_returned_empty" in parse_error:
                        # LLMè¿”å›ç©ºå†…å®¹
                        error_msg = "LLMè¿”å›äº†ç©ºå†…å®¹"
                        suggestion = "LLMå¯èƒ½ä¸æ”¯æŒå½“å‰çš„ä»»åŠ¡ï¼Œæˆ–é‡åˆ°äº†å†…éƒ¨é”™è¯¯ã€‚è¯·å°è¯•æ›´æ¢LLMæ¨¡å‹æˆ–ç®€åŒ–è¾“å…¥ã€‚"
                    else:
                        # JSONè§£æå¤±è´¥
                        error_msg = "LLMæœªè¿”å›æœ‰æ•ˆçš„tool_calls JSONæ ¼å¼"
                        suggestion = "LLMå¯èƒ½æ²¡æœ‰ç†è§£JSONæ ¼å¼è¦æ±‚ï¼Œæˆ–è¿”å›äº†æ™®é€šæ–‡æœ¬ã€‚è¯·æ£€æŸ¥LLMæ¨¡å‹æ˜¯å¦æ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼Œæˆ–è°ƒæ•´ç³»ç»Ÿæç¤ºè¯ã€‚"

                    error_details = {
                        "error": error_msg,
                        "logs": logs,
                        "llm_response": llm_text,
                        "debug": {
                            "llm_parse_error": parse_error,
                            "llm_output_length": len(llm_text or ""),
                            "available_tools": [t.get('name', '') for t in tools[:5]],  # åªæ˜¾ç¤ºå‰5ä¸ªå·¥å…·é¿å…æ—¥å¿—è¿‡é•¿
                            "iteration": it + 1,
                            "suggestion": suggestion
                        },
                    }

                    # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
                    log(f"âŒ LLM å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{parse_error}")
                    log(f"LLM è¾“å‡ºé•¿åº¦: {len(llm_text or '')} å­—ç¬¦")
                    log(f"LLM è¾“å‡ºé¢„è§ˆ: {(llm_text or '')[:200]}...")
                    if len(llm_text or '') > 200:
                        log(f"... (çœç•¥ {len(llm_text or '') - 200} å­—ç¬¦)")

                    return error_details

                # æ‰§è¡Œæœ¬è½® tool_calls
                log(f"ç¬¬ {it+1} è½®ï¼šæ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                for i, tc in enumerate(tool_calls[:5]):  # æ¯è½®æœ€å¤š 5 ä¸ªï¼Œé¿å…å¤±æ§
                    tool_name = (tc or {}).get("name")
                    tool_args = (tc or {}).get("arguments", {}) or {}
                    if not tool_name:
                        continue
                    
                    # éªŒè¯å·¥å…·åç§°æ˜¯å¦çœŸå®å­˜åœ¨
                    tool_name_lower = tool_name.lower()
                    if tool_name_lower not in tool_name_map:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…
                        matched_tool = None
                        for actual_name, tool_info in tool_name_map.items():
                            if tool_name_lower in actual_name or actual_name in tool_name_lower:
                                matched_tool = tool_info
                                tool_name = tool_info['name']  # ä½¿ç”¨çœŸå®çš„å·¥å…·åç§°
                                log(f"å·¥å…·åç§°ä¿®æ­£: {tc.get('name')} -> {tool_name}")
                                break
                        
                        if not matched_tool:
                            error_msg = f"å·¥å…· '{tool_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·: {', '.join([t['name'] for t in tools[:10]])}"
                            log(f"âŒ {error_msg}")
                            results.append({"tool": tool_name, "error": error_msg})
                            continue
                    
                    # éªŒè¯å‚æ•°æ˜¯å¦ç¬¦åˆå·¥å…·schema
                    tool_info = tool_name_map.get(tool_name_lower)
                    if tool_info:
                        props = tool_info.get('props', {})
                        schema = tool_info.get('schema', {})
                        required_params = schema.get('required', []) if isinstance(schema, dict) else []
                        
                        # æ£€æŸ¥å¿…éœ€å‚æ•°
                        missing_required = [p for p in required_params if p not in tool_args]
                        if missing_required:
                            log(f"âš ï¸ å·¥å…· {tool_name} ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_required}")
                            # å°è¯•ä½¿ç”¨é»˜è®¤å€¼å¡«å……
                            for param in missing_required:
                                if param in props:
                                    param_info = props[param]
                                    default_val = param_info.get('default')
                                    if default_val is not None:
                                        tool_args[param] = default_val
                                        log(f"  ä½¿ç”¨é»˜è®¤å€¼å¡«å…… {param}: {default_val}")
                                    elif 'input' in props:
                                        tool_args[param] = effective_input
                                    else:
                                        tool_args[param] = ""
                        
                        # ç§»é™¤ä¸åœ¨schemaä¸­çš„å‚æ•°
                        valid_params = set(props.keys())
                        invalid_params = set(tool_args.keys()) - valid_params
                        if invalid_params:
                            log(f"âš ï¸ å·¥å…· {tool_name} ç§»é™¤äº†æ— æ•ˆå‚æ•°: {invalid_params}")
                            tool_args = {k: v for k, v in tool_args.items() if k in valid_params}

                    sig = f"{tool_name}:{json.dumps(tool_args, ensure_ascii=False, sort_keys=True)[:400]}"
                    if sig in seen_signatures:
                        # é˜²å¾ªç¯
                        log(f"âš ï¸ è·³è¿‡é‡å¤çš„å·¥å…·è°ƒç”¨: {tool_name}")
                        continue
                    seen_signatures.add(sig)

                    # é€šç”¨å®‰å…¨æ‹¦æˆªï¼šç ´åæ€§å·¥å…·å¿…é¡»ç”¨æˆ·æ˜ç¡®è¦æ±‚
                    destructive_markers = ("delete", "clear", "remove", "logout", "reset", "wipe")
                    user_lower_for_policy = (effective_input or "").lower()
                    user_asked_destructive = any(k in user_lower_for_policy for k in ("åˆ é™¤", "æ¸…é™¤", "ç§»é™¤", "ç™»å‡º", "é€€å‡ºç™»å½•", "delete", "clear", "remove", "logout", "reset", "wipe"))
                    if (not user_asked_destructive) and any(m in tool_name.lower() for m in destructive_markers):
                        msg = f"Blocked destructive tool call without explicit user request: {tool_name}"
                        log(f"âŒ {msg}")
                        results.append({
                            "tool": tool_name,
                            "error": msg,
                            "error_type": "policy",
                        })
                        return {
                            "error": msg,
                            "logs": logs,
                            "results": results,
                        }

                    all_tool_calls.append({"name": tool_name, "arguments": tool_args})
                    log(f"æ‰§è¡Œå·¥å…·è°ƒç”¨: {tool_name}")
                    log(f"  å‚æ•°: {json.dumps(tool_args, ensure_ascii=False)[:200]}")
                    
                    print(f"{YELLOW}[MCP EXEC] ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}{RESET}")
                    print(f"{CYAN}[MCP EXEC]   å‚æ•°: {json.dumps(tool_args, ensure_ascii=False)[:150]}{RESET}")
                    
                    try:
                        # ä½¿ç”¨ mcp_common_logic ç›´æ¥è°ƒç”¨å·¥å…·
                        print(f"{YELLOW}[MCP EXEC]   â†’ è°ƒç”¨ call_mcp_tool...{RESET}")
                        tool_result = call_mcp_tool(server_url, headers, tool_name, tool_args, log)
                        print(f"{GREEN}[MCP EXEC]   â† call_mcp_tool è¿”å›{RESET}")
                        print(f"{CYAN}[MCP EXEC]   ç»“æœç±»å‹: {type(tool_result).__name__}, keys: {list(tool_result.keys()) if isinstance(tool_result, dict) else 'N/A'}{RESET}")
                        
                        # å¤„ç†æ–°çš„ç»“æ„åŒ–è¿”å›æ ¼å¼
                        if isinstance(tool_result, dict):
                            if tool_result.get('success'):
                                # æˆåŠŸ
                                result_data = tool_result.get('data')
                                result_text = tool_result.get('text')
                                raw_result = tool_result.get('raw_result')
                                
                                results.append({
                                    'tool': tool_name,
                                    'result': {
                                        'jsonrpc': '2.0',
                                        'result': raw_result or {'content': [{'type': 'text', 'text': str(result_data)}]}
                                    },
                                    'tool_text': result_text or str(result_data) if result_data else '',
                                })
                                log(f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                                executed_tool_names.add(tool_name.lower())
                            else:
                                # å¤±è´¥ - åŒºåˆ†é”™è¯¯ç±»å‹
                                error_type = tool_result.get('error_type', 'unknown')
                                error_msg = tool_result.get('error', 'æœªçŸ¥é”™è¯¯')
                                error_code = tool_result.get('error_code')
                                http_code = tool_result.get('http_code')
                                
                                if error_type == 'network':
                                    error_display = f"[ç½‘ç»œé”™è¯¯] HTTP {http_code}: {error_msg}" if http_code else f"[ç½‘ç»œé”™è¯¯] {error_msg}"
                                elif error_type == 'business':
                                    error_display = f"[ä¸šåŠ¡é”™è¯¯] ä»£ç  {error_code}: {error_msg}" if error_code else f"[ä¸šåŠ¡é”™è¯¯] {error_msg}"
                                else:
                                    error_display = f"[{error_type}] {error_msg}"
                                
                                log(f"âŒ å·¥å…· {tool_name} å¤±è´¥: {error_display}")
                                results.append({
                                    "tool": tool_name,
                                    "error": error_display,
                                    "error_type": error_type,
                                    "error_code": error_code,
                                })
                        else:
                            # å…¼å®¹æ—§æ ¼å¼ï¼ˆç›´æ¥è¿”å›ç»“æœï¼‰
                            if tool_result:
                                results.append({
                                    'tool': tool_name,
                                    'result': {
                                        'jsonrpc': '2.0',
                                        'result': {'content': [{'type': 'text', 'text': str(tool_result)}]}
                                    }
                                })
                                log(f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
                                executed_tool_names.add(tool_name.lower())
                            else:
                                results.append({"tool": tool_name, "error": "å·¥å…·è¿”å›ç©ºç»“æœ"})
                                
                    except Exception as e:
                        import traceback
                        log(f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}")
                        results.append({
                            "tool": tool_name,
                            "error": f"æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                            "error_type": "exception",
                        })

                if done_flag:
                    break

            # æŠ½å–å¯è¯»æ–‡æœ¬è¾“å‡ºï¼Œç»™ LLM ä½œä¸ºâ€œäº‹å®æºâ€ï¼ˆä¼˜åŒ–ï¼šæå–æ‰€æœ‰å¯ç”¨ä¿¡æ¯ï¼‰
            tool_text_outputs: List[str] = []
            try:
                for r in results:
                    tool_resp = r.get("result")
                    tool_name = r.get("tool") or "tool"
                    
                    # å¤„ç†é”™è¯¯æƒ…å†µ
                    if r.get("error"):
                        error_msg = str(r.get("error", ""))
                        r["tool_text"] = f"é”™è¯¯: {error_msg}"
                        tool_text_outputs.append(f"[{tool_name}] âŒ {error_msg}")
                        continue
                    
                    if not isinstance(tool_resp, dict):
                        # å¦‚æœä¸æ˜¯ dictï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        if tool_resp:
                            text_block = str(tool_resp).strip()
                            r["tool_text"] = text_block
                            tool_text_outputs.append(f"[{tool_name}]\n{text_block}")
                        continue
                    
                    # æå– content ä¸­çš„æ–‡æœ¬å†…å®¹
                    content = (tool_resp.get("result") or {}).get("content")
                    texts = []
                    
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict):
                                item_type = item.get("type", "")
                                if item_type == "text" and item.get("text"):
                                    texts.append(str(item.get("text")))
                                elif item_type == "image" and item.get("data"):
                                    # å›¾ç‰‡å†…å®¹ï¼šè®°å½•ä¸ºæç¤º
                                    texts.append(f"[å›¾ç‰‡æ•°æ®å·²è¿”å›ï¼Œå¤§å°: {len(str(item.get('data', '')))} å­—ç¬¦]")
                                elif item_type:
                                    # å…¶ä»–ç±»å‹ï¼šå°è¯•æå–å¯è¯»ä¿¡æ¯
                                    for key in ["text", "content", "message", "data"]:
                                        if item.get(key):
                                            texts.append(f"[{item_type}]: {str(item.get(key))[:500]}")
                                            break
                    
                    # å¦‚æœæ²¡æœ‰ä» content æå–åˆ°æ–‡æœ¬ï¼Œå°è¯•å…¶ä»–å­—æ®µ
                    if not texts:
                        # å°è¯•ç›´æ¥æå– result ä¸­çš„æ–‡æœ¬å­—æ®µ
                        for key in ["text", "message", "content", "output", "data"]:
                            if tool_resp.get("result", {}).get(key):
                                texts.append(str(tool_resp["result"][key]))
                                break
                        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•æ•´ä¸ª result
                        if not texts and tool_resp.get("result"):
                            result_data = tool_resp.get("result")
                            if isinstance(result_data, str):
                                texts.append(result_data)
                            elif isinstance(result_data, dict):
                                # å°è¯•åºåˆ—åŒ–ä¸º JSONï¼ˆä½†é™åˆ¶é•¿åº¦ï¼‰
                                try:
                                    result_json = json.dumps(result_data, ensure_ascii=False)
                                    if len(result_json) < 2000:
                                        texts.append(result_json)
                                    else:
                                        texts.append(result_json[:2000] + "...[å·²æˆªæ–­]")
                                except:
                                    texts.append(str(result_data)[:1000])
                    
                    if texts:
                        text_block = ("\n".join(texts)).strip()
                        r["tool_text"] = text_block
                        tool_text_outputs.append(f"[{tool_name}]\n{text_block}")
                    else:
                        # å¦‚æœå®Œå…¨æ²¡æœ‰æ–‡æœ¬ï¼Œè‡³å°‘è®°å½•å·¥å…·å·²æ‰§è¡Œ
                        r["tool_text"] = f"å·¥å…· {tool_name} å·²æ‰§è¡Œï¼Œä½†æœªè¿”å›æ–‡æœ¬å†…å®¹"
                        tool_text_outputs.append(f"[{tool_name}] å·²æ‰§è¡Œï¼ˆæ— æ–‡æœ¬è¿”å›ï¼‰")
            except Exception as e:
                import traceback
                traceback.print_exc()
                # å³ä½¿æå–å¤±è´¥ï¼Œä¹Ÿä¸å½±å“æ•´ä½“æµç¨‹
                pass

            tool_names = [r.get("tool") for r in results if r.get("tool")]
            tool_names_text = ", ".join(tool_names[:8]) + ("..." if len(tool_names) > 8 else "")
            summary = f'âœ… MCP "{server_name}" æ‰§è¡Œå®Œæˆï¼ˆ{len(results)} ä¸ªå·¥å…·è°ƒç”¨ï¼š{tool_names_text}ï¼‰'

            raw_result = {
                "mcp_server_id": mcp_server_id,
                "mcp_server_name": server_name,
                "mcp_server_url": server_url,
                "input": effective_input,
                "tool_calls": all_tool_calls,
                "results": results,  # results[i].result ä¿ç•™åŸå§‹ MCP jsonrpcï¼ˆå« base64 å›¾ç‰‡ï¼‰
            }

            return {
                "summary": summary,
                "tool_text": "\n\n".join(tool_text_outputs).strip() if tool_text_outputs else None,
                "results": results,  # é¡¶å±‚ä¹Ÿæš´éœ² resultsï¼Œä¾¿äºé”™è¯¯å¤„ç†
                "raw_result": raw_result,
                "raw_result_compact": _truncate_deep(raw_result),
                "logs": logs,
            }

        finally:
            if cursor:
                cursor.close()
            conn.close()

    except Exception as e:
        return {"error": str(e), "logs": logs}

