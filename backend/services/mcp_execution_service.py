"""
MCP æ‰§è¡ŒæœåŠ¡ï¼ˆä¾› AgentActor/æ¥å£å¤ç”¨ï¼‰

ç›®æ ‡ï¼š
- ç»™å®š mcp_server_id + ç”¨æˆ·è¾“å…¥ + llm_config_id
- å…ˆè·å– MCP tools åˆ—è¡¨
- ç”¨ LLM äº§å‡º tool_calls JSON
- æ‰§è¡Œ tool_calls å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ + logs

æ³¨æ„ï¼šè¿™é‡Œä¸ä¾èµ– Flask app.pyï¼Œé¿å…å¾ªç¯å¯¼å…¥ã€‚
ä½¿ç”¨ mcp_common_logic æ¨¡å—ç›´æ¥è°ƒç”¨ MCPï¼ˆç±»ä¼¼ ok-publish åˆ†æ”¯ï¼‰ã€‚
"""

from __future__ import annotations

import json
import re
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import requests

from database import get_mysql_connection
from mcp_server.mcp_common_logic import get_mcp_tools_list, call_mcp_tool, prepare_mcp_headers, initialize_mcp_session
import pymysql


# ==================== å‚æ•°ç”Ÿæˆè¾…åŠ©å‡½æ•°ï¼ˆä¸¤æ­¥æ³•ï¼‰====================

def extract_user_request_from_input(input_text: str) -> str:
    """ä»åŒ…å«ã€å¯ç”¨å·¥å…·ã€‘ã€å¯¹è¯å†å²ã€‘ã€å½“å‰è¯·æ±‚ã€‘çš„è¾“å…¥ä¸­æå–ç”¨æˆ·çš„å®é™…è¯·æ±‚"""
    if not input_text:
        return ""
    
    # å°è¯•æå–ã€å½“å‰è¯·æ±‚ã€‘éƒ¨åˆ†
    match = re.search(r'ã€å½“å‰è¯·æ±‚ã€‘\s*\n?(.*?)(?=\n\n|$)', input_text, re.DOTALL)
    if match:
        user_request = match.group(1).strip()
        if user_request:
            return user_request
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ã€å½“å‰è¯·æ±‚ã€‘æ ‡è®°ï¼Œå°è¯•æå–æœ€åä¸€éƒ¨åˆ†ï¼ˆå‡è®¾æ˜¯ç”¨æˆ·è¯·æ±‚ï¼‰
    # ç§»é™¤ã€å¯ç”¨å·¥å…·ã€‘å’Œã€å¯¹è¯å†å²ã€‘éƒ¨åˆ†
    cleaned = re.sub(r'ã€å¯ç”¨å·¥å…·ã€‘.*?ã€å¯¹è¯å†å²ã€‘', '', input_text, flags=re.DOTALL)
    cleaned = re.sub(r'ã€å¯¹è¯å†å²ã€‘.*?ã€å½“å‰è¯·æ±‚ã€‘', '', cleaned, flags=re.DOTALL)
    cleaned = cleaned.strip()
    
    # å¦‚æœæ¸…ç†åè¿˜æœ‰å†…å®¹ï¼Œè¿”å›æ¸…ç†åçš„å†…å®¹
    if cleaned:
        return cleaned
    
    # å¦åˆ™è¿”å›åŸå§‹è¾“å…¥
    return input_text.strip()


def extract_title_from_text(text: str, max_length: int = 50) -> str:
    """ä»æ–‡æœ¬ä¸­æå–æ ‡é¢˜"""
    if not text:
        return "æœªå‘½å"
    
    # å…ˆå°è¯•æå–ç”¨æˆ·è¯·æ±‚ï¼ˆå¦‚æœåŒ…å«ç»“æ„åŒ–æ ‡è®°ï¼‰
    user_request = extract_user_request_from_input(text)
    if user_request and user_request != text:
        text = user_request
    
    # å°è¯•æå–ç¬¬ä¸€è¡Œ
    first_line = text.split('\n')[0].strip()
    if first_line:
        # ç§»é™¤ markdown æ ‡è®°å’Œç‰¹æ®Šæ ‡è®°
        title = re.sub(r'^#+\s*', '', first_line)
        title = re.sub(r'^ã€.*?ã€‘\s*', '', title)  # ç§»é™¤ã€æ ‡è®°ã€‘
        title = title.strip()
        if len(title) > max_length:
            title = title[:max_length] + "..."
        return title or "æœªå‘½å"
    
    # å¦‚æœç¬¬ä¸€è¡Œä¸ºç©ºï¼Œä½¿ç”¨å‰ N ä¸ªå­—ç¬¦
    cleaned = text.strip()
    if len(cleaned) > max_length:
        return cleaned[:max_length] + "..."
    return cleaned or "æœªå‘½å"


def _extract_args_with_llm(
    tool_name: str,
    tool_info: Dict[str, Any],
    full_input_text: str,
    context: Dict[str, Any],
    llm_config: Dict[str, Any],
    add_log: Optional[callable] = None
) -> Optional[Dict[str, Any]]:
    """
    ä½¿ç”¨ LLM ä»å¯¹è¯å†å²ä¸­æå–å·¥å…·å‚æ•°
    
    Args:
        tool_name: å·¥å…·åç§°
        tool_info: å·¥å…·ä¿¡æ¯
        full_input_text: å®Œæ•´çš„è¾“å…¥æ–‡æœ¬ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        llm_config: LLM é…ç½®
        add_log: æ—¥å¿—å‡½æ•°
    
    Returns:
        æå–çš„å‚æ•°å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    props = tool_info.get('props', {})
    required = tool_info.get('required', [])
    
    # æ„å»ºå‚æ•°æè¿°
    param_descriptions = []
    for param_name, param_info in props.items():
        param_type = param_info.get('type', 'string')
        param_desc = param_info.get('description', '')
        is_required = param_name in required
        req_mark = "ï¼ˆå¿…éœ€ï¼‰" if is_required else "ï¼ˆå¯é€‰ï¼‰"
        param_descriptions.append(f"- {param_name} ({param_type}){req_mark}: {param_desc}")
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‚æ•°æå–åŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»å¯¹è¯å†å²ï¼Œä»ä¸­æå–è°ƒç”¨å·¥å…· "{tool_name}" æ‰€éœ€çš„æ‰€æœ‰å‚æ•°ã€‚

å·¥å…·åç§°ï¼š{tool_name}
å·¥å…·æè¿°ï¼š{tool_info.get('description', '')}

éœ€è¦æå–çš„å‚æ•°ï¼š
{chr(10).join(param_descriptions)}

é‡è¦æç¤ºï¼š
1. ä»”ç»†é˜…è¯»æ•´ä¸ªå¯¹è¯å†å²ï¼ŒåŒ…æ‹¬ã€å¯¹è¯å†å²ã€‘å’Œã€å½“å‰è¯·æ±‚ã€‘éƒ¨åˆ†
2. ä»å¯¹è¯å†å²ä¸­æ‰¾å‡ºæ‰€æœ‰ç›¸å…³çš„å‚æ•°å€¼ï¼ŒåŒ…æ‹¬ï¼š
   - æ ‡é¢˜ï¼ˆtitleï¼‰ï¼šä»å¯¹è¯ä¸­æå–çš„æ ‡é¢˜æˆ–ä¸»é¢˜
   - å†…å®¹ï¼ˆcontentï¼‰ï¼šç”¨æˆ·æƒ³è¦å‘å¸ƒæˆ–åˆ†äº«çš„å†…å®¹
   - æ ‡ç­¾ï¼ˆtagsï¼‰ï¼šç”¨æˆ·æåˆ°çš„æ ‡ç­¾æˆ–è¯é¢˜
   - å›¾ç‰‡ï¼ˆimagesï¼‰ï¼šç”¨æˆ·ä¸Šä¼ æˆ–æåˆ°çš„å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
3. å¦‚æœå¯¹è¯å†å²ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°æŸä¸ªå‚æ•°ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡åˆç†æ¨æ–­
4. å¯¹äºå¯é€‰å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ç›¸å…³ä¿¡æ¯å¯ä»¥çœç•¥
5. å›¾ç‰‡å‚æ•°åº”è¯¥ä»ä¸Šä¸‹æ–‡ä¸­æå–ï¼ˆå¦‚æœç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡ï¼‰

è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON å¯¹è±¡ï¼ŒåªåŒ…å«å‚æ•°åå’Œå‚æ•°å€¼ã€‚ä¾‹å¦‚ï¼š
{{
  "title": "ä»å¯¹è¯ä¸­æå–çš„æ ‡é¢˜",
  "content": "ä»å¯¹è¯ä¸­æå–çš„å®Œæ•´å†…å®¹",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
}}

æ³¨æ„ï¼šåªè¿”å› JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
    
    # è°ƒç”¨ LLM
    if add_log:
        add_log(f"  ä½¿ç”¨ LLM ä»å¯¹è¯å†å²ä¸­æå–å‚æ•°...")
    
    llm_response = call_llm_api(llm_config, system_prompt, full_input_text, add_log)
    if not llm_response:
        return None
    
    # è§£æ JSON
    try:
        # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        json_match = re.search(r'\{[\s\S]*\}', llm_response)
        if json_match:
            args = json.loads(json_match.group())
            # éªŒè¯å‚æ•°ç±»å‹
            validated_args = {}
            for param_name, param_value in args.items():
                if param_name not in props:
                    continue  # å¿½ç•¥æœªçŸ¥å‚æ•°
                param_info = props[param_name]
                param_type = param_info.get('type', 'string')
                
                # ç±»å‹éªŒè¯å’Œè½¬æ¢
                if param_type == 'array' and not isinstance(param_value, list):
                    if param_value:
                        validated_args[param_name] = [param_value]
                    else:
                        validated_args[param_name] = []
                elif param_type in ['number', 'integer']:
                    try:
                        validated_args[param_name] = int(param_value) if param_type == 'integer' else float(param_value)
                    except:
                        validated_args[param_name] = param_value
                elif param_type == 'boolean':
                    if isinstance(param_value, bool):
                        validated_args[param_name] = param_value
                    elif isinstance(param_value, str):
                        validated_args[param_name] = param_value.lower() in ('true', '1', 'yes', 'æ˜¯')
                    else:
                        validated_args[param_name] = bool(param_value)
                else:
                    validated_args[param_name] = param_value
            
            # å¤„ç†å›¾ç‰‡å‚æ•°ï¼ˆä» context ä¸­æå–ï¼‰
            for param_name in ['images', 'image', 'photos', 'pictures', 'files']:
                if param_name in props:
                    images = extract_images_from_context(context)
                    if images:
                        param_type = props[param_name].get('type', 'string')
                        if param_type == 'array':
                            validated_args[param_name] = images
                        elif images:
                            validated_args[param_name] = images[0]
            
            if add_log:
                add_log(f"  âœ… LLM æå–åˆ° {len(validated_args)} ä¸ªå‚æ•°")
            
            return validated_args
    except json.JSONDecodeError as e:
        if add_log:
            add_log(f"  âš ï¸ LLM è¿”å›çš„ JSON è§£æå¤±è´¥: {e}")
        return None
    except Exception as e:
        if add_log:
            add_log(f"  âš ï¸ LLM å‚æ•°æå–å‡ºé”™: {e}")
        return None
    
    return None


def extract_images_from_context(context: dict) -> List[str]:
    """ä»ä¸Šä¸‹æ–‡ä¸­æå–å›¾ç‰‡è·¯å¾„"""
    images = []
    
    # ä»åŸå§‹æ¶ˆæ¯çš„ ext.media ä¸­æå–
    original_message = context.get('original_message', {})
    if not original_message:
        return images
    
    # å¤„ç† ext å­—æ®µï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
    ext = original_message.get('ext', {}) or {}
    if isinstance(ext, str):
        try:
            import json
            ext = json.loads(ext)
        except Exception:
            ext = {}
    
    media_list = ext.get('media', [])
    if not isinstance(media_list, list):
        return images
    
    for m in media_list:
        if not isinstance(m, dict):
            continue
        
        if m.get('type') == 'image':
            # ä¼˜å…ˆä½¿ç”¨ urlï¼ˆæœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ– HTTP URLï¼‰
            img_path = m.get('url')
            if img_path:
                images.append(img_path)
            # å¦‚æœæ²¡æœ‰ urlï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ dataï¼ˆbase64ï¼‰ï¼Œä½†éœ€è¦è½¬æ¢ä¸ºæ–‡ä»¶è·¯å¾„
            # æ³¨æ„ï¼šbase64 æ•°æ®éœ€è¦å…ˆä¿å­˜ä¸ºæ–‡ä»¶æ‰èƒ½ä¼ é€’ç»™ MCP å·¥å…·
            elif m.get('data'):
                # è¿™é‡Œå¯ä»¥æ·»åŠ  base64 è½¬æ–‡ä»¶çš„é€»è¾‘ï¼Œä½†æš‚æ—¶è·³è¿‡
                # å› ä¸º MCP å·¥å…·é€šå¸¸éœ€è¦æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯ base64
                pass
    
    return images


def generate_tool_arguments(
    tool_name: str,
    tool_info: Dict[str, Any],
    user_input: str,
    context: Dict[str, Any],
    llm_config: Optional[Dict[str, Any]] = None,
    full_input_text: Optional[str] = None,
    add_log: Optional[callable] = None
) -> Dict[str, Any]:
    """
    æ ¹æ®å·¥å…· schema å’Œç”¨æˆ·è¾“å…¥è‡ªåŠ¨ç”Ÿæˆå‚æ•°ï¼ˆä¸¤æ­¥æ³•æ ¸å¿ƒï¼‰
    ä¼˜å…ˆä½¿ç”¨ LLM ä»å¯¹è¯å†å²ä¸­æå–å‚æ•°ï¼Œå¦‚æœ LLM ä¸å¯ç”¨åˆ™ä½¿ç”¨è§„åˆ™åŒ¹é…
    
    Args:
        tool_name: å·¥å…·åç§°
        tool_info: å·¥å…·ä¿¡æ¯ï¼ˆåŒ…å« schema, props, requiredï¼‰
        user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼ˆå·²æå–çš„å®é™…è¯·æ±‚ï¼‰
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å« original_message ç­‰ï¼‰
        llm_config: LLM é…ç½®ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨ LLM æå–å‚æ•°ï¼‰
        full_input_text: å®Œæ•´çš„è¾“å…¥æ–‡æœ¬ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
        add_log: æ—¥å¿—å‡½æ•°
    
    Returns:
        ç”Ÿæˆçš„å‚æ•°å­—å…¸
    """
    schema = tool_info.get('schema', {})
    props = tool_info.get('props', {})
    required = tool_info.get('required', [])
    
    # å¦‚æœæä¾›äº† LLM é…ç½®å’Œå®Œæ•´è¾“å…¥æ–‡æœ¬ï¼Œä½¿ç”¨ LLM æå–å‚æ•°
    if llm_config and full_input_text:
        try:
            llm_args = _extract_args_with_llm(
                tool_name=tool_name,
                tool_info=tool_info,
                full_input_text=full_input_text,
                context=context,
                llm_config=llm_config,
                add_log=add_log
            )
            if llm_args:
                return llm_args
        except Exception as e:
            if add_log:
                add_log(f"âš ï¸ LLM å‚æ•°æå–å¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™åŒ¹é…: {e}")
    
    # å›é€€åˆ°è§„åˆ™åŒ¹é…
    args = {}
    
    # 1. å¤„ç†å¿…éœ€å‚æ•°
    for param in required:
        if param not in props:
            # å¦‚æœ schema ä¸­æ²¡æœ‰å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
            args[param] = user_input
            continue
        
        param_info = props[param]
        param_type = param_info.get('type', 'string')
        param_desc = (param_info.get('description', '') or '').lower()
        
        # æ ¹æ®å‚æ•°åç§°å’Œæè¿°æ¨æ–­å€¼
        param_lower = param.lower()
        
        # Content/Text ç±»å‚æ•°ï¼šä½¿ç”¨å®Œæ•´ç”¨æˆ·è¾“å…¥
        if param_lower in ['content', 'text', 'body', 'description', 'message']:
            args[param] = user_input
        
        # Title ç±»å‚æ•°ï¼šæå–æ ‡é¢˜
        elif param_lower in ['title', 'subject', 'heading', 'name']:
            args[param] = extract_title_from_text(user_input)
        
        # Images ç±»å‚æ•°ï¼šä»ä¸Šä¸‹æ–‡æå–
        elif param_lower in ['images', 'image', 'photos', 'pictures', 'files']:
            images = extract_images_from_context(context)
            args[param] = images if param_type == 'array' else (images[0] if images else None)
        
        # Tags ç±»å‚æ•°ï¼šå°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ ‡ç­¾ï¼ˆä½¿ç”¨ # æ ‡è®°æˆ–é€—å·åˆ†éš”ï¼‰
        elif param_lower in ['tags', 'tag', 'categories', 'category']:
            if param_type == 'array':
                # å°è¯•æå–æ ‡ç­¾ï¼šæŸ¥æ‰¾ #æ ‡ç­¾ æ ¼å¼æˆ–é€—å·åˆ†éš”çš„æ ‡ç­¾
                tags = []
                # æå– #æ ‡ç­¾ æ ¼å¼
                hash_tags = re.findall(r'#([^\s#]+)', user_input)
                if hash_tags:
                    tags.extend(hash_tags)
                # æå–"æ ‡ç­¾ï¼š"åçš„å†…å®¹
                tag_match = re.search(r'æ ‡ç­¾[ï¼š:]\s*([^\n]+)', user_input)
                if tag_match:
                    tag_str = tag_match.group(1)
                    # åˆ†å‰²é€—å·æˆ–ç©ºæ ¼åˆ†éš”çš„æ ‡ç­¾
                    comma_tags = [t.strip() for t in re.split(r'[,ï¼Œã€\s]+', tag_str) if t.strip()]
                    tags.extend(comma_tags)
                # å¦‚æœæ²¡æ‰¾åˆ°æ ‡ç­¾ï¼Œä½¿ç”¨ç©ºæ•°ç»„ï¼ˆå¯é€‰å‚æ•°ï¼‰
                args[param] = tags if tags else []
            else:
                args[param] = user_input
        
        # Query/Search ç±»å‚æ•°ï¼šä½¿ç”¨ç”¨æˆ·è¾“å…¥
        elif param_lower in ['query', 'keyword', 'search', 'q']:
            args[param] = user_input
        
        # Input ç±»å‚æ•°ï¼šä½¿ç”¨ç”¨æˆ·è¾“å…¥
        elif param_lower in ['input']:
            args[param] = user_input
        
        # ID ç±»å‚æ•°ï¼šå°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ•°å­—æˆ– ID
        elif 'id' in param_lower or param_type in ['number', 'integer']:
            # å°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ•°å­—
            match = re.search(r'\d+', user_input)
            if match:
                args[param] = int(match.group()) if param_type in ['number', 'integer'] else match.group()
            else:
                args[param] = None
        
        # Boolean ç±»å‚æ•°ï¼šä½¿ç”¨é»˜è®¤å€¼
        elif param_type == 'boolean':
            args[param] = param_info.get('default', True)
        
        # å…¶ä»–ï¼šä½¿ç”¨é»˜è®¤å€¼æˆ–ç”¨æˆ·è¾“å…¥
        else:
            if 'default' in param_info:
                args[param] = param_info['default']
            elif param_type == 'string':
                args[param] = user_input
            else:
                args[param] = None
    
    # 2. å¤„ç†å¯é€‰å‚æ•°ï¼ˆä»…ä½¿ç”¨æœ‰é»˜è®¤å€¼çš„ï¼‰
    for param, param_info in props.items():
        if param not in args and 'default' in param_info:
            args[param] = param_info['default']
    
    return args


# ==================== åŸæœ‰å‡½æ•° ====================

def _mk_logger(external_log: Optional[callable] = None) -> tuple[list[str], callable]:
    logs: list[str] = []

    def add_log(message: str):
        line = f"[{datetime.now().strftime('%H:%M:%S')}] {message}"
        logs.append(line)
        if external_log:
            try:
                external_log(line)
            except Exception:
                pass

    return logs, add_log


def _truncate_deep(obj: Any, *, max_str: int = 2000) -> Any:
    """é¿å…æŠŠè¶…å¤§ç»“æœï¼ˆå°¤å…¶ base64ï¼‰å¡è¿› processSteps/system prompt"""
    if obj is None:
        return None
    if isinstance(obj, str):
        s = obj
        if len(s) > max_str:
            return s[:max_str] + f"...[truncated:{len(s)}]"
        return s
    if isinstance(obj, (int, float, bool)):
        return obj
    if isinstance(obj, list):
        return [_truncate_deep(x, max_str=max_str) for x in obj[:200]]
    if isinstance(obj, dict):
        out: Dict[str, Any] = {}
        for k, v in list(obj.items())[:200]:
            # å¸¸è§å­—æ®µï¼šdata/base64ï¼Œå•ç‹¬æ›´ä¸¥æ ¼ä¸€ç‚¹
            if k in ("data", "image", "base64", "payload") and isinstance(v, str) and len(v) > 512:
                out[k] = v[:256] + f"...[truncated:{len(v)}]"
            else:
                out[k] = _truncate_deep(v, max_str=max_str)
        return out
    return str(obj)


def call_llm_api(llm_config: dict, system_prompt: str, user_input: str, add_log=None):
    """
    è°ƒç”¨LLM API - ä½¿ç”¨ Provider SDK ç»Ÿä¸€è°ƒç”¨
    """
    from services.providers.factory import create_provider
    from services.providers.base import LLMMessage
    
    provider = llm_config.get('provider', '')
    api_key = llm_config.get('api_key', '')
    api_url = llm_config.get('api_url', '')
    model = llm_config.get('model', '')
    
    api_key_preview = f"{api_key[:8]}...{api_key[-4:]}" if api_key and len(api_key) > 12 else ("å·²è®¾ç½®" if api_key else "âŒ æœªè®¾ç½®")
    print(f"[call_llm_api] ğŸ”„ è°ƒç”¨LLM API (ä½¿ç”¨ Provider SDK)")
    print(f"[call_llm_api]    Provider: {provider}")
    print(f"[call_llm_api]    Model: {model}")
    print(f"[call_llm_api]    API URL: {api_url or 'é»˜è®¤'}")
    print(f"[call_llm_api]    API Key: {api_key_preview}")
    
    if add_log:
        add_log(f"ğŸ”„ è°ƒç”¨LLM API: {provider} - {model}")
        add_log(f"ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}, ç”¨æˆ·è¾“å…¥é•¿åº¦: {len(user_input)}")
        add_log(f"LLMé…ç½®è¯¦æƒ…: provider={provider}, model={model}, api_url={api_url or 'é»˜è®¤'}, api_key={api_key_preview}")

    # æ£€æŸ¥å¿…è¦å‚æ•°
    if not provider:
        print(f"[call_llm_api] âŒ LLMé…ç½®ä¸­ç¼ºå°‘providerå­—æ®µ")
        if add_log:
            add_log("âŒ LLMé…ç½®ä¸­ç¼ºå°‘providerå­—æ®µ")
        return None

    if not api_key:
        print(f"[call_llm_api] âŒ APIå¯†é’¥ä¸ºç©º (provider: {provider})")
        if add_log:
            add_log(f"âŒ APIå¯†é’¥ä¸ºç©º (provider: {provider})")
        return None

    if not model:
        print(f"[call_llm_api] âŒ æ¨¡å‹åç§°ä¸ºç©º (provider: {provider})")
        if add_log:
            add_log(f"âŒ æ¨¡å‹åç§°ä¸ºç©º (provider: {provider})")
        return None

    # ä½¿ç”¨ Provider SDK ç»Ÿä¸€è°ƒç”¨
    try:
        llm_provider = create_provider(
            provider_type=provider,
            api_key=api_key,
            api_url=api_url or None,
            model=model
        )
        
        messages = [
            LLMMessage(role='system', content=system_prompt),
            LLMMessage(role='user', content=user_input)
        ]
        
        print(f"[call_llm_api] ğŸ“¤ è°ƒç”¨ {provider.upper()} Provider SDK...")
        response = llm_provider.chat(messages, temperature=0.1, max_tokens=8192)
        
        content = response.content
        print(f"[call_llm_api] âœ… {provider.upper()} APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
        if add_log:
            add_log(f"âœ… {provider.upper()} APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
        return content
        
    except ValueError as e:
        # Provider ä¸æ”¯æŒ
        error_msg = str(e)
        print(f"[call_llm_api] âŒ Provider é”™è¯¯: {error_msg}")
        if add_log:
            add_log(f"âŒ Provider é”™è¯¯: {error_msg}")
        return None
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[call_llm_api] âŒ APIè°ƒç”¨å¤±è´¥: {error_msg}")
        if add_log:
            add_log(f"âŒ {provider.upper()} APIè°ƒç”¨å¤±è´¥: {error_msg}")
        return None


def call_llm_with_tools(
    llm_config: dict, 
    messages: List[Dict[str, Any]], 
    tools: List[Dict[str, Any]], 
    add_log=None
) -> Optional[Dict[str, Any]]:
    """
    ä½¿ç”¨åŸç”Ÿ Tool Calling è°ƒç”¨ LLMï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰
    
    ä¸ä¸´æ—¶ä¼šè¯ç›¸åŒçš„è°ƒç”¨æ–¹å¼ï¼Œä¸€æ¬¡ API è¯·æ±‚å³å¯å®Œæˆå·¥å…·é€‰æ‹©
    
    Args:
        llm_config: LLM é…ç½®
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆOpenAI æ ¼å¼ï¼‰
        tools: å·¥å…·åˆ—è¡¨ï¼ˆOpenAI function calling æ ¼å¼ï¼‰
        add_log: æ—¥å¿—å‡½æ•°
        
    Returns:
        {
            'content': str,  # æ–‡æœ¬å›å¤
            'tool_calls': List[Dict],  # å·¥å…·è°ƒç”¨åˆ—è¡¨
            'finish_reason': str
        }
        æˆ– Noneï¼ˆå¤±è´¥æ—¶ï¼‰
    """
    from services.providers.factory import create_provider
    from services.providers.base import LLMMessage
    
    provider = llm_config.get('provider', '')
    api_key = llm_config.get('api_key', '')
    api_url = llm_config.get('api_url', '')
    model = llm_config.get('model', '')
    
    api_key_preview = f"{api_key[:8]}...{api_key[-4:]}" if api_key and len(api_key) > 12 else ("å·²è®¾ç½®" if api_key else "âŒ æœªè®¾ç½®")
    print(f"[call_llm_with_tools] ğŸ”„ åŸç”Ÿ Tool Calling")
    print(f"[call_llm_with_tools]    Provider: {provider}, Model: {model}")
    print(f"[call_llm_with_tools]    Tools: {len(tools)} ä¸ª")
    print(f"[call_llm_with_tools]    Messages: {len(messages)} æ¡")
    
    if add_log:
        add_log(f"ğŸ”§ åŸç”ŸTool Calling: {provider}/{model}, {len(tools)}ä¸ªå·¥å…·")

    # æ£€æŸ¥å¿…è¦å‚æ•°
    if not provider or not api_key or not model:
        print(f"[call_llm_with_tools] âŒ ç¼ºå°‘å¿…è¦å‚æ•°")
        return None

    try:
        llm_provider = create_provider(
            provider_type=provider,
            api_key=api_key,
            api_url=api_url or None,
            model=model
        )
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        llm_messages = []
        for msg in messages:
            llm_messages.append(LLMMessage(
                role=msg.get('role', 'user'),
                content=msg.get('content', ''),
                tool_calls=msg.get('tool_calls'),
                tool_call_id=msg.get('tool_call_id'),
                name=msg.get('name')
            ))
        
        # è°ƒç”¨ LLMï¼ˆä¼ é€’ tools å‚æ•°å¯ç”¨åŸç”Ÿ function callingï¼‰
        print(f"[call_llm_with_tools] ğŸ“¤ è°ƒç”¨ {provider.upper()} SDK with tools...")
        response = llm_provider.chat(
            llm_messages, 
            tools=tools,
            tool_choice="auto",
            temperature=0.1,
            max_tokens=4096
        )
        
        result = {
            'content': response.content or '',
            'tool_calls': response.tool_calls or [],
            'finish_reason': response.finish_reason
        }
        
        tool_count = len(result['tool_calls']) if result['tool_calls'] else 0
        print(f"[call_llm_with_tools] âœ… æˆåŠŸ: {tool_count} ä¸ªå·¥å…·è°ƒç”¨, å†…å®¹é•¿åº¦: {len(result['content'])}")
        if add_log:
            add_log(f"âœ… åŸç”ŸTool CallingæˆåŠŸ: {tool_count}ä¸ªå·¥å…·è°ƒç”¨")
        
        return result
        
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"[call_llm_with_tools] âŒ å¤±è´¥: {error_msg}")
        if add_log:
            add_log(f"âŒ Tool Callingå¤±è´¥: {error_msg}")
        return None


# ==================== æ—§çš„åŸç”Ÿ HTTP å®ç°ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™å¤‡ç”¨ï¼‰ ====================
def _call_llm_api_legacy(llm_config: dict, system_prompt: str, user_input: str, add_log=None):
    """
    æ—§ç‰ˆ LLM API è°ƒç”¨ï¼ˆåŸç”Ÿ HTTP å®ç°ï¼‰
    å·²å¼ƒç”¨ï¼Œä¿ç•™å¤‡ç”¨
    """
    import requests
    from requests.exceptions import RequestException, Timeout, ConnectionError as RequestsConnectionError
    
    provider = llm_config.get('provider', '')
    api_key = llm_config.get('api_key', '')
    api_url = llm_config.get('api_url', '')
    model = llm_config.get('model', '')

    if provider == 'openai':
        default_url = 'https://api.openai.com/v1/chat/completions'
        url = api_url or default_url

        payload = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_input}
            ],
            # å·¥å…·é€‰æ‹©/ç»“æ„åŒ–è¾“å‡ºï¼šå°½é‡ç¨³å®š
            'temperature': 0.1,
            'max_tokens': 8192,  # å¢åŠ  max_tokens ç¡®ä¿å®Œæ•´è¿”å› JSON
        }

        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }

        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            if response.ok:
                data = response.json()
                content = data['choices'][0]['message']['content']
                if add_log:
                    add_log(f"âœ… OpenAI APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                return content
            else:
                if add_log:
                    error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                    add_log(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {error_text}")
                return None
        except Timeout:
            if add_log:
                add_log(f"âŒ OpenAI APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
            return None
        except RequestsConnectionError as e:
            if add_log:
                add_log(f"âŒ OpenAI APIè¿æ¥å¤±è´¥: {str(e)}")
            return None
        except RequestException as e:
            if add_log:
                add_log(f"âŒ OpenAI APIè¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            return None
        except Exception as e:
            if add_log:
                add_log(f"âŒ OpenAI APIè°ƒç”¨æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)}")
            return None

    elif provider == 'deepseek':
        # DeepSeek ä½¿ç”¨ OpenAI å…¼å®¹ API
        default_url = 'https://api.deepseek.com/v1/chat/completions'
        if not api_url:
            url = default_url
        elif '/chat/completions' not in api_url:
            # å¦‚æœåªæä¾›äº† hostï¼Œéœ€è¦è¡¥å…¨è·¯å¾„
            base_url = api_url.rstrip('/')
            if base_url.endswith('/v1'):
                url = f"{base_url}/chat/completions"
            else:
                url = f"{base_url}/v1/chat/completions"
        else:
            url = api_url
        
        # è°ƒè¯•æ—¥å¿—ï¼ˆå§‹ç»ˆæ‰“å°ï¼Œä¸ä¾èµ– add_logï¼‰
        print(f"[DeepSeek MCP] ğŸ”„ è°ƒç”¨ DeepSeek API")
        print(f"[DeepSeek MCP]    åŸå§‹ API URL: {api_url or 'æœªè®¾ç½®'}")
        print(f"[DeepSeek MCP]    æœ€ç»ˆ URL: {url}")
        print(f"[DeepSeek MCP]    Model: {model}")
        print(f"[DeepSeek MCP]    API Key: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")

        payload = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_input}
            ],
            # å·¥å…·é€‰æ‹©/ç»“æ„åŒ–è¾“å‡ºï¼šå°½é‡ç¨³å®š
            'temperature': 0.1,
            'max_tokens': 8192,  # å¢åŠ  max_tokens ç¡®ä¿å®Œæ•´è¿”å› JSON
        }

        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }

        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            print(f"[DeepSeek MCP]    Response Status: {response.status_code}")
            if response.ok:
                data = response.json()
                content = data['choices'][0]['message']['content']
                print(f"[DeepSeek MCP] âœ… æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                if add_log:
                    add_log(f"âœ… DeepSeek APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                return content
            else:
                error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                print(f"[DeepSeek MCP] âŒ å¤±è´¥: HTTP {response.status_code} - {error_text}")
                if add_log:
                    add_log(f"âŒ DeepSeek APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {error_text}")
                return None
        except Timeout:
            print(f"[DeepSeek MCP] âŒ è¶…æ—¶ (60ç§’)")
            if add_log:
                add_log(f"âŒ DeepSeek APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
            return None
        except RequestsConnectionError as e:
            print(f"[DeepSeek MCP] âŒ è¿æ¥å¤±è´¥: {str(e)}")
            if add_log:
                add_log(f"âŒ DeepSeek APIè¿æ¥å¤±è´¥: {str(e)}")
            return None
        except RequestException as e:
            print(f"[DeepSeek MCP] âŒ è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            if add_log:
                add_log(f"âŒ DeepSeek APIè¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            return None
        except Exception as e:
            print(f"[DeepSeek MCP] âŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)}")
            if add_log:
                add_log(f"âŒ DeepSeek APIè°ƒç”¨æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)}")
            return None
            
    elif provider == 'anthropic':
        default_url = 'https://api.anthropic.com/v1/messages'
        url = api_url or default_url
        
        payload = {
            'model': model,
            'max_tokens': 4096,
            'messages': [
                {'role': 'user', 'content': f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥: {user_input}"}
            ],
        }
        
        headers = {
            'x-api-key': api_key,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json',
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            if response.ok:
                data = response.json()
                content = data['content'][0]['text']
                if add_log:
                    add_log(f"âœ… Anthropic APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                return content
            else:
                if add_log:
                    error_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                    add_log(f"âŒ Anthropic APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {error_text}")
                return None
        except Timeout:
            if add_log:
                add_log(f"âŒ Anthropic APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
            return None
        except RequestsConnectionError as e:
            if add_log:
                add_log(f"âŒ Anthropic APIè¿æ¥å¤±è´¥: {str(e)}")
            return None
        except RequestException as e:
            if add_log:
                add_log(f"âŒ Anthropic APIè¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            return None
        except Exception as e:
            if add_log:
                add_log(f"âŒ Anthropic APIè°ƒç”¨æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)}")
            return None
            
    elif provider == 'gemini':
        default_url = 'https://generativelanguage.googleapis.com/v1beta'
        base_url = api_url or default_url
        model_name = model or 'gemini-2.5-flash'
        
        # æ„å»ºå®Œæ•´çš„ API URL
        if base_url.endswith('/'):
            url = f"{base_url}models/{model_name}:generateContent"
        else:
            url = f"{base_url}/models/{model_name}:generateContent"
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Gemini æ ¼å¼
        contents = [
            {
                'role': 'user',
                'parts': [{'text': f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥: {user_input}"}]
            }
        ]
        
        payload = {
            'contents': contents,
            'generationConfig': {
                # å·¥å…·é€‰æ‹©/ç»“æ„åŒ–è¾“å‡ºï¼šå°½é‡ç¨³å®š
                'temperature': 0.1,
                'maxOutputTokens': 8192,  # å¢åŠ  maxOutputTokens ç¡®ä¿å®Œæ•´è¿”å› JSON
            },
        }
        
        # åªåœ¨metadataä¸­æ˜ç¡®æŒ‡å®šthinking_levelæ—¶æ‰æ·»åŠ ï¼ˆæŸäº›æ¨¡å‹ä¸æ”¯æŒæ­¤å­—æ®µï¼‰
        if llm_config.get('metadata') and llm_config['metadata'].get('thinking_level'):
            payload['generationConfig']['thinkingLevel'] = llm_config['metadata']['thinking_level']
        
        headers = {
            'x-goog-api-key': api_key,
            'Content-Type': 'application/json',
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            if response.ok:
                data = response.json()
                if data.get('candidates') and len(data['candidates']) > 0:
                    candidate = data['candidates'][0]
                    if candidate.get('content') and candidate['content'].get('parts'):
                        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                        text_parts = [part.get('text', '') for part in candidate['content']['parts'] if part.get('text')]
                        content = ''.join(text_parts)
                        if add_log:
                            add_log(f"âœ… Gemini APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content or '')}")
                        return content
                if add_log:
                    add_log("âŒ Gemini APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
                return None
            else:
                if add_log:
                    try:
                        error_data = response.json() if response.content else {}
                        error_msg = error_data.get('error', {}).get('message', response.text)
                    except:
                        error_msg = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                    add_log(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code} - {error_msg}")
                return None
        except Timeout:
            if add_log:
                add_log(f"âŒ Gemini APIè°ƒç”¨è¶…æ—¶ (60ç§’)")
            return None
        except RequestsConnectionError as e:
            if add_log:
                add_log(f"âŒ Gemini APIè¿æ¥å¤±è´¥: {str(e)}")
            return None
        except RequestException as e:
            if add_log:
                add_log(f"âŒ Gemini APIè¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            return None
        except Exception as e:
            if add_log:
                add_log(f"âŒ Gemini APIè°ƒç”¨æœªçŸ¥é”™è¯¯: {type(e).__name__}: {str(e)}")
            return None
    else:
        print(f"[_call_llm_api_legacy] âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        if add_log:
            add_log(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        return None


def execute_mcp_with_llm(
    *,
    mcp_server_id: str,
    input_text: str,
    llm_config_id: str,
    add_log: Optional[callable] = None,
    max_iterations: int = 3,
    topic_id: Optional[str] = None,
    existing_session_id: Optional[str] = None,
    agent_system_prompt: Optional[str] = None,  # Agent çš„äººè®¾/ç³»ç»Ÿæç¤ºè¯
    original_message: Optional[Dict[str, Any]] = None,  # åŸå§‹æ¶ˆæ¯ï¼ˆç”¨äºæå–å›¾ç‰‡ç­‰ä¸Šä¸‹æ–‡ï¼‰
) -> Dict[str, Any]:
    """
    æ‰§è¡Œ MCPï¼ˆä¸¤æ­¥æ³•ï¼‰ï¼šLLM åªé€‰æ‹©å·¥å…·ï¼Œå‚æ•°ç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ
    
    Args:
        agent_system_prompt: Agent çš„äººè®¾ï¼Œä¼šä½œä¸ºç³»ç»Ÿæç¤ºè¯çš„ä¸€éƒ¨åˆ†
        original_message: åŸå§‹æ¶ˆæ¯ï¼ˆç”¨äºæå–å›¾ç‰‡ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰

    Returns:
      {
        "summary": str | None,
        "raw_result": dict | None,
        "logs": list[str],
        "error": str | None,
        "llm_response": str | None,
        "media": list[dict] | None,  # æå–çš„åª’ä½“æ•°æ®
      }
    """
    # ANSI é¢œè‰²ç 
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    MAGENTA = '\033[95m'
    RESET = '\033[0m'
    BOLD = '\033[1m'
    
    print(f"{MAGENTA}{BOLD}[MCP EXEC] ========== execute_mcp_with_llm å¼€å§‹ =========={RESET}")
    print(f"{MAGENTA}[MCP EXEC] Server: {mcp_server_id}, LLM: {llm_config_id}{RESET}")
    print(f"{MAGENTA}[MCP EXEC] Input é•¿åº¦: {len(input_text) if input_text else 0} å­—ç¬¦{RESET}")
    
    logs, log = _mk_logger(add_log)

    try:
        # å»æ‰ AgentActor æ³¨å…¥çš„â€œå·¥å…·ä½¿ç”¨æƒæç¤ºâ€ï¼Œé¿å…æ±¡æŸ“ LLM å†³ç­–è¾“å…¥
        effective_input = re.sub(r"^\[ä½ å·²è·å¾—å·¥å…·ä½¿ç”¨æƒï¼š.*?\]\s*", "", input_text or "").strip()
        if not effective_input:
            effective_input = input_text or ""

        # ä½¿ç”¨ llm_service è·å– LLM é…ç½®ï¼ˆç¡®ä¿æ ¼å¼æ­£ç¡®ä¸”åŒ…å« API keyï¼‰
        log(f"è·å–LLMé…ç½®: {llm_config_id}")
        try:
            from services.llm_service import get_llm_service
            llm_service = get_llm_service()
            llm_config = llm_service.get_config(llm_config_id, include_api_key=True)
            
            if not llm_config:
                log(f"âŒ LLMé…ç½®ä¸å­˜åœ¨æˆ–å·²ç¦ç”¨: {llm_config_id}")
                return {"error": "LLM config not found or disabled", "logs": logs}
            
            # llm_service.get_config è¿”å›çš„é…ç½®å·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
            log(f"âœ… LLMé…ç½®è·å–æˆåŠŸ:")
            log(f"   é…ç½®ID: {llm_config.get('config_id', llm_config_id)}")
            log(f"   Provider: {llm_config.get('provider', 'æœªçŸ¥')}")
            log(f"   Model: {llm_config.get('model', 'æœªçŸ¥')}")
            log(f"   API URL: {llm_config.get('api_url', 'é»˜è®¤')}")
            log(f"   API Key: {'å·²è®¾ç½®' if llm_config.get('api_key') else 'âŒ æœªè®¾ç½®'}")
            log(f"   Metadata: {llm_config.get('metadata', {})}")

            # éªŒè¯LLMé…ç½®çš„å®Œæ•´æ€§
            missing_fields = []
            if not llm_config.get('provider'):
                missing_fields.append('provider')
            if not llm_config.get('model'):
                missing_fields.append('model')
            if not llm_config.get('api_key'):
                missing_fields.append('api_key')

            if missing_fields:
                error_msg = f"LLMé…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}"
                log(f"âŒ {error_msg}")
                return {"error": error_msg, "logs": logs}
        except Exception as e:
            error_msg = f"è·å–LLMé…ç½®å¤±è´¥: {str(e)}"
            log(f"âŒ {error_msg}")
            return {"error": error_msg, "logs": logs}

        # è·å– MCP æœåŠ¡å™¨é…ç½®ï¼ˆä»ç„¶éœ€è¦æ•°æ®åº“è¿æ¥ï¼‰
        conn = get_mysql_connection()
        if not conn:
            return {"error": "MySQL not available", "logs": logs}

        cursor = None
        try:
            import pymysql
            cursor = conn.cursor(pymysql.cursors.DictCursor)

            # MCP server
            log(f"è·å–MCPæœåŠ¡å™¨é…ç½®: {mcp_server_id}")
            cursor.execute(
                """
                SELECT server_id, name, url, enabled
                FROM mcp_servers
                WHERE server_id = %s AND enabled = 1
                """,
                (mcp_server_id,),
            )
            mcp_server = cursor.fetchone()
            if not mcp_server:
                return {"error": "MCP server not found or disabled", "logs": logs}

            server_name = mcp_server.get("name") or mcp_server_id
            server_url = mcp_server.get("url")
            log(f"MCPæœåŠ¡å™¨é…ç½®è·å–æˆåŠŸ: {server_name} ({server_url})")

            # ==================== ä½¿ç”¨ mcp_common_logic ç›´æ¥è°ƒç”¨ MCPï¼ˆç±»ä¼¼ ok-publishï¼‰ ====================
            # 1. å‡†å¤‡è¯·æ±‚å¤´ï¼ˆåŒ…æ‹¬ OAuth token ç­‰ï¼‰
            base_headers = {
                'Content-Type': 'application/json',
                'Accept': 'application/json, text/event-stream',
                'mcp-protocol-version': '2025-06-18',
            }
            headers = prepare_mcp_headers(server_url, base_headers, base_headers)
            
            # 1.5 å¦‚æœæœ‰ existing_session_idï¼Œå¤ç”¨å·²æœ‰ä¼šè¯ï¼ˆé‡è¦ï¼šæŸäº› MCP æœåŠ¡å™¨è¦æ±‚ä¿æŒä¼šè¯è¿ç»­æ€§ï¼‰
            if existing_session_id:
                headers['mcp-session-id'] = existing_session_id
                log(f"å¤ç”¨å·²æœ‰ MCP session: {existing_session_id[:16]}...")
            
            # 2. åˆå§‹åŒ– MCP ä¼šè¯ï¼ˆä»…å½“æ²¡æœ‰ session_id æ—¶ï¼‰
            if 'mcp-session-id' not in headers:
                init_response = initialize_mcp_session(server_url, headers)
                if not init_response:
                    log("âš ï¸ MCP initialize å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•è·å–å·¥å…·åˆ—è¡¨")
                else:
                    log(f"MCP ä¼šè¯åˆå§‹åŒ–æˆåŠŸï¼Œsession_id: {headers.get('mcp-session-id', 'N/A')[:16]}...")
            else:
                log(f"è·³è¿‡ MCP ä¼šè¯åˆå§‹åŒ–ï¼Œä½¿ç”¨å·²æœ‰ session_id")
            
            # 3. è·å–å·¥å…·åˆ—è¡¨ï¼ˆå¸¦è‡ªåŠ¨é‡è¿å’Œé‡è¯•æœºåˆ¶ï¼‰
            log("Step 2/3: tools/list")
            # Actor åœºæ™¯ä¼˜å…ˆä¸èµ°ç¼“å­˜ï¼šé¿å… tools/list çš„çŸ­æœŸç¼“å­˜æ©ç›– session-id/æƒé™å˜æ›´
            # auto_reconnect=True ä¼šåœ¨å¤±è´¥æ—¶è‡ªåŠ¨æ¸…ç†æ—§è¿æ¥å¹¶é‡è¯•
            max_retries = 0  # æœ€å¤šé‡è¯•2æ¬¡ï¼ˆåŠ ä¸Šç¬¬ä¸€æ¬¡å…±3æ¬¡ï¼‰
            tools_response = None
            last_error = None
            
            for retry_attempt in range(max_retries + 1):
                if retry_attempt > 0:
                    log(f"âš ï¸ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥ï¼Œç¬¬ {retry_attempt + 1} æ¬¡å°è¯•...")
                    # æ¸…ç†æ—§è¿æ¥å’Œ session-idï¼Œå‡†å¤‡é‡æ–°åˆå§‹åŒ–
                    from mcp_server.mcp_common_logic import invalidate_mcp_connection
                    invalidate_mcp_connection(server_url)
                    if 'mcp-session-id' in headers:
                        del headers['mcp-session-id']
                    # é‡æ–°åˆå§‹åŒ–ä¼šè¯
                    init_response = initialize_mcp_session(server_url, headers)
                    if init_response:
                        log(f"âœ… é‡æ–°åˆå§‹åŒ– MCP ä¼šè¯æˆåŠŸï¼Œsession_id: {headers.get('mcp-session-id', 'N/A')[:16]}...")
                    else:
                        log("âš ï¸ é‡æ–°åˆå§‹åŒ– MCP ä¼šè¯å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•è·å–å·¥å…·åˆ—è¡¨")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
                    import time
                    time.sleep(0.5 * retry_attempt)
                
                tools_response = get_mcp_tools_list(server_url, headers, use_cache=False, auto_reconnect=True)
                if tools_response and 'result' in tools_response:
                    # æˆåŠŸè·å–å·¥å…·åˆ—è¡¨
                    break
                else:
                    # è®°å½•é”™è¯¯ä¿¡æ¯
                    if tools_response:
                        last_error = f"Invalid response: {str(tools_response)[:200]}"
                    else:
                        last_error = "No response from MCP server"
                    log(f"âŒ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {last_error}")
            
            if not tools_response or 'result' not in tools_response:
                # å¯¼å…¥å¥åº·çŠ¶æ€å‡½æ•°
                from mcp_server.mcp_common_logic import get_mcp_health_status
                health_status = get_mcp_health_status(server_url)
                log(f"âŒ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {last_error}")
                return {
                    "error": "Failed to get MCP tools list",
                    "logs": logs,
                    "debug": {
                        "server_url": server_url,
                        "mcp_session_id": headers.get("mcp-session-id"),
                        "tools_response_preview": _truncate_deep(tools_response, max_str=1200),
                        "health_status": health_status,
                        "last_error": last_error,
                        "retry_attempts": max_retries + 1,
                        "hint": "MCP æœåŠ¡å¯èƒ½å·²é‡å¯æˆ–ä¸å¯ç”¨ï¼Œç³»ç»Ÿå·²å°è¯•è‡ªåŠ¨é‡è¿å’Œé‡è¯•ã€‚è¯·æ£€æŸ¥ MCP æœåŠ¡çŠ¶æ€ã€‚",
                    },
                }

            tools = tools_response['result'].get('tools', [])
            if not tools:
                return {
                    "error": "No tools available from MCP server",
                    "logs": logs,
                }

            log(f"è·å–åˆ° {len(tools)} ä¸ªå¯ç”¨å·¥å…·")
            print(f"{GREEN}[MCP EXEC] âœ… è·å–åˆ° {len(tools)} ä¸ªå·¥å…·{RESET}")
            # è¯¦ç»†æ—¥å¿—ï¼šæ˜¾ç¤ºæ‰€æœ‰å·¥å…·åˆ—è¡¨
            all_tool_names = [t.get('name', 'unnamed') for t in tools]
            log(f"  å¯ç”¨å·¥å…·: {', '.join(all_tool_names)}")
            print(f"{CYAN}[MCP EXEC] æ‰€æœ‰å·¥å…·: {', '.join(all_tool_names)}{RESET}")
            
            # æ‰“å°å½“å‰ session_id çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
            current_session_id = headers.get('mcp-session-id')
            if current_session_id:
                log(f"  å½“å‰ MCP Session ID: {current_session_id[:16]}...")
            else:
                log(f"  âš ï¸ è­¦å‘Šï¼šæ—  MCP Session IDï¼ˆæŸäº›æœåŠ¡å™¨å¯èƒ½è¦æ±‚ï¼‰")

            # æ„å»ºå·¥å…·æè¿°ï¼ˆåŒ…å«å®Œæ•´çš„å‚æ•° schemaï¼‰
            def _format_tool_params(schema: Dict[str, Any]) -> str:
                """æ ¼å¼åŒ–å·¥å…·å‚æ•°ä¸ºæ˜“è¯»çš„æè¿°"""
                if not schema or not isinstance(schema, dict):
                    return "  å‚æ•°: æ— "
                
                props = schema.get("properties", {})
                required = schema.get("required", [])
                
                if not props:
                    return "  å‚æ•°: æ— "
                
                lines = []
                for param_name, param_info in props.items():
                    param_type = param_info.get("type", "string")
                    param_desc = param_info.get("description", "")
                    is_required = param_name in required
                    req_mark = "*å¿…éœ€*" if is_required else "å¯é€‰"
                    lines.append(f"    - {param_name} ({param_type}, {req_mark}): {param_desc}")
                
                return "  å‚æ•°:\n" + "\n".join(lines)
            
            tools_description_parts = []
            for t in tools:
                name = t.get('name', '')
                desc = t.get('description', '')
                schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                params_desc = _format_tool_params(schema)
                tools_description_parts.append(f"ã€{name}ã€‘\n  æè¿°: {desc}\n{params_desc}")
            
            tools_description = '\n\n'.join(tools_description_parts)
            
            # æ„å»ºå·¥å…·åç§°æ˜ å°„ï¼ˆç”¨äºéªŒè¯ï¼‰
            tool_name_map: Dict[str, Dict[str, Any]] = {}
            for t in tools:
                tool_name = t.get('name', '').strip()
                if tool_name:
                    schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                    props = {}
                    required = []
                    if isinstance(schema, dict):
                        props = schema.get("properties") or {}
                        required = schema.get("required") or []
                    tool_name_map[tool_name.lower()] = {
                        'name': tool_name,
                        'description': t.get('description', '').strip(),
                        'schema': schema,
                        'props': props if isinstance(props, dict) else {},
                        'required': required if isinstance(required, list) else [],
                    }

            # ç³»ç»Ÿæç¤ºè¯ï¼šAgent äººè®¾ + å·¥å…·è°ƒåº¦åŸåˆ™
            system_prompt_parts = []
            
            # 1. Agent çš„äººè®¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if agent_system_prompt:
                system_prompt_parts.append(agent_system_prompt)
                system_prompt_parts.append("")  # ç©ºè¡Œåˆ†éš”
            
            # 2. å·¥å…·é€‰æ‹©åŸåˆ™ï¼ˆä¸¤æ­¥æ³•ï¼šåªé€‰æ‹©å·¥å…·ï¼Œä¸ç”Ÿæˆå‚æ•°ï¼‰
            system_prompt_parts.append("""## å·¥å…·é€‰æ‹©èƒ½åŠ›

ä½ æ˜¯ä¸€ä¸ªå·¥å…·é€‰æ‹©åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œä»å¯ç”¨å·¥å…·ä¸­é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚

### âš ï¸ é‡è¦ï¼šè¿”å›æ ¼å¼è¦æ±‚

**ä½ åªéœ€è¦é€‰æ‹©å·¥å…·åç§°ï¼Œä¸è¦ç”Ÿæˆå‚æ•°ã€‚å‚æ•°ä¼šç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆã€‚**

è¿”å›æ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
```json
{
  "selected_tools": ["tool_name1", "tool_name2"],
  "intent": "ç”¨æˆ·æ„å›¾ç®€è¿°ï¼ˆ10å­—ä»¥å†…ï¼‰"
}
```

å¦‚æœä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼š
```json
{
  "selected_tools": [],
  "intent": "æ— éœ€å·¥å…·"
}
```

**è§„åˆ™ï¼š**
1. åªè¿”å›å·¥å…·åç§°åˆ—è¡¨ï¼Œä¸è¦åŒ…å«å‚æ•°
2. å·¥å…·åç§°å¿…é¡»å®Œå…¨åŒ¹é…å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­çš„åç§°
3. æœ€å¤šé€‰æ‹© 3 ä¸ªå·¥å…·
4. æŒ‰æ‰§è¡Œé¡ºåºæ’åˆ—
5. intent å­—æ®µç®€çŸ­æè¿°ç”¨æˆ·æ„å›¾ï¼ˆ10å­—ä»¥å†…ï¼‰
6. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—æˆ–markdownä»£ç å—""")
            
            system_prompt = "\n".join(system_prompt_parts)
            
            print(f"{CYAN}[MCP EXEC] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦{RESET}")
            
            # ç”¨æˆ·æ¶ˆæ¯ï¼šå†å² + å½“å‰è¯·æ±‚ + å·¥å…·åˆ—è¡¨
            user_message_parts = []
            
            # ä» effective_input ä¸­æå–å†å²å’Œå½“å‰è¯·æ±‚
            # effective_input æ ¼å¼å¯èƒ½æ˜¯ï¼šã€å¯¹è¯å†å²ã€‘...ã€å½“å‰è¯·æ±‚ã€‘...
            user_message_parts.append(effective_input)
            
            # æ·»åŠ å®Œæ•´çš„å·¥å…·åˆ—è¡¨
            user_message_parts.append(f"\n\n## å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆå…± {len(tools)} ä¸ªï¼‰\n")
            user_message_parts.append(tools_description)
            user_message_parts.append("\n\nè¯·æ ¹æ®ä¸Šè¿°è¯·æ±‚é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·å¹¶è¿”å› JSONã€‚")
            
            user_input_for_llm = "".join(user_message_parts)
            
            print(f"{CYAN}[MCP EXEC] ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(user_input_for_llm)} å­—ç¬¦{RESET}")

            # è®©åŒä¸€ä¸ª llm_config å†³å®š tool_callsï¼ˆæ”¯æŒå¤šè½®â€œè¿ç»­è°ƒç”¨â€ï¼‰
            # æ³¨æ„ï¼šä¸åŒæ¨¡å‹å¯¹â€œä¸¥æ ¼è¾“å‡º JSONâ€èƒ½åŠ›å·®å¼‚å¾ˆå¤§ï¼ˆå°¤å…¶ Gemini/è½»é‡æ¨¡å‹ï¼‰ã€‚
            # è¿™é‡Œä¸åšâ€œè‡ªåŠ¨çŒœå·¥å…·â€çš„ fallbackï¼šå¿…é¡»ç”± LLM å†³å®š tool_callsï¼›è‹¥å¤±è´¥åˆ™è¿”å› errorã€‚
            # ä¸¤æ­¥æ³•ï¼šç§»é™¤äº† _default_args_for_toolï¼Œä½¿ç”¨ generate_tool_arguments æ›¿ä»£
            
            def _infer_next_tool_from_context(
                user_input: str,
                prior_results: str,
                tool_list: List[Dict[str, Any]],
                executed_results: List[Dict[str, Any]],
                tool_map: Dict[str, Dict[str, Any]]
            ) -> Optional[Dict[str, Any]]:
                """
                æ ¹æ®å·²æ‰§è¡Œç»“æœå’Œç”¨æˆ·è¾“å…¥æ¨æ–­ä¸‹ä¸€æ­¥åº”è¯¥è°ƒç”¨çš„å·¥å…·
                
                ç­–ç•¥ï¼š
                1. å¦‚æœä¹‹å‰çš„å·¥å…·æ‰§è¡Œæœ‰é”™è¯¯ï¼Œä¸å†ç»§ç»­
                2. å¦‚æœä¹‹å‰çš„ç»“æœä¸­æœ‰æ˜ç¡®çš„"ä¸‹ä¸€æ­¥"æç¤ºï¼Œå°è¯•è§£æ
                3. å¦‚æœç”¨æˆ·è¾“å…¥åŒ…å«å¤šä¸ªæ„å›¾ï¼Œå°è¯•æ‰¾åˆ°å°šæœªæ‰§è¡Œçš„å·¥å…·
                """
                # æ£€æŸ¥æ˜¯å¦æœ‰æ‰§è¡Œå¤±è´¥çš„ç»“æœ
                for r in executed_results:
                    if r.get('error'):
                        return None  # æœ‰é”™è¯¯ï¼Œä¸å†ç»§ç»­
                
                # æå–å·²æ‰§è¡Œçš„å·¥å…·åç§°
                executed_tool_names = set()
                for r in executed_results:
                    tool_name = r.get('tool')
                    if tool_name:
                        executed_tool_names.add(tool_name.lower())
                
                # æ‰¾åˆ°å°šæœªæ‰§è¡Œçš„ç›¸å…³å·¥å…·
                user_lower = user_input.lower()
                tokens = [w for w in re.split(r"[^a-z0-9\u4e00-\u9fff]+", user_lower) if w]
                
                best_candidate = None
                best_score = 0
                
                for t in tool_list:
                    tool_name = t.get('name', '').lower()
                    if tool_name in executed_tool_names:
                        continue  # å·²æ‰§è¡Œè¿‡ï¼Œè·³è¿‡
                    
                    # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
                    hay = f"{t.get('name','')} {t.get('description','')}".lower()
                    score = 0
                    for w in tokens[:12]:
                        if w and w in hay:
                            score += 1
                    
                    # å¦‚æœå¾—åˆ†è¶³å¤Ÿé«˜ï¼ˆè‡³å°‘æœ‰2ä¸ªå…³é”®è¯åŒ¹é…ï¼‰ï¼Œè€ƒè™‘ä½œä¸ºå€™é€‰
                    if score >= 2 and score > best_score:
                        best_score = score
                        best_candidate = t
                
                if best_candidate:
                    tool_name = best_candidate.get('name', '')
                    # æ„å»ºå‚æ•°ï¼ˆä½¿ç”¨ç®€å•è§„åˆ™ï¼‰
                    schema = best_candidate.get("inputSchema") or best_candidate.get("input_schema") or best_candidate.get("parameters") or {}
                    props = schema.get("properties") or {} if isinstance(schema, dict) else {}
                    
                    # ç®€å•å‚æ•°ç”Ÿæˆ
                    if "input" in props:
                        args = {"input": user_input}
                    elif "query" in props:
                        args = {"query": user_input}
                    elif "text" in props:
                        args = {"text": user_input}
                    elif len(props) == 1:
                        k = next(iter(props.keys()))
                        args = {k: user_input}
                    else:
                        args = {"input": user_input}
                    
                    return {"name": tool_name, "arguments": args}
                
                return None

            all_tool_calls: List[Dict[str, Any]] = []
            results: List[Dict[str, Any]] = []
            executed_tool_names: set[str] = set()  # è®°å½•å·²æ‰§è¡Œçš„å·¥å…·å

            # ==================== å°è¯•åŸç”Ÿ Tool Callingï¼ˆé«˜æ€§èƒ½è·¯å¾„ï¼‰ ====================
            # æ”¯æŒåŸç”Ÿ function calling çš„æ¨¡å‹ï¼ˆOpenAI, DeepSeek ç­‰ï¼‰å¯ä»¥ä¸€æ¬¡ API è°ƒç”¨å®Œæˆå·¥å…·é€‰æ‹©
            provider_type = llm_config.get('provider', '').lower()
            use_native_tool_calling = provider_type in ('openai', 'deepseek', 'anthropic', 'claude')
            
            if use_native_tool_calling:
                log("Step 3/3: å·¥å…·é€‰æ‹©ä¸æ‰§è¡Œï¼ˆåŸç”Ÿ Tool Calling - é«˜æ€§èƒ½ï¼‰")
                print(f"{GREEN}[MCP EXEC] ğŸš€ ä½¿ç”¨åŸç”Ÿ Tool Callingï¼ˆ{provider_type}ï¼‰{RESET}")
                
                # æ„å»º OpenAI æ ¼å¼çš„å·¥å…·åˆ—è¡¨
                openai_tools = []
                for t in tools:
                    schema = t.get("inputSchema") or t.get("input_schema") or t.get("parameters") or {}
                    openai_tools.append({
                        "type": "function",
                        "function": {
                            "name": t.get("name", ""),
                            "description": t.get("description", ""),
                            "parameters": schema
                        }
                    })
                
                # æ„å»ºæ¶ˆæ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸éœ€è¦å¤æ‚çš„ JSON æŒ‡ä»¤ï¼‰
                native_messages = []
                if agent_system_prompt:
                    native_messages.append({
                        "role": "system",
                        "content": agent_system_prompt + "\n\nä½ å¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚"
                    })
                else:
                    native_messages.append({
                        "role": "system", 
                        "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚"
                    })
                
                # ä» effective_input æå–ç”¨æˆ·è¯·æ±‚
                actual_request = extract_user_request_from_input(effective_input)
                if not actual_request:
                    actual_request = effective_input
                
                native_messages.append({
                    "role": "user",
                    "content": actual_request
                })
                
                # è°ƒç”¨åŸç”Ÿ Tool Calling
                native_result = call_llm_with_tools(llm_config, native_messages, openai_tools, log)
                
                if native_result and native_result.get('tool_calls'):
                    tool_calls_from_native = native_result['tool_calls']
                    log(f"âœ… åŸç”Ÿ Tool Calling è¿”å› {len(tool_calls_from_native)} ä¸ªå·¥å…·è°ƒç”¨")
                    print(f"{GREEN}[MCP EXEC] âœ… åŸç”Ÿè¿”å› {len(tool_calls_from_native)} ä¸ªå·¥å…·è°ƒç”¨{RESET}")
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    for tc in tool_calls_from_native[:5]:  # æœ€å¤š5ä¸ª
                        tool_name = tc.get('function', {}).get('name') or tc.get('name', '')
                        tool_args_str = tc.get('function', {}).get('arguments') or tc.get('arguments', '{}')
                        
                        # è§£æå‚æ•°
                        try:
                            if isinstance(tool_args_str, str):
                                tool_args = json.loads(tool_args_str) if tool_args_str else {}
                            else:
                                tool_args = tool_args_str if isinstance(tool_args_str, dict) else {}
                        except json.JSONDecodeError:
                            tool_args = {}
                        
                        log(f"  æ‰§è¡Œå·¥å…·: {tool_name}")
                        print(f"{CYAN}[MCP EXEC] æ‰§è¡Œå·¥å…·: {tool_name}, å‚æ•°: {list(tool_args.keys())}{RESET}")
                        
                        # è°ƒç”¨ MCP å·¥å…·
                        try:
                            tool_result = call_mcp_tool(
                                target_url=server_url,
                                headers=headers,
                                tool_name=tool_name,
                                tool_args=tool_args,
                                add_log=log,
                            )
                            
                            # æå–ç»“æœï¼ˆcall_mcp_tool è¿”å›æ ¼å¼ï¼š{success, data, text, raw_result, ...}ï¼‰
                            if tool_result and tool_result.get('success'):
                                tool_text = tool_result.get('text') or str(tool_result.get('data', ''))
                                
                                results.append({
                                    "tool": tool_name,
                                    "arguments": tool_args,
                                    "tool_text": tool_text,
                                    "raw_result": tool_result.get('raw_result'),
                                    "success": True,
                                })
                                executed_tool_names.add(tool_name)
                                log(f"    âœ… {tool_name} æ‰§è¡ŒæˆåŠŸ")
                            else:
                                error_msg = tool_result.get('error', 'æœªçŸ¥é”™è¯¯') if tool_result else 'è°ƒç”¨å¤±è´¥'
                                results.append({
                                    "tool": tool_name,
                                    "error": error_msg,
                                    "success": False,
                                })
                                log(f"    âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {error_msg}")
                        except Exception as e:
                            results.append({
                                "tool": tool_name,
                                "error": str(e),
                                "success": False,
                            })
                            log(f"    âŒ {tool_name} å¼‚å¸¸: {e}")
                    
                    # åŸç”Ÿ Tool Calling æˆåŠŸï¼Œè·³è¿‡ä¸¤æ­¥æ³•
                    all_tool_calls = tool_calls_from_native
                    
                    # æ„å»ºè¿”å›ç»“æœ
                    tool_text_outputs = []
                    for r in results:
                        if r.get('success') and r.get('tool_text'):
                            tool_text_outputs.append(f"ã€{r['tool']}ã€‘\n{r['tool_text']}")
                    
                    final_tool_text = '\n\n'.join(tool_text_outputs) if tool_text_outputs else ''
                    executed_names = [r.get('tool') for r in results if r.get('success')]
                    summary = f"âœ… MCP \"{server_name}\" æ‰§è¡Œå®Œæˆï¼ˆ{len(executed_names)} ä¸ªå·¥å…·è°ƒç”¨ï¼š{', '.join(executed_names)}ï¼‰"
                    
                    log(f"åŸç”Ÿ Tool Calling å®Œæˆ: {summary}")
                    
                    return {
                        "summary": summary,
                        "tool_text": final_tool_text,
                        "results": results,
                        "raw_result": results[0].get('raw_result') if results else None,
                        "raw_result_compact": _truncate_deep(results[0].get('raw_result'), max_str=1200) if results else None,
                        "logs": logs,
                        "media": [],  # TODO: æå–åª’ä½“
                        "mcp_session_id": headers.get('mcp-session-id'),
                        "native_tool_calling": True,
                    }
                else:
                    # åŸç”Ÿ Tool Calling æ²¡æœ‰è¿”å›å·¥å…·è°ƒç”¨ï¼Œå¯èƒ½æ˜¯ä¸éœ€è¦å·¥å…·æˆ–å¤±è´¥
                    if native_result and native_result.get('content'):
                        log(f"âš ï¸ åŸç”Ÿ Tool Calling è¿”å›æ–‡æœ¬è€Œéå·¥å…·è°ƒç”¨ï¼Œå›é€€åˆ°ä¸¤æ­¥æ³•")
                        print(f"{YELLOW}[MCP EXEC] âš ï¸ åŸç”Ÿè¿”å›æ–‡æœ¬ï¼Œå›é€€ä¸¤æ­¥æ³•{RESET}")
                    else:
                        log(f"âš ï¸ åŸç”Ÿ Tool Calling å¤±è´¥ï¼Œå›é€€åˆ°ä¸¤æ­¥æ³•")
                        print(f"{YELLOW}[MCP EXEC] âš ï¸ åŸç”Ÿå¤±è´¥ï¼Œå›é€€ä¸¤æ­¥æ³•{RESET}")

            # ==================== ä¸¤æ­¥æ³•ï¼ˆå…¼å®¹æ—§æ¨¡å‹ï¼‰ ====================
            log("Step 3/3: å·¥å…·é€‰æ‹©ä¸æ‰§è¡Œï¼ˆä¸¤æ­¥æ³• - å…¼å®¹æ¨¡å¼ï¼‰")
            for it in range(max(1, int(max_iterations or 1))):
                # ä¸¤æ­¥æ³•ï¼šé¦–è½®ç›´æ¥é€‰æ‹©å·¥å…·ï¼Œåç»­è½®æ¬¡æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
                if it == 0:
                    # é¦–è½®ï¼šç®€å•æç¤º
                    iter_system = system_prompt + "\n\nè¯·åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚åªè¿”å›JSONæ ¼å¼ã€‚"
                    iter_user = user_input_for_llm
                else:
                    # åç»­è½®æ¬¡ï¼šå¸¦ä¸Šå·²æ‰§è¡Œçš„å·¥å…·ç»“æœï¼Œè®© LLM å†³å®šæ˜¯å¦éœ€è¦æ›´å¤šå·¥å…·
                    prior_texts = []
                    for r in results[-6:]:
                        if r.get("tool") and r.get("tool_text"):
                            prior_texts.append(f"ã€{r['tool']}ã€‘æ‰§è¡Œç»“æœ:\n{r['tool_text']}")
                    prior_block = ("\n\n".join(prior_texts)).strip()

                    # æ„å»ºå·²æ‰§è¡Œå·¥å…·åˆ—è¡¨
                    executed_tools_str = ", ".join(executed_tool_names) if executed_tool_names else "æ— "
                    
                    iter_system = system_prompt + f"""

## å½“å‰çŠ¶æ€

- å·²æ‰§è¡Œå·¥å…·: {executed_tools_str}
- è¿™æ˜¯ç¬¬ {it+1} è½®å†³ç­–

## å†³ç­–è§„åˆ™

1. **ä¸è¦é‡å¤è°ƒç”¨å·²æ‰§è¡Œè¿‡çš„å·¥å…·**
2. å¦‚æœç”¨æˆ·çš„éœ€æ±‚å·²è¢«æ»¡è¶³ï¼Œè¿”å›ç©ºçš„å·¥å…·åˆ—è¡¨: {{"selected_tools": [], "intent": "å·²å®Œæˆ"}}
3. åªæœ‰åœ¨ç¡®å®éœ€è¦æ–°ä¿¡æ¯æ—¶æ‰é€‰æ‹©æ–°å·¥å…·"""

                    # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼šå†å² + è¯·æ±‚ + å·¥å…·åˆ—è¡¨ + å·²æ‰§è¡Œç»“æœ
                    iter_user = user_input_for_llm
                    if prior_block:
                        iter_user += f"\n\n=== å·²æ‰§è¡Œå·¥å…·çš„ç»“æœ ===\n{prior_block}\n\nè¯·æ ¹æ®ä»¥ä¸Šç»“æœå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨æ›´å¤šå·¥å…·ï¼Œæˆ–è€…ä»»åŠ¡å·²å®Œæˆã€‚"

                selected_tool_names: List[str] = []
                llm_text: str = ""
                intent: Optional[str] = None
                def _parse_llm_tool_selection(raw_text: str) -> Tuple[List[str], Optional[str], Optional[str]]:
                    """
                    ä» LLM è¾“å‡ºä¸­è§£æå·¥å…·é€‰æ‹©ï¼ˆä¸¤æ­¥æ³•ï¼‰
                    
                    æœŸæœ›æ ¼å¼ï¼š
                    {
                      "selected_tools": ["tool_name1", "tool_name2"],
                      "intent": "ç”¨æˆ·æ„å›¾"
                    }
                    
                    Returns:
                        (å·¥å…·åç§°åˆ—è¡¨, intent, é”™è¯¯ä¿¡æ¯)
                    """
                    if not raw_text:
                        return [], None, "empty llm output"

                    txt = (raw_text or "").strip()

                    # å»æ‰ markdown code fenceï¼ˆå¸¸è§ï¼š```json ... ```ï¼‰
                    fence_match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", txt, re.IGNORECASE)
                    if fence_match:
                        txt = fence_match.group(1).strip()

                    # å…¼å®¹æ™ºèƒ½å¼•å·
                    txt = (
                        txt.replace("\u201c", "\"")
                        .replace("\u201d", "\"")
                        .replace("\u2018", "'")
                        .replace("\u2019", "'")
                    )

                    def _extract_json_objects(s: str) -> List[str]:
                        """
                        æå– JSON å¯¹è±¡ï¼Œæ­£ç¡®å¤„ç†å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                        """
                        objs: List[str] = []
                        depth = 0
                        start = None
                        in_string = False
                        escape_next = False
                        
                        for i, ch in enumerate(s):
                            if escape_next:
                                escape_next = False
                                continue
                            
                            if ch == '\\':
                                escape_next = True
                                continue
                            
                            if ch == '"' and not escape_next:
                                in_string = not in_string
                                continue
                            
                            if not in_string:
                                if ch == "{":
                                    if depth == 0:
                                        start = i
                                    depth += 1
                                elif ch == "}":
                                    if depth > 0:
                                        depth -= 1
                                        if depth == 0 and start is not None:
                                            objs.append(s[start : i + 1])
                                            start = None
                        return objs

                    candidates = _extract_json_objects(txt)
                    if not candidates:
                        return [], None, "no json object found in llm output"

                    last_err: Optional[str] = None
                    for cand in candidates:
                        try:
                            data = json.loads(cand)
                            if not isinstance(data, dict):
                                continue
                            
                            # æ”¯æŒæ–°æ ¼å¼ï¼šselected_tools
                            if "selected_tools" in data:
                                selected = data.get("selected_tools", [])
                                tool_names = selected if isinstance(selected, list) else []
                                intent = data.get("intent", "")
                                return tool_names, intent, None
                            
                            # å…¼å®¹æ—§æ ¼å¼ï¼štool_callsï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                            elif "tool_calls" in data:
                                tc = data.get("tool_calls", [])
                                if isinstance(tc, list) and len(tc) > 0:
                                    # ä» tool_calls ä¸­æå–å·¥å…·åç§°
                                    tool_names = [call.get("name") for call in tc if isinstance(call, dict) and call.get("name")]
                                    return tool_names, "å…¼å®¹æ—§æ ¼å¼", None
                                else:
                                    # ç©ºçš„ tool_callsï¼Œè¡¨ç¤ºä¸éœ€è¦å·¥å…·
                                    return [], "æ— éœ€å·¥å…·", None
                        except Exception as e:
                            last_err = f"{type(e).__name__}: {str(e)}"
                            continue

                    # Fallback: å°è¯•æ›´æ¿€è¿›çš„JSONæå–
                    # æŸ¥æ‰¾åŒ…å« "selected_tools" æˆ– "tool_calls" çš„JSONç‰‡æ®µ
                    fallback_candidates = []
                    patterns = [
                        re.compile(r'["\']selected_tools["\']\s*:\s*\[', re.IGNORECASE),
                        re.compile(r'["\']tool_calls["\']\s*:\s*\[', re.IGNORECASE)
                    ]
                    
                    for pattern in patterns:
                        for match in pattern.finditer(txt):
                            start_pos = match.start()
                            # ä»åŒ¹é…ä½ç½®å‘å‰æŸ¥æ‰¾JSONå¼€å§‹
                            brace_count = 0
                            json_start = -1
                            for i in range(start_pos, -1, -1):
                                if txt[i] == '{':
                                    brace_count += 1
                                    if brace_count == 1:
                                        json_start = i
                                        break
                                elif txt[i] == '}':
                                    brace_count -= 1

                            if json_start >= 0:
                                # ä»json_startå¼€å§‹æå–å®Œæ•´çš„JSONå¯¹è±¡
                                # éœ€è¦æ­£ç¡®å¤„ç†å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                                depth = 0
                                in_string = False
                                escape_next = False
                                for i in range(json_start, len(txt)):
                                    if escape_next:
                                        escape_next = False
                                        continue
                                    
                                    if txt[i] == '\\':
                                        escape_next = True
                                        continue
                                    
                                    if txt[i] == '"' and not escape_next:
                                        in_string = not in_string
                                        continue
                                    
                                    if not in_string:
                                        if txt[i] == '{':
                                            depth += 1
                                        elif txt[i] == '}':
                                            depth -= 1
                                            if depth == 0:
                                                candidate = txt[json_start:i+1]
                                                fallback_candidates.append(candidate)
                                                break

                    # å°è¯•è§£æfallbackå€™é€‰
                    for cand in fallback_candidates:
                        try:
                            data = json.loads(cand)
                            if isinstance(data, dict):
                                # æ”¯æŒæ–°æ ¼å¼ï¼šselected_tools
                                if "selected_tools" in data:
                                    selected = data.get("selected_tools", [])
                                    tool_names = selected if isinstance(selected, list) else []
                                    intent = data.get("intent", "")
                                    return tool_names, intent, None
                                # å…¼å®¹æ—§æ ¼å¼ï¼štool_calls
                                elif "tool_calls" in data:
                                    tc = data.get("tool_calls", [])
                                    if isinstance(tc, list):
                                        tool_names = [call.get("name") for call in tc if isinstance(call, dict) and call.get("name")]
                                        return tool_names, "å…¼å®¹æ—§æ ¼å¼", None
                        except Exception as e:
                            continue

                    return [], None, last_err or "json parse failed"

                def _decide_with_llm(system_text: str, user_text: str, round_label: str) -> Tuple[List[str], Optional[str], str, Optional[str]]:
                    """
                    ä½¿ç”¨ LLM å†³ç­–å·¥å…·é€‰æ‹©ï¼ˆä¸¤æ­¥æ³•ï¼‰
                    
                    Returns:
                        (å·¥å…·åç§°åˆ—è¡¨, intent, LLMè¾“å‡ºæ–‡æœ¬, é”™è¯¯ä¿¡æ¯)
                    """
                    out_text = ""
                    tool_names: List[str] = []
                    intent: Optional[str] = None
                    parse_err: Optional[str] = None
                    try:
                        log(f"{round_label}ï¼šä½¿ç”¨LLMé€‰æ‹©å·¥å…·")
                        log(f"   LLMé…ç½®ID: {llm_config_id}")
                        log(f"   LLMé…ç½®å†…å®¹: provider={llm_config.get('provider')}, model={llm_config.get('model')}, has_api_key={bool(llm_config.get('api_key'))}")
                        api_result = call_llm_api(llm_config, system_text, user_text, log)

                        if api_result is None:
                            # LLM APIè°ƒç”¨å¤±è´¥
                            parse_err = "llm_api_call_failed: APIè°ƒç”¨è¿”å›Noneï¼Œè¯·æ£€æŸ¥LLMé…ç½®ã€ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥"
                            out_text = ""
                        elif api_result == "":
                            # LLMè¿”å›äº†ç©ºå­—ç¬¦ä¸²
                            parse_err = "llm_returned_empty: LLMè¿”å›äº†ç©ºå­—ç¬¦ä¸²"
                            out_text = ""
                        else:
                            # APIè°ƒç”¨æˆåŠŸï¼Œæœ‰è¿”å›å†…å®¹
                            out_text = api_result
                            tool_names, intent, parse_err = _parse_llm_tool_selection(out_text)

                    except Exception as e:
                        log(f"âš ï¸ {round_label} LLM å†³ç­–å¤±è´¥: {str(e)}")
                        parse_err = f"llm_call_failed: {type(e).__name__}: {str(e)}"
                        out_text = ""

                    # å…³é”®è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºé¢„è§ˆ + è§£æé”™è¯¯
                    preview = (out_text or "").replace("\n", "\\n")[:600]
                    print(f"{MAGENTA}[MCP EXEC] {round_label} LLMè¾“å‡ºé¢„è§ˆ: {preview}{RESET}")
                    print(f"{CYAN}[MCP EXEC] {round_label} LLMè¾“å‡ºæ€»é•¿åº¦: {len(out_text or '')} å­—ç¬¦{RESET}")
                    print(f"{CYAN}[MCP EXEC] {round_label} é€‰æ‹©çš„å·¥å…·: {tool_names}{RESET}")
                    if intent:
                        print(f"{CYAN}[MCP EXEC] {round_label} ç”¨æˆ·æ„å›¾: {intent}{RESET}")
                    if parse_err:
                        print(f"{YELLOW}[MCP EXEC] {round_label} é”™è¯¯: {parse_err}{RESET}")

                    return tool_names, intent, out_text, parse_err

                # ç¬¬ä¸€æ¬¡å†³ç­–ï¼šLLM é€‰æ‹©å·¥å…·ï¼ˆåªè¿”å›å·¥å…·åç§°ï¼‰
                selected_tool_names, intent, llm_text, parse_error = _decide_with_llm(
                    iter_system,
                    iter_user,
                    f"ç¬¬ {it+1}/{max_iterations} è½®",
                )

                # å…è®¸ä¸€æ¬¡é‡è¯•ï¼šå¦‚æœ LLM æ²¡ç»™å‡ºå·¥å…·é€‰æ‹©
                if not selected_tool_names:
                    retry_system = (
                        system_prompt
                        + "\n\nâš ï¸ é”™è¯¯ï¼šä½ ä¸Šä¸€æ¬¡æ²¡æœ‰è¿”å›åˆæ³•çš„JSONæ ¼å¼ã€‚"
                        + "\n\nè¯·é‡æ–°æ€è€ƒå¹¶åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
                        + "\n- éœ€è¦å·¥å…·ï¼š{\"selected_tools\": [\"tool_name1\"], \"intent\": \"æ„å›¾\"}"
                        + "\n- ä¸éœ€è¦å·¥å…·ï¼š{\"selected_tools\": [], \"intent\": \"æ— éœ€å·¥å…·\"}"
                        + "\n\nç°åœ¨è¯·é‡æ–°å›ç­”ï¼Œåªè¾“å‡ºJSONï¼š"
                    )
                    selected_tool_names, intent, retry_text, retry_parse_error = _decide_with_llm(
                        retry_system,
                        iter_user,
                        f"ç¬¬ {it+1}/{max_iterations} è½®ï¼ˆé‡è¯•1æ¬¡ï¼‰",
                    )
                    if retry_text:
                        llm_text = retry_text
                        parse_error = retry_parse_error

                if not selected_tool_names:
                    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„é”™è¯¯ä¿¡æ¯
                    if parse_error and ("llm_api_call_failed" in parse_error or "llm_call_failed" in parse_error):
                        # APIè°ƒç”¨å¤±è´¥
                        error_msg = "LLM APIè°ƒç”¨å¤±è´¥"
                        suggestion = "è¯·æ£€æŸ¥ï¼š1) LLMé…ç½®æ˜¯å¦æ­£ç¡® 2) APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ 3) ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ 4) APIé¢åº¦æ˜¯å¦å……è¶³"
                    elif parse_error and "llm_returned_empty" in parse_error:
                        # LLMè¿”å›ç©ºå†…å®¹
                        error_msg = "LLMè¿”å›äº†ç©ºå†…å®¹"
                        suggestion = "LLMå¯èƒ½ä¸æ”¯æŒå½“å‰çš„ä»»åŠ¡ï¼Œæˆ–é‡åˆ°äº†å†…éƒ¨é”™è¯¯ã€‚è¯·å°è¯•æ›´æ¢LLMæ¨¡å‹æˆ–ç®€åŒ–è¾“å…¥ã€‚"
                    else:
                        # JSONè§£æå¤±è´¥
                        error_msg = "LLMæœªè¿”å›æœ‰æ•ˆçš„å·¥å…·é€‰æ‹© JSON æ ¼å¼"
                        suggestion = "LLMå¯èƒ½æ²¡æœ‰ç†è§£JSONæ ¼å¼è¦æ±‚ï¼Œæˆ–è¿”å›äº†æ™®é€šæ–‡æœ¬ã€‚è¯·æ£€æŸ¥LLMæ¨¡å‹æ˜¯å¦æ”¯æŒç»“æ„åŒ–è¾“å‡ºã€‚"

                    error_details = {
                        "error": error_msg,
                        "logs": logs,
                        "llm_response": llm_text,
                        "debug": {
                            "llm_parse_error": parse_error,
                            "llm_output_length": len(llm_text or ""),
                            "available_tools": [t.get('name', '') for t in tools[:5]],  # åªæ˜¾ç¤ºå‰5ä¸ªå·¥å…·é¿å…æ—¥å¿—è¿‡é•¿
                            "iteration": it + 1,
                            # "suggestion": suggestion  # å·²ç§»é™¤ï¼Œé¿å…è§¦å‘è‡ªåŠ¨åˆ†æ
                        },
                    }

                    # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
                    log(f"âŒ LLM å·¥å…·é€‰æ‹©å¤±è´¥ï¼š{parse_error}")
                    log(f"LLM è¾“å‡ºé•¿åº¦: {len(llm_text or '')} å­—ç¬¦")
                    log(f"LLM è¾“å‡ºé¢„è§ˆ: {(llm_text or '')[:200]}...")
                    if len(llm_text or '') > 200:
                        log(f"... (çœç•¥ {len(llm_text or '') - 200} å­—ç¬¦)")

                    return error_details

                # æ‰§è¡Œæœ¬è½®å·¥å…·è°ƒç”¨ï¼ˆä¸¤æ­¥æ³•ï¼šå…ˆç”Ÿæˆå‚æ•°ï¼Œå†è°ƒç”¨ï¼‰
                log(f"ç¬¬ {it+1} è½®ï¼šé€‰æ‹©äº† {len(selected_tool_names)} ä¸ªå·¥å…·")
                for i, tool_name in enumerate(selected_tool_names[:5]):  # æ¯è½®æœ€å¤š 5 ä¸ªï¼Œé¿å…å¤±æ§
                    if not tool_name:
                        continue
                    
                    # ã€ä¸¤æ­¥æ³•ã€‘æ­¥éª¤2ï¼šç”Ÿæˆå·¥å…·å‚æ•°
                    # éªŒè¯å·¥å…·åç§°æ˜¯å¦çœŸå®å­˜åœ¨
                    tool_name_str = str(tool_name).strip()
                    tool_name_lower = tool_name_str.lower()
                    tool_info = tool_name_map.get(tool_name_lower)
                    
                    if not tool_info:
                        # å°è¯•æ¨¡ç³ŠåŒ¹é…
                        matched_tool_info = None
                        for actual_name, info in tool_name_map.items():
                            if tool_name_lower in actual_name or actual_name in tool_name_lower:
                                matched_tool_info = info
                                tool_name_str = info['name']  # ä½¿ç”¨çœŸå®çš„å·¥å…·åç§°
                                tool_info = info
                                log(f"å·¥å…·åç§°ä¿®æ­£: {tool_name_lower} -> {tool_name_str}")
                                break
                        
                        if not matched_tool_info:
                            error_msg = f"å·¥å…· '{tool_name_str}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·: {', '.join([t['name'] for t in tools[:10]])}"
                            log(f"âŒ {error_msg}")
                            results.append({"tool": tool_name_str, "error": error_msg})
                            continue
                        
                        tool_info = matched_tool_info
                    
                    # ã€ä¸¤æ­¥æ³•æ ¸å¿ƒã€‘è‡ªåŠ¨ç”Ÿæˆå·¥å…·å‚æ•°ï¼ˆå‡å°‘æ—¥å¿—è¾“å‡ºä»¥åŠ é€Ÿï¼‰
                    # ä» effective_input ä¸­æå–ç”¨æˆ·çš„å®é™…è¯·æ±‚ï¼ˆå»é™¤å·¥å…·æè¿°å’Œå†å²ä¸Šä¸‹æ–‡ï¼‰
                    actual_user_request = extract_user_request_from_input(effective_input)
                    if not actual_user_request:
                        actual_user_request = effective_input  # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥
                    
                    tool_args = generate_tool_arguments(
                        tool_name=tool_name_str,
                        tool_info=tool_info,
                        user_input=actual_user_request,
                        context={
                            'original_message': original_message or {'ext': {}},
                        },
                        llm_config=llm_config,  # ä¼ é€’ LLM é…ç½®
                        full_input_text=effective_input,  # ä¼ é€’å®Œæ•´è¾“å…¥ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
                        add_log=None  # ä¸ä¼ é€’æ—¥å¿—å‡½æ•°ï¼Œå‡å°‘è¾“å‡º
                    )
                    
                    # åªè®°å½•å…³é”®ä¿¡æ¯ï¼Œä¸è¾“å‡ºè¯¦ç»†å‚æ•°
                    log(f"å‡†å¤‡è°ƒç”¨å·¥å…·: {tool_name_str}")
                    
                    # éªŒè¯å¿…éœ€å‚æ•°æ˜¯å¦éƒ½å·²ç”Ÿæˆ
                    required_params = tool_info.get('required', [])
                    missing_required = [p for p in required_params if p not in tool_args or tool_args[p] is None]
                    if missing_required:
                        log(f"âš ï¸ å·¥å…· {tool_name_str} ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_required}")
                        # å°è¯•ä½¿ç”¨é»˜è®¤å€¼å¡«å……
                        props = tool_info.get('props', {})
                        for param in missing_required:
                            if param in props:
                                param_info = props[param]
                                default_val = param_info.get('default')
                                if default_val is not None:
                                    tool_args[param] = default_val
                                    log(f"  ä½¿ç”¨é»˜è®¤å€¼å¡«å…… {param}: {default_val}")
                                else:
                                    # å¦‚æœæ²¡æœ‰é»˜è®¤å€¼ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼ˆé¿å…è°ƒç”¨å¤±è´¥ï¼‰
                                    tool_args[param] = ""
                                    log(f"  ä½¿ç”¨ç©ºå€¼å¡«å…… {param}")
                    
                    # ç§»é™¤å€¼ä¸º None çš„å‚æ•°
                    tool_args = {k: v for k, v in tool_args.items() if v is not None}

                    # é˜²æ­¢é‡å¤è°ƒç”¨åŒä¸€ä¸ªå·¥å…·ï¼ˆåŒä¸€è½®æ¬¡å†…ï¼‰
                    if tool_name_str.lower() in executed_tool_names:
                        log(f"âš ï¸ è·³è¿‡é‡å¤çš„å·¥å…·è°ƒç”¨: {tool_name_str}")
                        continue

                    # é€šç”¨å®‰å…¨æ‹¦æˆªï¼šç ´åæ€§å·¥å…·å¿…é¡»ç”¨æˆ·æ˜ç¡®è¦æ±‚
                    destructive_markers = ("delete", "clear", "remove", "logout", "reset", "wipe")
                    user_lower_for_policy = (effective_input or "").lower()
                    user_asked_destructive = any(k in user_lower_for_policy for k in ("åˆ é™¤", "æ¸…é™¤", "ç§»é™¤", "ç™»å‡º", "é€€å‡ºç™»å½•", "delete", "clear", "remove", "logout", "reset", "wipe"))
                    if (not user_asked_destructive) and any(m in tool_name_str.lower() for m in destructive_markers):
                        msg = f"Blocked destructive tool call without explicit user request: {tool_name_str}"
                        log(f"âŒ {msg}")
                        results.append({
                            "tool": tool_name_str,
                            "error": msg,
                            "error_type": "policy",
                        })
                        return {
                            "error": msg,
                            "logs": logs,
                            "results": results,
                        }

                    all_tool_calls.append({"name": tool_name_str, "arguments": tool_args, "auto_generated": True})
                    # å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œåªè®°å½•å…³é”®ä¿¡æ¯
                    log(f"æ‰§è¡Œå·¥å…·: {tool_name_str}")
                    
                    try:
                        # ä½¿ç”¨ mcp_common_logic ç›´æ¥è°ƒç”¨å·¥å…·ï¼ˆä¸ä¼ é€’ log ä»¥å‡å°‘è¾“å‡ºï¼‰
                        tool_result = call_mcp_tool(server_url, headers, tool_name_str, tool_args, None)
                        
                        # å¤„ç†æ–°çš„ç»“æ„åŒ–è¿”å›æ ¼å¼
                        if isinstance(tool_result, dict):
                            if tool_result.get('success'):
                                # æˆåŠŸ
                                result_data = tool_result.get('data')
                                result_text = tool_result.get('text')
                                raw_result = tool_result.get('raw_result')
                                
                                results.append({
                                    'tool': tool_name_str,
                                    'result': {
                                        'jsonrpc': '2.0',
                                        'result': raw_result or {'content': [{'type': 'text', 'text': str(result_data)}]}
                                    },
                                    'tool_text': result_text or str(result_data) if result_data else '',
                                })
                                # æˆåŠŸï¼šåªè®°å½•ç®€è¦ä¿¡æ¯
                                executed_tool_names.add(tool_name_str.lower())
                            else:
                                # å¤±è´¥ - åŒºåˆ†é”™è¯¯ç±»å‹ï¼ˆåªè®°å½•é”™è¯¯ï¼Œä¸è®°å½•è¯¦ç»†ä¿¡æ¯ï¼‰
                                error_type = tool_result.get('error_type', 'unknown')
                                error_msg = tool_result.get('error', 'æœªçŸ¥é”™è¯¯')
                                error_code = tool_result.get('error_code')
                                http_code = tool_result.get('http_code')
                                
                                if error_type == 'network':
                                    error_display = f"[ç½‘ç»œé”™è¯¯] HTTP {http_code}: {error_msg}" if http_code else f"[ç½‘ç»œé”™è¯¯] {error_msg}"
                                elif error_type == 'business':
                                    error_display = f"[ä¸šåŠ¡é”™è¯¯] ä»£ç  {error_code}: {error_msg}" if error_code else f"[ä¸šåŠ¡é”™è¯¯] {error_msg}"
                                else:
                                    error_display = f"[{error_type}] {error_msg}"
                                
                                # åªè®°å½•é”™è¯¯ï¼Œä¸è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                                log(f"âŒ {tool_name_str}: {error_display[:100]}")
                                results.append({
                                    "tool": tool_name_str,
                                    "error": error_display,
                                    "error_type": error_type,
                                    "error_code": error_code,
                                })
                        else:
                            # å…¼å®¹æ—§æ ¼å¼ï¼ˆç›´æ¥è¿”å›ç»“æœï¼‰
                            if tool_result:
                                results.append({
                                    'tool': tool_name_str,
                                    'result': {
                                        'jsonrpc': '2.0',
                                        'result': {'content': [{'type': 'text', 'text': str(tool_result)}]}
                                    }
                                })
                                # æˆåŠŸï¼šåªè®°å½•ç®€è¦ä¿¡æ¯
                                executed_tool_names.add(tool_name_str.lower())
                            else:
                                results.append({"tool": tool_name_str, "error": "å·¥å…·è¿”å›ç©ºç»“æœ"})
                                
                    except Exception as e:
                        import traceback
                        # åªè®°å½•ç®€è¦é”™è¯¯ä¿¡æ¯
                        log(f"âŒ {tool_name_str}: {str(e)[:100]}")
                        results.append({
                            "tool": tool_name_str,
                            "error": f"æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                            "error_type": "exception",
                        })

                # ä¸¤æ­¥æ³•ï¼šå®Œæˆæœ¬è½®åç»“æŸï¼ˆä¸å†éœ€è¦ done_flag åˆ¤æ–­ï¼‰
                break

            # æŠ½å–å¯è¯»æ–‡æœ¬è¾“å‡ºï¼Œç»™ LLM ä½œä¸ºâ€œäº‹å®æºâ€ï¼ˆä¼˜åŒ–ï¼šæå–æ‰€æœ‰å¯ç”¨ä¿¡æ¯ï¼‰
            tool_text_outputs: List[str] = []
            all_extracted_media: List[Dict[str, Any]] = []  # æ”¶é›†æ‰€æœ‰æå–çš„åª’ä½“æ•°æ®
            try:
                for r in results:
                    tool_resp = r.get("result")
                    tool_name = r.get("tool") or "tool"
                    
                    # å¤„ç†é”™è¯¯æƒ…å†µ
                    if r.get("error"):
                        error_msg = str(r.get("error", ""))
                        r["tool_text"] = f"é”™è¯¯: {error_msg}"
                        tool_text_outputs.append(f"[{tool_name}] âŒ {error_msg}")
                        continue
                    
                    if not isinstance(tool_resp, dict):
                        # å¦‚æœä¸æ˜¯ dictï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        if tool_resp:
                            text_block = str(tool_resp).strip()
                            r["tool_text"] = text_block
                            tool_text_outputs.append(f"[{tool_name}]\n{text_block}")
                        continue
                    
                    # æå– content ä¸­çš„æ–‡æœ¬å†…å®¹å’Œå›¾ç‰‡æ•°æ®
                    content = (tool_resp.get("result") or {}).get("content")
                    texts = []
                    tool_images = []  # å½“å‰å·¥å…·è¿”å›çš„å›¾ç‰‡
                    
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict):
                                item_type = item.get("type", "")
                                if item_type == "text" and item.get("text"):
                                    texts.append(str(item.get("text")))
                                elif item_type == "image" and item.get("data"):
                                    # æå–å›¾ç‰‡æ•°æ®
                                    image_data = item.get("data")
                                    mime_type = item.get("mimeType") or item.get("mime_type") or "image/png"
                                    
                                    # å¦‚æœ data æ˜¯ data URLï¼Œæå– base64 éƒ¨åˆ†
                                    if isinstance(image_data, str) and image_data.startswith("data:"):
                                        # æå– base64 éƒ¨åˆ†
                                        comma_idx = image_data.find(",")
                                        if comma_idx >= 0:
                                            # ä» data URL ä¸­æå– mime type
                                            mime_part = image_data[5:comma_idx].split(";")[0]
                                            if mime_part:
                                                mime_type = mime_part
                                            image_data = image_data[comma_idx + 1:]
                                    
                                    if image_data:
                                        image_item = {
                                            "type": "image",
                                            "mimeType": mime_type,
                                            "data": image_data,
                                        }
                                        tool_images.append(image_item)
                                        all_extracted_media.append(image_item)
                                        texts.append(f"[å›¾ç‰‡æ•°æ®å·²è¿”å›ï¼Œå¤§å°: {len(str(image_data))} å­—ç¬¦]")
                                elif item_type:
                                    # å…¶ä»–ç±»å‹ï¼šå°è¯•æå–å¯è¯»ä¿¡æ¯
                                    for key in ["text", "content", "message", "data"]:
                                        if item.get(key):
                                            texts.append(f"[{item_type}]: {str(item.get(key))[:500]}")
                                            break
                    
                    # å°†æå–çš„å›¾ç‰‡æ•°æ®å­˜å‚¨åˆ°ç»“æœä¸­
                    if tool_images:
                        r["media"] = tool_images
                    
                    # å¦‚æœæ²¡æœ‰ä» content æå–åˆ°æ–‡æœ¬ï¼Œå°è¯•å…¶ä»–å­—æ®µ
                    if not texts:
                        # å°è¯•ç›´æ¥æå– result ä¸­çš„æ–‡æœ¬å­—æ®µ
                        for key in ["text", "message", "content", "output", "data"]:
                            if tool_resp.get("result", {}).get(key):
                                texts.append(str(tool_resp["result"][key]))
                                break
                        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•æ•´ä¸ª result
                        if not texts and tool_resp.get("result"):
                            result_data = tool_resp.get("result")
                            if isinstance(result_data, str):
                                texts.append(result_data)
                            elif isinstance(result_data, dict):
                                # å°è¯•åºåˆ—åŒ–ä¸º JSONï¼ˆä½†é™åˆ¶é•¿åº¦ï¼‰
                                try:
                                    result_json = json.dumps(result_data, ensure_ascii=False)
                                    if len(result_json) < 2000:
                                        texts.append(result_json)
                                    else:
                                        texts.append(result_json[:2000] + "...[å·²æˆªæ–­]")
                                except:
                                    texts.append(str(result_data)[:1000])
                    
                    if texts:
                        text_block = ("\n".join(texts)).strip()
                        r["tool_text"] = text_block
                        tool_text_outputs.append(f"[{tool_name}]\n{text_block}")
                    else:
                        # å¦‚æœå®Œå…¨æ²¡æœ‰æ–‡æœ¬ï¼Œè‡³å°‘è®°å½•å·¥å…·å·²æ‰§è¡Œ
                        r["tool_text"] = f"å·¥å…· {tool_name} å·²æ‰§è¡Œï¼Œä½†æœªè¿”å›æ–‡æœ¬å†…å®¹"
                        tool_text_outputs.append(f"[{tool_name}] å·²æ‰§è¡Œï¼ˆæ— æ–‡æœ¬è¿”å›ï¼‰")
            except Exception as e:
                import traceback
                traceback.print_exc()
                # å³ä½¿æå–å¤±è´¥ï¼Œä¹Ÿä¸å½±å“æ•´ä½“æµç¨‹
                pass

            tool_names = [r.get("tool") for r in results if r.get("tool")]
            tool_names_text = ", ".join(tool_names[:8]) + ("..." if len(tool_names) > 8 else "")
            summary = f'âœ… MCP "{server_name}" æ‰§è¡Œå®Œæˆï¼ˆ{len(results)} ä¸ªå·¥å…·è°ƒç”¨ï¼š{tool_names_text}ï¼‰'

            raw_result = {
                "mcp_server_id": mcp_server_id,
                "mcp_server_name": server_name,
                "mcp_server_url": server_url,
                "input": effective_input,
                "tool_calls": all_tool_calls,
                "results": results,  # results[i].result ä¿ç•™åŸå§‹ MCP jsonrpcï¼ˆå« base64 å›¾ç‰‡ï¼‰
            }

            return {
                "summary": summary,
                "tool_text": "\n\n".join(tool_text_outputs).strip() if tool_text_outputs else None,
                "results": results,  # é¡¶å±‚ä¹Ÿæš´éœ² resultsï¼Œä¾¿äºé”™è¯¯å¤„ç†
                "raw_result": raw_result,
                "raw_result_compact": _truncate_deep(raw_result),
                "logs": logs,
                "media": all_extracted_media if all_extracted_media else None,  # æå–çš„æ‰€æœ‰åª’ä½“æ•°æ®
            }

        finally:
            if cursor:
                cursor.close()
            conn.close()

    except Exception as e:
        return {"error": str(e), "logs": logs}

