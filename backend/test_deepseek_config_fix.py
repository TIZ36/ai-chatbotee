#!/usr/bin/env python3
"""
æµ‹è¯• DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½® API URL
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from services.llm_service import get_llm_service


def test_deepseek_api_url_auto_setting():
    """æµ‹è¯• DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½® API URL"""
    print("ğŸ”„ æµ‹è¯• DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½® API URL...")

    # æ¨¡æ‹Ÿ LLM é…ç½®æœåŠ¡
    class MockLLMConfig:
        def __init__(self, config_id, name, provider, model, api_url=None):
            self.config_id = config_id
            self.name = name
            self.provider = provider
            self.model = model
            self.api_url = api_url
            self.api_key = 'test_key'

        def to_dict(self, include_api_key=False):
            result = {
                'config_id': self.config_id,
                'name': self.name,
                'provider': self.provider,
                'model': self.model,
                'api_url': self.api_url,
            }
            if include_api_key:
                result['api_key'] = self.api_key
            return result

    # æ¨¡æ‹Ÿå­˜å‚¨åº“
    class MockRepository:
        def __init__(self):
            self.configs = {
                'deepseek_config': MockLLMConfig(
                    'deepseek_config',
                    'DeepSeek Reasoner',
                    'openai',
                    'deepseek-reasoner',
                    None  # api_url ä¸ºç©ºï¼Œåº”è¯¥è¢«è‡ªåŠ¨è®¾ç½®
                ),
                'openai_config': MockLLMConfig(
                    'openai_config',
                    'GPT-4',
                    'openai',
                    'gpt-4',
                    None  # api_url ä¸ºç©º
                ),
                'deepseek_custom_url': MockLLMConfig(
                    'deepseek_custom_url',
                    'DeepSeek Custom',
                    'openai',
                    'deepseek-chat',
                    'https://custom.deepseek.api/v1/chat/completions'  # å·²ç»æœ‰è‡ªå®šä¹‰ URL
                )
            }

        def find_by_id(self, config_id):
            return self.configs.get(config_id)

    # åˆ›å»ºæ¨¡æ‹Ÿçš„ LLM æœåŠ¡
    class MockLLMService:
        def __init__(self):
            self.repository = MockRepository()

        def get_config(self, config_id: str, include_api_key: bool = False):
            config = self.repository.find_by_id(config_id)
            if config:
                config_dict = config.to_dict(include_api_key=include_api_key)

                # è‡ªåŠ¨è®¾ç½® DeepSeek çš„ API URLï¼ˆå¤åˆ¶å®é™…é€»è¾‘ï¼‰
                if config.provider == 'openai' and config.model and 'deepseek' in config.model.lower():
                    if not config.api_url:  # åªæœ‰åœ¨æ²¡æœ‰è®¾ç½®è‡ªå®šä¹‰ URL æ—¶æ‰è‡ªåŠ¨è®¾ç½®
                        config_dict['api_url'] = 'https://api.deepseek.com/v1/chat/completions'

                return config_dict
            return None

    # æµ‹è¯•é€»è¾‘
    service = MockLLMService()

    # æµ‹è¯• DeepSeek é…ç½®ï¼ˆæ²¡æœ‰è‡ªå®šä¹‰ URLï¼‰
    print("\nğŸ§ª æµ‹è¯• DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½® URL...")
    deepseek_config = service.get_config('deepseek_config', include_api_key=True)
    assert deepseek_config is not None, "DeepSeek é…ç½®ä¸å­˜åœ¨"
    assert deepseek_config['api_url'] == 'https://api.deepseek.com/v1/chat/completions', f"DeepSeek URL æœªè‡ªåŠ¨è®¾ç½®: {deepseek_config['api_url']}"
    assert deepseek_config['api_key'] == 'test_key', "API Key æ²¡æœ‰åŒ…å«"
    print("  âœ… DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½® URL æˆåŠŸ")

    # æµ‹è¯•æ™®é€š OpenAI é…ç½®
    print("\nğŸ§ª æµ‹è¯•æ™®é€š OpenAI é…ç½®...")
    openai_config = service.get_config('openai_config', include_api_key=True)
    assert openai_config is not None, "OpenAI é…ç½®ä¸å­˜åœ¨"
    assert openai_config['api_url'] is None, f"OpenAI é…ç½®ä¸åº”è‡ªåŠ¨è®¾ç½® URL: {openai_config['api_url']}"
    print("  âœ… æ™®é€š OpenAI é…ç½®ä¿æŒä¸å˜")

    # æµ‹è¯• DeepSeek é…ç½®ï¼ˆå·²æœ‰è‡ªå®šä¹‰ URLï¼‰
    print("\nğŸ§ª æµ‹è¯• DeepSeek é…ç½®ï¼ˆå·²æœ‰è‡ªå®šä¹‰ URLï¼‰...")
    deepseek_custom_config = service.get_config('deepseek_custom_url', include_api_key=True)
    assert deepseek_custom_config is not None, "DeepSeek è‡ªå®šä¹‰é…ç½®ä¸å­˜åœ¨"
    assert deepseek_custom_config['api_url'] == 'https://custom.deepseek.api/v1/chat/completions', f"è‡ªå®šä¹‰ URL è¢«è¦†ç›–: {deepseek_custom_config['api_url']}"
    print("  âœ… è‡ªå®šä¹‰ URL é…ç½®ä¿æŒä¸å˜")

    print("âœ… DeepSeek é…ç½®è‡ªåŠ¨è®¾ç½®æµ‹è¯•é€šè¿‡")

    return True


def test_call_llm_api_routing():
    """æµ‹è¯• call_llm_api çš„è·¯ç”±é€»è¾‘"""
    print("ğŸ”„ æµ‹è¯• call_llm_api è·¯ç”±é€»è¾‘...")

    from services.mcp_execution_service import call_llm_api

    # æµ‹è¯•é…ç½®
    deepseek_config = {
        'provider': 'openai',
        'model': 'deepseek-reasoner',
        'api_key': 'test_key',
        'api_url': 'https://api.deepseek.com/v1/chat/completions'
    }

    openai_config = {
        'provider': 'openai',
        'model': 'gpt-4',
        'api_key': 'test_key',
        'api_url': None
    }

    # æµ‹è¯•æ—¥å¿—æ”¶é›†
    logs = []

    def add_log(msg):
        logs.append(msg)
        print(f"ğŸ“ {msg}")

    # æµ‹è¯• DeepSeek é…ç½®
    print("\nğŸ§ª æµ‹è¯• DeepSeek API è°ƒç”¨è·¯ç”±...")
    # æ³¨æ„ï¼šè¿™é‡Œä¸ä¼šå®é™…è°ƒç”¨ APIï¼Œå› ä¸º API key æ˜¯å‡çš„
    # æˆ‘ä»¬åªæ£€æŸ¥å®ƒæ˜¯å¦è¿›å…¥äº†æ­£ç¡®çš„åˆ†æ”¯
    try:
        result = call_llm_api(deepseek_config, "test", "test", add_log)
        # åº”è¯¥ä¼šå¤±è´¥ï¼Œä½†è‡³å°‘åº”è¯¥æ˜¾ç¤ºæ­£ç¡®çš„æ—¥å¿—
        assert any("DeepSeek" not in log for log in logs), "ä¸åº”è¯¥æœ‰ DeepSeek ç‰¹æ®Šæ—¥å¿—"
        assert any("openai" in log.lower() for log in logs), "åº”è¯¥ä½¿ç”¨ OpenAI åˆ†æ”¯"
        print("  âœ… DeepSeek é…ç½®ä½¿ç”¨ OpenAI åˆ†æ”¯ï¼ˆæ­£ç¡®ï¼‰")
    except Exception:
        # é¢„æœŸçš„ï¼Œå› ä¸º API key æ˜¯å‡çš„
        assert any("openai" in log.lower() for log in logs), "åº”è¯¥ä½¿ç”¨ OpenAI åˆ†æ”¯"
        print("  âœ… DeepSeek é…ç½®ä½¿ç”¨ OpenAI åˆ†æ”¯ï¼ˆæ­£ç¡®ï¼‰")

    print("âœ… call_llm_api è·¯ç”±é€»è¾‘æµ‹è¯•é€šè¿‡")

    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ DeepSeek é…ç½®ä¿®å¤æµ‹è¯•")
    print("=" * 60)

    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_deepseek_api_url_auto_setting()
        test_call_llm_api_routing()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ DeepSeek é…ç½®ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ ä¿®å¤å†…å®¹:")
        print("  - âœ… å‰ç«¯è‡ªåŠ¨è®¾ç½® DeepSeek API URL")
        print("  - âœ… åç«¯è‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„ DeepSeek API URL")
        print("  - âœ… ç®€åŒ– MCP æ‰§è¡ŒæœåŠ¡çš„ API è°ƒç”¨é€»è¾‘")
        print("  - âœ… DeepSeek ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£")
        return 0

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())